{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平均損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.621033, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "    \n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    \n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "\n",
    "X, y = data_loader.get_batch(batch_size)\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(X)\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 優化神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.270030\n",
      "batch 1: loss 2.224965\n",
      "batch 2: loss 2.026703\n",
      "batch 3: loss 1.971361\n",
      "batch 4: loss 1.675312\n",
      "batch 5: loss 1.727646\n",
      "batch 6: loss 1.700375\n",
      "batch 7: loss 1.589053\n",
      "batch 8: loss 1.656189\n",
      "batch 9: loss 1.352090\n",
      "batch 10: loss 1.368398\n",
      "batch 11: loss 1.185152\n",
      "batch 12: loss 1.270373\n",
      "batch 13: loss 1.259618\n",
      "batch 14: loss 1.310029\n",
      "batch 15: loss 1.102000\n",
      "batch 16: loss 1.156472\n",
      "batch 17: loss 0.945554\n",
      "batch 18: loss 0.876053\n",
      "batch 19: loss 1.122862\n",
      "batch 20: loss 0.895682\n",
      "batch 21: loss 1.022535\n",
      "batch 22: loss 0.975804\n",
      "batch 23: loss 0.775467\n",
      "batch 24: loss 0.906837\n",
      "batch 25: loss 1.011373\n",
      "batch 26: loss 0.877039\n",
      "batch 27: loss 0.672401\n",
      "batch 28: loss 0.974840\n",
      "batch 29: loss 0.705565\n",
      "batch 30: loss 0.778809\n",
      "batch 31: loss 0.796692\n",
      "batch 32: loss 0.686874\n",
      "batch 33: loss 0.799991\n",
      "batch 34: loss 0.787389\n",
      "batch 35: loss 0.689136\n",
      "batch 36: loss 0.603588\n",
      "batch 37: loss 0.938194\n",
      "batch 38: loss 0.661362\n",
      "batch 39: loss 0.699422\n",
      "batch 40: loss 0.718282\n",
      "batch 41: loss 0.464456\n",
      "batch 42: loss 0.554190\n",
      "batch 43: loss 0.707650\n",
      "batch 44: loss 0.619041\n",
      "batch 45: loss 0.755484\n",
      "batch 46: loss 0.636869\n",
      "batch 47: loss 0.689093\n",
      "batch 48: loss 0.714121\n",
      "batch 49: loss 0.621533\n",
      "batch 50: loss 0.733986\n",
      "batch 51: loss 0.484270\n",
      "batch 52: loss 0.616739\n",
      "batch 53: loss 0.657399\n",
      "batch 54: loss 0.538003\n",
      "batch 55: loss 0.547417\n",
      "batch 56: loss 0.660068\n",
      "batch 57: loss 0.562709\n",
      "batch 58: loss 0.579823\n",
      "batch 59: loss 0.689675\n",
      "batch 60: loss 0.438540\n",
      "batch 61: loss 0.508521\n",
      "batch 62: loss 0.575902\n",
      "batch 63: loss 0.562010\n",
      "batch 64: loss 0.352814\n",
      "batch 65: loss 0.621333\n",
      "batch 66: loss 0.655967\n",
      "batch 67: loss 0.427076\n",
      "batch 68: loss 0.553424\n",
      "batch 69: loss 0.390243\n",
      "batch 70: loss 0.463166\n",
      "batch 71: loss 0.457130\n",
      "batch 72: loss 0.538970\n",
      "batch 73: loss 0.712189\n",
      "batch 74: loss 0.435248\n",
      "batch 75: loss 0.673122\n",
      "batch 76: loss 0.529030\n",
      "batch 77: loss 0.429585\n",
      "batch 78: loss 0.518898\n",
      "batch 79: loss 0.491338\n",
      "batch 80: loss 0.352216\n",
      "batch 81: loss 0.519415\n",
      "batch 82: loss 0.771273\n",
      "batch 83: loss 0.302615\n",
      "batch 84: loss 0.460792\n",
      "batch 85: loss 0.588036\n",
      "batch 86: loss 0.408025\n",
      "batch 87: loss 0.439211\n",
      "batch 88: loss 0.404049\n",
      "batch 89: loss 0.464711\n",
      "batch 90: loss 0.321760\n",
      "batch 91: loss 0.630198\n",
      "batch 92: loss 0.551522\n",
      "batch 93: loss 0.459717\n",
      "batch 94: loss 0.479026\n",
      "batch 95: loss 0.252136\n",
      "batch 96: loss 0.472006\n",
      "batch 97: loss 0.246865\n",
      "batch 98: loss 0.515168\n",
      "batch 99: loss 0.585708\n",
      "batch 100: loss 0.355762\n",
      "batch 101: loss 0.343469\n",
      "batch 102: loss 0.432388\n",
      "batch 103: loss 0.548368\n",
      "batch 104: loss 0.401364\n",
      "batch 105: loss 0.429606\n",
      "batch 106: loss 0.489318\n",
      "batch 107: loss 0.382066\n",
      "batch 108: loss 0.306755\n",
      "batch 109: loss 0.278457\n",
      "batch 110: loss 0.399130\n",
      "batch 111: loss 0.507932\n",
      "batch 112: loss 0.403676\n",
      "batch 113: loss 0.464171\n",
      "batch 114: loss 0.456673\n",
      "batch 115: loss 0.434254\n",
      "batch 116: loss 0.645310\n",
      "batch 117: loss 0.289569\n",
      "batch 118: loss 0.320448\n",
      "batch 119: loss 0.335894\n",
      "batch 120: loss 0.190130\n",
      "batch 121: loss 0.601099\n",
      "batch 122: loss 0.513551\n",
      "batch 123: loss 0.443448\n",
      "batch 124: loss 0.376867\n",
      "batch 125: loss 0.425498\n",
      "batch 126: loss 0.359255\n",
      "batch 127: loss 0.416238\n",
      "batch 128: loss 0.451309\n",
      "batch 129: loss 0.448307\n",
      "batch 130: loss 0.595024\n",
      "batch 131: loss 0.452595\n",
      "batch 132: loss 0.529518\n",
      "batch 133: loss 0.459315\n",
      "batch 134: loss 0.295062\n",
      "batch 135: loss 0.395023\n",
      "batch 136: loss 0.353039\n",
      "batch 137: loss 0.286702\n",
      "batch 138: loss 0.445700\n",
      "batch 139: loss 0.420580\n",
      "batch 140: loss 0.394838\n",
      "batch 141: loss 0.422034\n",
      "batch 142: loss 0.357224\n",
      "batch 143: loss 0.455904\n",
      "batch 144: loss 0.503556\n",
      "batch 145: loss 0.538292\n",
      "batch 146: loss 0.440850\n",
      "batch 147: loss 0.397737\n",
      "batch 148: loss 0.311417\n",
      "batch 149: loss 0.337859\n",
      "batch 150: loss 0.325248\n",
      "batch 151: loss 0.346653\n",
      "batch 152: loss 0.388063\n",
      "batch 153: loss 0.442101\n",
      "batch 154: loss 0.461439\n",
      "batch 155: loss 0.532614\n",
      "batch 156: loss 0.318059\n",
      "batch 157: loss 0.380178\n",
      "batch 158: loss 0.356751\n",
      "batch 159: loss 0.404056\n",
      "batch 160: loss 0.395997\n",
      "batch 161: loss 0.623044\n",
      "batch 162: loss 0.366523\n",
      "batch 163: loss 0.273786\n",
      "batch 164: loss 0.399338\n",
      "batch 165: loss 0.199160\n",
      "batch 166: loss 0.316487\n",
      "batch 167: loss 0.286997\n",
      "batch 168: loss 0.198980\n",
      "batch 169: loss 0.479535\n",
      "batch 170: loss 0.565021\n",
      "batch 171: loss 0.507466\n",
      "batch 172: loss 0.249711\n",
      "batch 173: loss 0.373484\n",
      "batch 174: loss 0.376673\n",
      "batch 175: loss 0.253150\n",
      "batch 176: loss 0.353454\n",
      "batch 177: loss 0.217090\n",
      "batch 178: loss 0.386448\n",
      "batch 179: loss 0.396114\n",
      "batch 180: loss 0.366973\n",
      "batch 181: loss 0.338620\n",
      "batch 182: loss 0.284394\n",
      "batch 183: loss 0.302488\n",
      "batch 184: loss 0.374576\n",
      "batch 185: loss 0.274542\n",
      "batch 186: loss 0.209661\n",
      "batch 187: loss 0.375400\n",
      "batch 188: loss 0.359534\n",
      "batch 189: loss 0.498058\n",
      "batch 190: loss 0.369099\n",
      "batch 191: loss 0.162737\n",
      "batch 192: loss 0.693580\n",
      "batch 193: loss 0.279623\n",
      "batch 194: loss 0.284622\n",
      "batch 195: loss 0.244616\n",
      "batch 196: loss 0.732970\n",
      "batch 197: loss 0.350293\n",
      "batch 198: loss 0.510529\n",
      "batch 199: loss 0.415137\n",
      "batch 200: loss 0.374957\n",
      "batch 201: loss 0.549183\n",
      "batch 202: loss 0.288907\n",
      "batch 203: loss 0.519196\n",
      "batch 204: loss 0.487934\n",
      "batch 205: loss 0.283655\n",
      "batch 206: loss 0.436107\n",
      "batch 207: loss 0.289804\n",
      "batch 208: loss 0.279254\n",
      "batch 209: loss 0.464312\n",
      "batch 210: loss 0.342162\n",
      "batch 211: loss 0.159102\n",
      "batch 212: loss 0.297352\n",
      "batch 213: loss 0.282037\n",
      "batch 214: loss 0.457074\n",
      "batch 215: loss 0.302252\n",
      "batch 216: loss 0.339940\n",
      "batch 217: loss 0.302602\n",
      "batch 218: loss 0.437788\n",
      "batch 219: loss 0.421712\n",
      "batch 220: loss 0.544921\n",
      "batch 221: loss 0.484675\n",
      "batch 222: loss 0.235647\n",
      "batch 223: loss 0.347144\n",
      "batch 224: loss 0.490056\n",
      "batch 225: loss 0.313746\n",
      "batch 226: loss 0.306117\n",
      "batch 227: loss 0.344779\n",
      "batch 228: loss 0.305851\n",
      "batch 229: loss 0.396660\n",
      "batch 230: loss 0.221537\n",
      "batch 231: loss 0.275551\n",
      "batch 232: loss 0.238352\n",
      "batch 233: loss 0.349959\n",
      "batch 234: loss 0.298941\n",
      "batch 235: loss 0.267577\n",
      "batch 236: loss 0.378898\n",
      "batch 237: loss 0.439134\n",
      "batch 238: loss 0.492305\n",
      "batch 239: loss 0.420499\n",
      "batch 240: loss 0.397856\n",
      "batch 241: loss 0.192714\n",
      "batch 242: loss 0.193994\n",
      "batch 243: loss 0.159022\n",
      "batch 244: loss 0.304466\n",
      "batch 245: loss 0.207902\n",
      "batch 246: loss 0.276255\n",
      "batch 247: loss 0.499789\n",
      "batch 248: loss 0.414215\n",
      "batch 249: loss 0.390300\n",
      "batch 250: loss 0.318375\n",
      "batch 251: loss 0.307058\n",
      "batch 252: loss 0.232747\n",
      "batch 253: loss 0.257920\n",
      "batch 254: loss 0.322988\n",
      "batch 255: loss 0.493352\n",
      "batch 256: loss 0.201518\n",
      "batch 257: loss 0.210571\n",
      "batch 258: loss 0.263801\n",
      "batch 259: loss 0.240439\n",
      "batch 260: loss 0.191941\n",
      "batch 261: loss 0.339699\n",
      "batch 262: loss 0.296519\n",
      "batch 263: loss 0.167787\n",
      "batch 264: loss 0.203205\n",
      "batch 265: loss 0.361040\n",
      "batch 266: loss 0.251753\n",
      "batch 267: loss 0.298666\n",
      "batch 268: loss 0.224177\n",
      "batch 269: loss 0.222159\n",
      "batch 270: loss 0.212035\n",
      "batch 271: loss 0.177242\n",
      "batch 272: loss 0.386403\n",
      "batch 273: loss 0.341370\n",
      "batch 274: loss 0.355659\n",
      "batch 275: loss 0.348893\n",
      "batch 276: loss 0.299877\n",
      "batch 277: loss 0.345610\n",
      "batch 278: loss 0.355401\n",
      "batch 279: loss 0.208400\n",
      "batch 280: loss 0.376052\n",
      "batch 281: loss 0.425505\n",
      "batch 282: loss 0.485184\n",
      "batch 283: loss 0.524739\n",
      "batch 284: loss 0.383821\n",
      "batch 285: loss 0.149561\n",
      "batch 286: loss 0.342876\n",
      "batch 287: loss 0.371364\n",
      "batch 288: loss 0.209675\n",
      "batch 289: loss 0.299347\n",
      "batch 290: loss 0.249280\n",
      "batch 291: loss 0.428571\n",
      "batch 292: loss 0.223105\n",
      "batch 293: loss 0.291947\n",
      "batch 294: loss 0.378533\n",
      "batch 295: loss 0.142669\n",
      "batch 296: loss 0.112581\n",
      "batch 297: loss 0.147338\n",
      "batch 298: loss 0.216014\n",
      "batch 299: loss 0.345853\n",
      "batch 300: loss 0.383802\n",
      "batch 301: loss 0.323009\n",
      "batch 302: loss 0.253502\n",
      "batch 303: loss 0.165190\n",
      "batch 304: loss 0.173356\n",
      "batch 305: loss 0.320753\n",
      "batch 306: loss 0.172877\n",
      "batch 307: loss 0.239926\n",
      "batch 308: loss 0.264758\n",
      "batch 309: loss 0.544931\n",
      "batch 310: loss 0.188028\n",
      "batch 311: loss 0.485537\n",
      "batch 312: loss 0.242507\n",
      "batch 313: loss 0.338903\n",
      "batch 314: loss 0.200388\n",
      "batch 315: loss 0.259142\n",
      "batch 316: loss 0.346953\n",
      "batch 317: loss 0.341265\n",
      "batch 318: loss 0.170186\n",
      "batch 319: loss 0.270572\n",
      "batch 320: loss 0.384694\n",
      "batch 321: loss 0.299003\n",
      "batch 322: loss 0.236339\n",
      "batch 323: loss 0.264896\n",
      "batch 324: loss 0.315988\n",
      "batch 325: loss 0.361822\n",
      "batch 326: loss 0.113153\n",
      "batch 327: loss 0.232339\n",
      "batch 328: loss 0.197522\n",
      "batch 329: loss 0.441040\n",
      "batch 330: loss 0.383995\n",
      "batch 331: loss 0.266915\n",
      "batch 332: loss 0.225270\n",
      "batch 333: loss 0.221904\n",
      "batch 334: loss 0.335038\n",
      "batch 335: loss 0.409949\n",
      "batch 336: loss 0.468235\n",
      "batch 337: loss 0.425525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 338: loss 0.293027\n",
      "batch 339: loss 0.337338\n",
      "batch 340: loss 0.320226\n",
      "batch 341: loss 0.255111\n",
      "batch 342: loss 0.306542\n",
      "batch 343: loss 0.136120\n",
      "batch 344: loss 0.164811\n",
      "batch 345: loss 0.241897\n",
      "batch 346: loss 0.283643\n",
      "batch 347: loss 0.300994\n",
      "batch 348: loss 0.444417\n",
      "batch 349: loss 0.405856\n",
      "batch 350: loss 0.171216\n",
      "batch 351: loss 0.324004\n",
      "batch 352: loss 0.237332\n",
      "batch 353: loss 0.163725\n",
      "batch 354: loss 0.218331\n",
      "batch 355: loss 0.229987\n",
      "batch 356: loss 0.265262\n",
      "batch 357: loss 0.248960\n",
      "batch 358: loss 0.388207\n",
      "batch 359: loss 0.243178\n",
      "batch 360: loss 0.338059\n",
      "batch 361: loss 0.318350\n",
      "batch 362: loss 0.302398\n",
      "batch 363: loss 0.294826\n",
      "batch 364: loss 0.535214\n",
      "batch 365: loss 0.115851\n",
      "batch 366: loss 0.231156\n",
      "batch 367: loss 0.513939\n",
      "batch 368: loss 0.281440\n",
      "batch 369: loss 0.186867\n",
      "batch 370: loss 0.212767\n",
      "batch 371: loss 0.165725\n",
      "batch 372: loss 0.407267\n",
      "batch 373: loss 0.378571\n",
      "batch 374: loss 0.315684\n",
      "batch 375: loss 0.197395\n",
      "batch 376: loss 0.406554\n",
      "batch 377: loss 0.371423\n",
      "batch 378: loss 0.269943\n",
      "batch 379: loss 0.187415\n",
      "batch 380: loss 0.278969\n",
      "batch 381: loss 0.299607\n",
      "batch 382: loss 0.212690\n",
      "batch 383: loss 0.227002\n",
      "batch 384: loss 0.132195\n",
      "batch 385: loss 0.291593\n",
      "batch 386: loss 0.228277\n",
      "batch 387: loss 0.213707\n",
      "batch 388: loss 0.321827\n",
      "batch 389: loss 0.325586\n",
      "batch 390: loss 0.406284\n",
      "batch 391: loss 0.204837\n",
      "batch 392: loss 0.319000\n",
      "batch 393: loss 0.192191\n",
      "batch 394: loss 0.349015\n",
      "batch 395: loss 0.262923\n",
      "batch 396: loss 0.240387\n",
      "batch 397: loss 0.498517\n",
      "batch 398: loss 0.732012\n",
      "batch 399: loss 0.317901\n",
      "batch 400: loss 0.287353\n",
      "batch 401: loss 0.363932\n",
      "batch 402: loss 0.218146\n",
      "batch 403: loss 0.256016\n",
      "batch 404: loss 0.360936\n",
      "batch 405: loss 0.186066\n",
      "batch 406: loss 0.313726\n",
      "batch 407: loss 0.269783\n",
      "batch 408: loss 0.194000\n",
      "batch 409: loss 0.239453\n",
      "batch 410: loss 0.266666\n",
      "batch 411: loss 0.209853\n",
      "batch 412: loss 0.368935\n",
      "batch 413: loss 0.305204\n",
      "batch 414: loss 0.322367\n",
      "batch 415: loss 0.373665\n",
      "batch 416: loss 0.489960\n",
      "batch 417: loss 0.248502\n",
      "batch 418: loss 0.308029\n",
      "batch 419: loss 0.219570\n",
      "batch 420: loss 0.086646\n",
      "batch 421: loss 0.324656\n",
      "batch 422: loss 0.295583\n",
      "batch 423: loss 0.154382\n",
      "batch 424: loss 0.216605\n",
      "batch 425: loss 0.592223\n",
      "batch 426: loss 0.303501\n",
      "batch 427: loss 0.458584\n",
      "batch 428: loss 0.203074\n",
      "batch 429: loss 0.121526\n",
      "batch 430: loss 0.385871\n",
      "batch 431: loss 0.092988\n",
      "batch 432: loss 0.236546\n",
      "batch 433: loss 0.271507\n",
      "batch 434: loss 0.338803\n",
      "batch 435: loss 0.185522\n",
      "batch 436: loss 0.239537\n",
      "batch 437: loss 0.496614\n",
      "batch 438: loss 0.163719\n",
      "batch 439: loss 0.264569\n",
      "batch 440: loss 0.175603\n",
      "batch 441: loss 0.242741\n",
      "batch 442: loss 0.118864\n",
      "batch 443: loss 0.352308\n",
      "batch 444: loss 0.466161\n",
      "batch 445: loss 0.434188\n",
      "batch 446: loss 0.226818\n",
      "batch 447: loss 0.276384\n",
      "batch 448: loss 0.239910\n",
      "batch 449: loss 0.228435\n",
      "batch 450: loss 0.284901\n",
      "batch 451: loss 0.276280\n",
      "batch 452: loss 0.223666\n",
      "batch 453: loss 0.250160\n",
      "batch 454: loss 0.536863\n",
      "batch 455: loss 0.349111\n",
      "batch 456: loss 0.114142\n",
      "batch 457: loss 0.390078\n",
      "batch 458: loss 0.368226\n",
      "batch 459: loss 0.277662\n",
      "batch 460: loss 0.175244\n",
      "batch 461: loss 0.169383\n",
      "batch 462: loss 0.141340\n",
      "batch 463: loss 0.188364\n",
      "batch 464: loss 0.237826\n",
      "batch 465: loss 0.175852\n",
      "batch 466: loss 0.256245\n",
      "batch 467: loss 0.301458\n",
      "batch 468: loss 0.260579\n",
      "batch 469: loss 0.217666\n",
      "batch 470: loss 0.155011\n",
      "batch 471: loss 0.181580\n",
      "batch 472: loss 0.263150\n",
      "batch 473: loss 0.161357\n",
      "batch 474: loss 0.216468\n",
      "batch 475: loss 0.244428\n",
      "batch 476: loss 0.353601\n",
      "batch 477: loss 0.137757\n",
      "batch 478: loss 0.241834\n",
      "batch 479: loss 0.236005\n",
      "batch 480: loss 0.118285\n",
      "batch 481: loss 0.327052\n",
      "batch 482: loss 0.310689\n",
      "batch 483: loss 0.146880\n",
      "batch 484: loss 0.137444\n",
      "batch 485: loss 0.273153\n",
      "batch 486: loss 0.442749\n",
      "batch 487: loss 0.269304\n",
      "batch 488: loss 0.241339\n",
      "batch 489: loss 0.271843\n",
      "batch 490: loss 0.216542\n",
      "batch 491: loss 0.312191\n",
      "batch 492: loss 0.311449\n",
      "batch 493: loss 0.290780\n",
      "batch 494: loss 0.264767\n",
      "batch 495: loss 0.309081\n",
      "batch 496: loss 0.035740\n",
      "batch 497: loss 0.243363\n",
      "batch 498: loss 0.252894\n",
      "batch 499: loss 0.353248\n",
      "batch 500: loss 0.256538\n",
      "batch 501: loss 0.349060\n",
      "batch 502: loss 0.160003\n",
      "batch 503: loss 0.312848\n",
      "batch 504: loss 0.424313\n",
      "batch 505: loss 0.149029\n",
      "batch 506: loss 0.184857\n",
      "batch 507: loss 0.282131\n",
      "batch 508: loss 0.149756\n",
      "batch 509: loss 0.235767\n",
      "batch 510: loss 0.286901\n",
      "batch 511: loss 0.190504\n",
      "batch 512: loss 0.236965\n",
      "batch 513: loss 0.135412\n",
      "batch 514: loss 0.377447\n",
      "batch 515: loss 0.183257\n",
      "batch 516: loss 0.182259\n",
      "batch 517: loss 0.365441\n",
      "batch 518: loss 0.213355\n",
      "batch 519: loss 0.228845\n",
      "batch 520: loss 0.500878\n",
      "batch 521: loss 0.182649\n",
      "batch 522: loss 0.272168\n",
      "batch 523: loss 0.299579\n",
      "batch 524: loss 0.142919\n",
      "batch 525: loss 0.190527\n",
      "batch 526: loss 0.333836\n",
      "batch 527: loss 0.188885\n",
      "batch 528: loss 0.195767\n",
      "batch 529: loss 0.479682\n",
      "batch 530: loss 0.204994\n",
      "batch 531: loss 0.173497\n",
      "batch 532: loss 0.215126\n",
      "batch 533: loss 0.194356\n",
      "batch 534: loss 0.309210\n",
      "batch 535: loss 0.268225\n",
      "batch 536: loss 0.157088\n",
      "batch 537: loss 0.190148\n",
      "batch 538: loss 0.215871\n",
      "batch 539: loss 0.370485\n",
      "batch 540: loss 0.145875\n",
      "batch 541: loss 0.155818\n",
      "batch 542: loss 0.167807\n",
      "batch 543: loss 0.210189\n",
      "batch 544: loss 0.099647\n",
      "batch 545: loss 0.096600\n",
      "batch 546: loss 0.270520\n",
      "batch 547: loss 0.113464\n",
      "batch 548: loss 0.247529\n",
      "batch 549: loss 0.191760\n",
      "batch 550: loss 0.677883\n",
      "batch 551: loss 0.316603\n",
      "batch 552: loss 0.250151\n",
      "batch 553: loss 0.174121\n",
      "batch 554: loss 0.062429\n",
      "batch 555: loss 0.247581\n",
      "batch 556: loss 0.267231\n",
      "batch 557: loss 0.274931\n",
      "batch 558: loss 0.242276\n",
      "batch 559: loss 0.148186\n",
      "batch 560: loss 0.169280\n",
      "batch 561: loss 0.315076\n",
      "batch 562: loss 0.197257\n",
      "batch 563: loss 0.267831\n",
      "batch 564: loss 0.104077\n",
      "batch 565: loss 0.384159\n",
      "batch 566: loss 0.193287\n",
      "batch 567: loss 0.303188\n",
      "batch 568: loss 0.178547\n",
      "batch 569: loss 0.242459\n",
      "batch 570: loss 0.147732\n",
      "batch 571: loss 0.097120\n",
      "batch 572: loss 0.284035\n",
      "batch 573: loss 0.237064\n",
      "batch 574: loss 0.107636\n",
      "batch 575: loss 0.133965\n",
      "batch 576: loss 0.546330\n",
      "batch 577: loss 0.208466\n",
      "batch 578: loss 0.078790\n",
      "batch 579: loss 0.291811\n",
      "batch 580: loss 0.095387\n",
      "batch 581: loss 0.399754\n",
      "batch 582: loss 0.396845\n",
      "batch 583: loss 0.409515\n",
      "batch 584: loss 0.439347\n",
      "batch 585: loss 0.363008\n",
      "batch 586: loss 0.314765\n",
      "batch 587: loss 0.334566\n",
      "batch 588: loss 0.172272\n",
      "batch 589: loss 0.497025\n",
      "batch 590: loss 0.118046\n",
      "batch 591: loss 0.264303\n",
      "batch 592: loss 0.210104\n",
      "batch 593: loss 0.378245\n",
      "batch 594: loss 0.116544\n",
      "batch 595: loss 0.231203\n",
      "batch 596: loss 0.145931\n",
      "batch 597: loss 0.186603\n",
      "batch 598: loss 0.315058\n",
      "batch 599: loss 0.205537\n",
      "batch 600: loss 0.219003\n",
      "batch 601: loss 0.218824\n",
      "batch 602: loss 0.295145\n",
      "batch 603: loss 0.225304\n",
      "batch 604: loss 0.269338\n",
      "batch 605: loss 0.142936\n",
      "batch 606: loss 0.433224\n",
      "batch 607: loss 0.335360\n",
      "batch 608: loss 0.358011\n",
      "batch 609: loss 0.138290\n",
      "batch 610: loss 0.220624\n",
      "batch 611: loss 0.553901\n",
      "batch 612: loss 0.166145\n",
      "batch 613: loss 0.277198\n",
      "batch 614: loss 0.078742\n",
      "batch 615: loss 0.140635\n",
      "batch 616: loss 0.176817\n",
      "batch 617: loss 0.228031\n",
      "batch 618: loss 0.245809\n",
      "batch 619: loss 0.455517\n",
      "batch 620: loss 0.190022\n",
      "batch 621: loss 0.131813\n",
      "batch 622: loss 0.461723\n",
      "batch 623: loss 0.408967\n",
      "batch 624: loss 0.204441\n",
      "batch 625: loss 0.145014\n",
      "batch 626: loss 0.175706\n",
      "batch 627: loss 0.228098\n",
      "batch 628: loss 0.372981\n",
      "batch 629: loss 0.245845\n",
      "batch 630: loss 0.462878\n",
      "batch 631: loss 0.238033\n",
      "batch 632: loss 0.214961\n",
      "batch 633: loss 0.219330\n",
      "batch 634: loss 0.256303\n",
      "batch 635: loss 0.156763\n",
      "batch 636: loss 0.351224\n",
      "batch 637: loss 0.267960\n",
      "batch 638: loss 0.113867\n",
      "batch 639: loss 0.160489\n",
      "batch 640: loss 0.302103\n",
      "batch 641: loss 0.259292\n",
      "batch 642: loss 0.114304\n",
      "batch 643: loss 0.171705\n",
      "batch 644: loss 0.139869\n",
      "batch 645: loss 0.088869\n",
      "batch 646: loss 0.262587\n",
      "batch 647: loss 0.140783\n",
      "batch 648: loss 0.251417\n",
      "batch 649: loss 0.155704\n",
      "batch 650: loss 0.253904\n",
      "batch 651: loss 0.131021\n",
      "batch 652: loss 0.154043\n",
      "batch 653: loss 0.162291\n",
      "batch 654: loss 0.327576\n",
      "batch 655: loss 0.116537\n",
      "batch 656: loss 0.182389\n",
      "batch 657: loss 0.251585\n",
      "batch 658: loss 0.253406\n",
      "batch 659: loss 0.164585\n",
      "batch 660: loss 0.221039\n",
      "batch 661: loss 0.065460\n",
      "batch 662: loss 0.294759\n",
      "batch 663: loss 0.134923\n",
      "batch 664: loss 0.170597\n",
      "batch 665: loss 0.294347\n",
      "batch 666: loss 0.394742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 667: loss 0.095009\n",
      "batch 668: loss 0.239383\n",
      "batch 669: loss 0.110938\n",
      "batch 670: loss 0.163227\n",
      "batch 671: loss 0.288147\n",
      "batch 672: loss 0.355464\n",
      "batch 673: loss 0.725920\n",
      "batch 674: loss 0.519828\n",
      "batch 675: loss 0.142860\n",
      "batch 676: loss 0.213494\n",
      "batch 677: loss 0.113062\n",
      "batch 678: loss 0.284629\n",
      "batch 679: loss 0.190958\n",
      "batch 680: loss 0.170837\n",
      "batch 681: loss 0.289865\n",
      "batch 682: loss 0.067399\n",
      "batch 683: loss 0.045795\n",
      "batch 684: loss 0.167481\n",
      "batch 685: loss 0.418679\n",
      "batch 686: loss 0.145204\n",
      "batch 687: loss 0.155196\n",
      "batch 688: loss 0.093097\n",
      "batch 689: loss 0.321463\n",
      "batch 690: loss 0.213799\n",
      "batch 691: loss 0.323712\n",
      "batch 692: loss 0.281795\n",
      "batch 693: loss 0.295149\n",
      "batch 694: loss 0.147488\n",
      "batch 695: loss 0.165607\n",
      "batch 696: loss 0.211938\n",
      "batch 697: loss 0.100596\n",
      "batch 698: loss 0.200391\n",
      "batch 699: loss 0.139096\n",
      "batch 700: loss 0.161488\n",
      "batch 701: loss 0.109602\n",
      "batch 702: loss 0.388603\n",
      "batch 703: loss 0.455597\n",
      "batch 704: loss 0.273524\n",
      "batch 705: loss 0.329263\n",
      "batch 706: loss 0.074830\n",
      "batch 707: loss 0.235020\n",
      "batch 708: loss 0.247702\n",
      "batch 709: loss 0.144757\n",
      "batch 710: loss 0.159046\n",
      "batch 711: loss 0.218013\n",
      "batch 712: loss 0.214747\n",
      "batch 713: loss 0.207721\n",
      "batch 714: loss 0.125363\n",
      "batch 715: loss 0.191301\n",
      "batch 716: loss 0.388783\n",
      "batch 717: loss 0.336810\n",
      "batch 718: loss 0.256477\n",
      "batch 719: loss 0.253176\n",
      "batch 720: loss 0.306199\n",
      "batch 721: loss 0.207771\n",
      "batch 722: loss 0.096619\n",
      "batch 723: loss 0.330702\n",
      "batch 724: loss 0.204791\n",
      "batch 725: loss 0.219064\n",
      "batch 726: loss 0.256515\n",
      "batch 727: loss 0.179025\n",
      "batch 728: loss 0.232094\n",
      "batch 729: loss 0.381160\n",
      "batch 730: loss 0.499167\n",
      "batch 731: loss 0.097102\n",
      "batch 732: loss 0.116589\n",
      "batch 733: loss 0.257633\n",
      "batch 734: loss 0.310789\n",
      "batch 735: loss 0.186123\n",
      "batch 736: loss 0.311805\n",
      "batch 737: loss 0.167515\n",
      "batch 738: loss 0.125501\n",
      "batch 739: loss 0.429121\n",
      "batch 740: loss 0.219450\n",
      "batch 741: loss 0.197179\n",
      "batch 742: loss 0.080062\n",
      "batch 743: loss 0.290923\n",
      "batch 744: loss 0.151775\n",
      "batch 745: loss 0.084022\n",
      "batch 746: loss 0.144165\n",
      "batch 747: loss 0.140841\n",
      "batch 748: loss 0.180233\n",
      "batch 749: loss 0.161374\n",
      "batch 750: loss 0.413464\n",
      "batch 751: loss 0.158791\n",
      "batch 752: loss 0.065411\n",
      "batch 753: loss 0.089276\n",
      "batch 754: loss 0.211641\n",
      "batch 755: loss 0.197359\n",
      "batch 756: loss 0.321772\n",
      "batch 757: loss 0.142565\n",
      "batch 758: loss 0.186514\n",
      "batch 759: loss 0.195595\n",
      "batch 760: loss 0.096611\n",
      "batch 761: loss 0.161361\n",
      "batch 762: loss 0.350783\n",
      "batch 763: loss 0.169928\n",
      "batch 764: loss 0.323263\n",
      "batch 765: loss 0.330181\n",
      "batch 766: loss 0.093696\n",
      "batch 767: loss 0.150910\n",
      "batch 768: loss 0.110488\n",
      "batch 769: loss 0.142757\n",
      "batch 770: loss 0.296324\n",
      "batch 771: loss 0.079362\n",
      "batch 772: loss 0.124164\n",
      "batch 773: loss 0.241917\n",
      "batch 774: loss 0.173210\n",
      "batch 775: loss 0.171314\n",
      "batch 776: loss 0.230142\n",
      "batch 777: loss 0.084316\n",
      "batch 778: loss 0.142972\n",
      "batch 779: loss 0.135590\n",
      "batch 780: loss 0.203208\n",
      "batch 781: loss 0.108348\n",
      "batch 782: loss 0.162734\n",
      "batch 783: loss 0.196021\n",
      "batch 784: loss 0.169853\n",
      "batch 785: loss 0.151145\n",
      "batch 786: loss 0.299421\n",
      "batch 787: loss 0.153940\n",
      "batch 788: loss 0.175090\n",
      "batch 789: loss 0.256346\n",
      "batch 790: loss 0.211141\n",
      "batch 791: loss 0.222490\n",
      "batch 792: loss 0.226469\n",
      "batch 793: loss 0.087524\n",
      "batch 794: loss 0.350674\n",
      "batch 795: loss 0.198440\n",
      "batch 796: loss 0.154113\n",
      "batch 797: loss 0.362029\n",
      "batch 798: loss 0.122775\n",
      "batch 799: loss 0.278427\n",
      "batch 800: loss 0.231771\n",
      "batch 801: loss 0.176058\n",
      "batch 802: loss 0.157881\n",
      "batch 803: loss 0.473431\n",
      "batch 804: loss 0.187238\n",
      "batch 805: loss 0.289144\n",
      "batch 806: loss 0.100508\n",
      "batch 807: loss 0.082464\n",
      "batch 808: loss 0.148009\n",
      "batch 809: loss 0.270543\n",
      "batch 810: loss 0.080585\n",
      "batch 811: loss 0.201960\n",
      "batch 812: loss 0.229598\n",
      "batch 813: loss 0.166799\n",
      "batch 814: loss 0.315724\n",
      "batch 815: loss 0.259037\n",
      "batch 816: loss 0.057873\n",
      "batch 817: loss 0.132311\n",
      "batch 818: loss 0.294686\n",
      "batch 819: loss 0.109461\n",
      "batch 820: loss 0.250156\n",
      "batch 821: loss 0.199962\n",
      "batch 822: loss 0.340701\n",
      "batch 823: loss 0.380961\n",
      "batch 824: loss 0.135743\n",
      "batch 825: loss 0.306551\n",
      "batch 826: loss 0.049339\n",
      "batch 827: loss 0.207315\n",
      "batch 828: loss 0.143642\n",
      "batch 829: loss 0.200780\n",
      "batch 830: loss 0.134095\n",
      "batch 831: loss 0.174661\n",
      "batch 832: loss 0.175422\n",
      "batch 833: loss 0.541177\n",
      "batch 834: loss 0.197705\n",
      "batch 835: loss 0.235870\n",
      "batch 836: loss 0.265521\n",
      "batch 837: loss 0.259382\n",
      "batch 838: loss 0.195278\n",
      "batch 839: loss 0.177889\n",
      "batch 840: loss 0.264951\n",
      "batch 841: loss 0.271780\n",
      "batch 842: loss 0.195180\n",
      "batch 843: loss 0.297845\n",
      "batch 844: loss 0.452517\n",
      "batch 845: loss 0.032473\n",
      "batch 846: loss 0.439071\n",
      "batch 847: loss 0.138078\n",
      "batch 848: loss 0.122155\n",
      "batch 849: loss 0.533113\n",
      "batch 850: loss 0.211902\n",
      "batch 851: loss 0.061927\n",
      "batch 852: loss 0.244856\n",
      "batch 853: loss 0.098328\n",
      "batch 854: loss 0.207437\n",
      "batch 855: loss 0.128316\n",
      "batch 856: loss 0.245702\n",
      "batch 857: loss 0.120125\n",
      "batch 858: loss 0.353796\n",
      "batch 859: loss 0.214871\n",
      "batch 860: loss 0.186784\n",
      "batch 861: loss 0.261465\n",
      "batch 862: loss 0.183248\n",
      "batch 863: loss 0.241167\n",
      "batch 864: loss 0.270874\n",
      "batch 865: loss 0.165470\n",
      "batch 866: loss 0.187746\n",
      "batch 867: loss 0.538198\n",
      "batch 868: loss 0.283261\n",
      "batch 869: loss 0.114752\n",
      "batch 870: loss 0.127257\n",
      "batch 871: loss 0.130672\n",
      "batch 872: loss 0.232111\n",
      "batch 873: loss 0.173103\n",
      "batch 874: loss 0.182294\n",
      "batch 875: loss 0.542040\n",
      "batch 876: loss 0.081866\n",
      "batch 877: loss 0.171592\n",
      "batch 878: loss 0.177433\n",
      "batch 879: loss 0.263124\n",
      "batch 880: loss 0.104738\n",
      "batch 881: loss 0.046359\n",
      "batch 882: loss 0.174728\n",
      "batch 883: loss 0.290755\n",
      "batch 884: loss 0.187036\n",
      "batch 885: loss 0.147976\n",
      "batch 886: loss 0.266215\n",
      "batch 887: loss 0.217503\n",
      "batch 888: loss 0.259556\n",
      "batch 889: loss 0.067253\n",
      "batch 890: loss 0.318111\n",
      "batch 891: loss 0.355881\n",
      "batch 892: loss 0.163863\n",
      "batch 893: loss 0.228760\n",
      "batch 894: loss 0.144261\n",
      "batch 895: loss 0.214282\n",
      "batch 896: loss 0.121786\n",
      "batch 897: loss 0.049677\n",
      "batch 898: loss 0.241016\n",
      "batch 899: loss 0.165952\n",
      "batch 900: loss 0.591759\n",
      "batch 901: loss 0.253249\n",
      "batch 902: loss 0.221891\n",
      "batch 903: loss 0.316063\n",
      "batch 904: loss 0.405919\n",
      "batch 905: loss 0.304283\n",
      "batch 906: loss 0.226286\n",
      "batch 907: loss 0.147388\n",
      "batch 908: loss 0.338875\n",
      "batch 909: loss 0.283406\n",
      "batch 910: loss 0.207997\n",
      "batch 911: loss 0.058497\n",
      "batch 912: loss 0.243356\n",
      "batch 913: loss 0.214267\n",
      "batch 914: loss 0.228022\n",
      "batch 915: loss 0.197464\n",
      "batch 916: loss 0.116638\n",
      "batch 917: loss 0.177528\n",
      "batch 918: loss 0.304807\n",
      "batch 919: loss 0.538827\n",
      "batch 920: loss 0.165177\n",
      "batch 921: loss 0.171793\n",
      "batch 922: loss 0.087326\n",
      "batch 923: loss 0.307325\n",
      "batch 924: loss 0.188700\n",
      "batch 925: loss 0.372042\n",
      "batch 926: loss 0.081537\n",
      "batch 927: loss 0.160845\n",
      "batch 928: loss 0.401942\n",
      "batch 929: loss 0.108127\n",
      "batch 930: loss 0.270357\n",
      "batch 931: loss 0.245116\n",
      "batch 932: loss 0.265622\n",
      "batch 933: loss 0.388673\n",
      "batch 934: loss 0.189179\n",
      "batch 935: loss 0.072816\n",
      "batch 936: loss 0.195796\n",
      "batch 937: loss 0.131945\n",
      "batch 938: loss 0.245271\n",
      "batch 939: loss 0.221651\n",
      "batch 940: loss 0.078419\n",
      "batch 941: loss 0.086939\n",
      "batch 942: loss 0.355800\n",
      "batch 943: loss 0.264686\n",
      "batch 944: loss 0.363585\n",
      "batch 945: loss 0.209941\n",
      "batch 946: loss 0.227280\n",
      "batch 947: loss 0.063881\n",
      "batch 948: loss 0.283871\n",
      "batch 949: loss 0.184504\n",
      "batch 950: loss 0.075761\n",
      "batch 951: loss 0.122031\n",
      "batch 952: loss 0.099115\n",
      "batch 953: loss 0.450258\n",
      "batch 954: loss 0.212284\n",
      "batch 955: loss 0.063029\n",
      "batch 956: loss 0.374622\n",
      "batch 957: loss 0.161610\n",
      "batch 958: loss 0.202048\n",
      "batch 959: loss 0.322143\n",
      "batch 960: loss 0.131638\n",
      "batch 961: loss 0.103364\n",
      "batch 962: loss 0.078271\n",
      "batch 963: loss 0.234900\n",
      "batch 964: loss 0.265316\n",
      "batch 965: loss 0.117946\n",
      "batch 966: loss 0.228642\n",
      "batch 967: loss 0.159739\n",
      "batch 968: loss 0.197057\n",
      "batch 969: loss 0.289212\n",
      "batch 970: loss 0.137382\n",
      "batch 971: loss 0.118670\n",
      "batch 972: loss 0.124259\n",
      "batch 973: loss 0.142156\n",
      "batch 974: loss 0.326356\n",
      "batch 975: loss 0.114046\n",
      "batch 976: loss 0.240429\n",
      "batch 977: loss 0.113714\n",
      "batch 978: loss 0.229716\n",
      "batch 979: loss 0.151213\n",
      "batch 980: loss 0.116252\n",
      "batch 981: loss 0.059892\n",
      "batch 982: loss 0.177055\n",
      "batch 983: loss 0.061613\n",
      "batch 984: loss 0.331179\n",
      "batch 985: loss 0.204951\n",
      "batch 986: loss 0.185354\n",
      "batch 987: loss 0.087890\n",
      "batch 988: loss 0.051867\n",
      "batch 989: loss 0.087720\n",
      "batch 990: loss 0.101428\n",
      "batch 991: loss 0.157526\n",
      "batch 992: loss 0.090822\n",
      "batch 993: loss 0.204693\n",
      "batch 994: loss 0.204628\n",
      "batch 995: loss 0.226664\n",
      "batch 996: loss 0.093387\n",
      "batch 997: loss 0.232747\n",
      "batch 998: loss 0.449789\n",
      "batch 999: loss 0.314394\n",
      "batch 1000: loss 0.184428\n",
      "batch 1001: loss 0.184033\n",
      "batch 1002: loss 0.323501\n",
      "batch 1003: loss 0.077278\n",
      "batch 1004: loss 0.117566\n",
      "batch 1005: loss 0.351874\n",
      "batch 1006: loss 0.074610\n",
      "batch 1007: loss 0.298259\n",
      "batch 1008: loss 0.211019\n",
      "batch 1009: loss 0.178150\n",
      "batch 1010: loss 0.145597\n",
      "batch 1011: loss 0.208926\n",
      "batch 1012: loss 0.171214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1013: loss 0.227252\n",
      "batch 1014: loss 0.212458\n",
      "batch 1015: loss 0.175069\n",
      "batch 1016: loss 0.303141\n",
      "batch 1017: loss 0.101159\n",
      "batch 1018: loss 0.027033\n",
      "batch 1019: loss 0.127897\n",
      "batch 1020: loss 0.162528\n",
      "batch 1021: loss 0.227250\n",
      "batch 1022: loss 0.299529\n",
      "batch 1023: loss 0.080822\n",
      "batch 1024: loss 0.078067\n",
      "batch 1025: loss 0.141415\n",
      "batch 1026: loss 0.072861\n",
      "batch 1027: loss 0.042950\n",
      "batch 1028: loss 0.097188\n",
      "batch 1029: loss 0.134337\n",
      "batch 1030: loss 0.148465\n",
      "batch 1031: loss 0.217348\n",
      "batch 1032: loss 0.071166\n",
      "batch 1033: loss 0.242039\n",
      "batch 1034: loss 0.166021\n",
      "batch 1035: loss 0.305340\n",
      "batch 1036: loss 0.313694\n",
      "batch 1037: loss 0.182614\n",
      "batch 1038: loss 0.141579\n",
      "batch 1039: loss 0.416232\n",
      "batch 1040: loss 0.242914\n",
      "batch 1041: loss 0.279742\n",
      "batch 1042: loss 0.131496\n",
      "batch 1043: loss 0.066605\n",
      "batch 1044: loss 0.117856\n",
      "batch 1045: loss 0.434851\n",
      "batch 1046: loss 0.137880\n",
      "batch 1047: loss 0.142020\n",
      "batch 1048: loss 0.071676\n",
      "batch 1049: loss 0.181042\n",
      "batch 1050: loss 0.133184\n",
      "batch 1051: loss 0.192282\n",
      "batch 1052: loss 0.159827\n",
      "batch 1053: loss 0.202967\n",
      "batch 1054: loss 0.189300\n",
      "batch 1055: loss 0.115392\n",
      "batch 1056: loss 0.467962\n",
      "batch 1057: loss 0.103706\n",
      "batch 1058: loss 0.343916\n",
      "batch 1059: loss 0.144036\n",
      "batch 1060: loss 0.216264\n",
      "batch 1061: loss 0.282438\n",
      "batch 1062: loss 0.263235\n",
      "batch 1063: loss 0.164162\n",
      "batch 1064: loss 0.195897\n",
      "batch 1065: loss 0.294735\n",
      "batch 1066: loss 0.217949\n",
      "batch 1067: loss 0.276646\n",
      "batch 1068: loss 0.184742\n",
      "batch 1069: loss 0.279238\n",
      "batch 1070: loss 0.343475\n",
      "batch 1071: loss 0.147567\n",
      "batch 1072: loss 0.242852\n",
      "batch 1073: loss 0.116436\n",
      "batch 1074: loss 0.108588\n",
      "batch 1075: loss 0.110707\n",
      "batch 1076: loss 0.189213\n",
      "batch 1077: loss 0.069994\n",
      "batch 1078: loss 0.286756\n",
      "batch 1079: loss 0.141255\n",
      "batch 1080: loss 0.120686\n",
      "batch 1081: loss 0.206152\n",
      "batch 1082: loss 0.218263\n",
      "batch 1083: loss 0.117055\n",
      "batch 1084: loss 0.075893\n",
      "batch 1085: loss 0.216958\n",
      "batch 1086: loss 0.134484\n",
      "batch 1087: loss 0.124986\n",
      "batch 1088: loss 0.269019\n",
      "batch 1089: loss 0.081070\n",
      "batch 1090: loss 0.099589\n",
      "batch 1091: loss 0.070381\n",
      "batch 1092: loss 0.346526\n",
      "batch 1093: loss 0.117069\n",
      "batch 1094: loss 0.204951\n",
      "batch 1095: loss 0.164191\n",
      "batch 1096: loss 0.186081\n",
      "batch 1097: loss 0.217344\n",
      "batch 1098: loss 0.123525\n",
      "batch 1099: loss 0.062650\n",
      "batch 1100: loss 0.128671\n",
      "batch 1101: loss 0.137248\n",
      "batch 1102: loss 0.109099\n",
      "batch 1103: loss 0.216807\n",
      "batch 1104: loss 0.095338\n",
      "batch 1105: loss 0.055569\n",
      "batch 1106: loss 0.201675\n",
      "batch 1107: loss 0.121798\n",
      "batch 1108: loss 0.261036\n",
      "batch 1109: loss 0.160638\n",
      "batch 1110: loss 0.073821\n",
      "batch 1111: loss 0.116806\n",
      "batch 1112: loss 0.054647\n",
      "batch 1113: loss 0.165908\n",
      "batch 1114: loss 0.162120\n",
      "batch 1115: loss 0.188277\n",
      "batch 1116: loss 0.189466\n",
      "batch 1117: loss 0.288045\n",
      "batch 1118: loss 0.078352\n",
      "batch 1119: loss 0.191007\n",
      "batch 1120: loss 0.346976\n",
      "batch 1121: loss 0.059240\n",
      "batch 1122: loss 0.175568\n",
      "batch 1123: loss 0.193703\n",
      "batch 1124: loss 0.168355\n",
      "batch 1125: loss 0.186090\n",
      "batch 1126: loss 0.384086\n",
      "batch 1127: loss 0.059283\n",
      "batch 1128: loss 0.084371\n",
      "batch 1129: loss 0.145250\n",
      "batch 1130: loss 0.079839\n",
      "batch 1131: loss 0.170208\n",
      "batch 1132: loss 0.210005\n",
      "batch 1133: loss 0.133775\n",
      "batch 1134: loss 0.165063\n",
      "batch 1135: loss 0.198824\n",
      "batch 1136: loss 0.038802\n",
      "batch 1137: loss 0.083720\n",
      "batch 1138: loss 0.152166\n",
      "batch 1139: loss 0.087315\n",
      "batch 1140: loss 0.139206\n",
      "batch 1141: loss 0.084011\n",
      "batch 1142: loss 0.045122\n",
      "batch 1143: loss 0.254918\n",
      "batch 1144: loss 0.101771\n",
      "batch 1145: loss 0.113578\n",
      "batch 1146: loss 0.161383\n",
      "batch 1147: loss 0.031330\n",
      "batch 1148: loss 0.496186\n",
      "batch 1149: loss 0.205096\n",
      "batch 1150: loss 0.085689\n",
      "batch 1151: loss 0.452568\n",
      "batch 1152: loss 0.184583\n",
      "batch 1153: loss 0.152869\n",
      "batch 1154: loss 0.096852\n",
      "batch 1155: loss 0.247715\n",
      "batch 1156: loss 0.152105\n",
      "batch 1157: loss 0.137041\n",
      "batch 1158: loss 0.077514\n",
      "batch 1159: loss 0.202644\n",
      "batch 1160: loss 0.117212\n",
      "batch 1161: loss 0.134754\n",
      "batch 1162: loss 0.403027\n",
      "batch 1163: loss 0.119092\n",
      "batch 1164: loss 0.111556\n",
      "batch 1165: loss 0.110096\n",
      "batch 1166: loss 0.119563\n",
      "batch 1167: loss 0.206685\n",
      "batch 1168: loss 0.254272\n",
      "batch 1169: loss 0.163653\n",
      "batch 1170: loss 0.091542\n",
      "batch 1171: loss 0.201832\n",
      "batch 1172: loss 0.039272\n",
      "batch 1173: loss 0.193329\n",
      "batch 1174: loss 0.108649\n",
      "batch 1175: loss 0.095305\n",
      "batch 1176: loss 0.292744\n",
      "batch 1177: loss 0.067422\n",
      "batch 1178: loss 0.137186\n",
      "batch 1179: loss 0.078956\n",
      "batch 1180: loss 0.307058\n",
      "batch 1181: loss 0.098671\n",
      "batch 1182: loss 0.100025\n",
      "batch 1183: loss 0.214786\n",
      "batch 1184: loss 0.150412\n",
      "batch 1185: loss 0.154652\n",
      "batch 1186: loss 0.067846\n",
      "batch 1187: loss 0.149529\n",
      "batch 1188: loss 0.189619\n",
      "batch 1189: loss 0.057522\n",
      "batch 1190: loss 0.256316\n",
      "batch 1191: loss 0.202236\n",
      "batch 1192: loss 0.187303\n",
      "batch 1193: loss 0.106637\n",
      "batch 1194: loss 0.098170\n",
      "batch 1195: loss 0.201148\n",
      "batch 1196: loss 0.167046\n",
      "batch 1197: loss 0.058886\n",
      "batch 1198: loss 0.044983\n",
      "batch 1199: loss 0.263990\n",
      "batch 1200: loss 0.412502\n",
      "batch 1201: loss 0.062645\n",
      "batch 1202: loss 0.099530\n",
      "batch 1203: loss 0.134217\n",
      "batch 1204: loss 0.205024\n",
      "batch 1205: loss 0.074319\n",
      "batch 1206: loss 0.098122\n",
      "batch 1207: loss 0.078564\n",
      "batch 1208: loss 0.268574\n",
      "batch 1209: loss 0.184256\n",
      "batch 1210: loss 0.334825\n",
      "batch 1211: loss 0.064761\n",
      "batch 1212: loss 0.197810\n",
      "batch 1213: loss 0.197863\n",
      "batch 1214: loss 0.120737\n",
      "batch 1215: loss 0.244009\n",
      "batch 1216: loss 0.181483\n",
      "batch 1217: loss 0.099123\n",
      "batch 1218: loss 0.249621\n",
      "batch 1219: loss 0.308549\n",
      "batch 1220: loss 0.095279\n",
      "batch 1221: loss 0.176051\n",
      "batch 1222: loss 0.047449\n",
      "batch 1223: loss 0.103860\n",
      "batch 1224: loss 0.103998\n",
      "batch 1225: loss 0.333872\n",
      "batch 1226: loss 0.148604\n",
      "batch 1227: loss 0.076254\n",
      "batch 1228: loss 0.162581\n",
      "batch 1229: loss 0.070354\n",
      "batch 1230: loss 0.080567\n",
      "batch 1231: loss 0.317583\n",
      "batch 1232: loss 0.195121\n",
      "batch 1233: loss 0.487424\n",
      "batch 1234: loss 0.072209\n",
      "batch 1235: loss 0.210975\n",
      "batch 1236: loss 0.085486\n",
      "batch 1237: loss 0.204878\n",
      "batch 1238: loss 0.065028\n",
      "batch 1239: loss 0.159385\n",
      "batch 1240: loss 0.263512\n",
      "batch 1241: loss 0.178111\n",
      "batch 1242: loss 0.235079\n",
      "batch 1243: loss 0.509458\n",
      "batch 1244: loss 0.086075\n",
      "batch 1245: loss 0.090871\n",
      "batch 1246: loss 0.177139\n",
      "batch 1247: loss 0.100610\n",
      "batch 1248: loss 0.086224\n",
      "batch 1249: loss 0.205915\n",
      "batch 1250: loss 0.336997\n",
      "batch 1251: loss 0.225798\n",
      "batch 1252: loss 0.187876\n",
      "batch 1253: loss 0.238770\n",
      "batch 1254: loss 0.067500\n",
      "batch 1255: loss 0.201606\n",
      "batch 1256: loss 0.095245\n",
      "batch 1257: loss 0.150432\n",
      "batch 1258: loss 0.082572\n",
      "batch 1259: loss 0.199675\n",
      "batch 1260: loss 0.100776\n",
      "batch 1261: loss 0.037103\n",
      "batch 1262: loss 0.102046\n",
      "batch 1263: loss 0.166307\n",
      "batch 1264: loss 0.172276\n",
      "batch 1265: loss 0.221607\n",
      "batch 1266: loss 0.087484\n",
      "batch 1267: loss 0.233666\n",
      "batch 1268: loss 0.039741\n",
      "batch 1269: loss 0.200426\n",
      "batch 1270: loss 0.046290\n",
      "batch 1271: loss 0.179609\n",
      "batch 1272: loss 0.247248\n",
      "batch 1273: loss 0.196211\n",
      "batch 1274: loss 0.368561\n",
      "batch 1275: loss 0.116571\n",
      "batch 1276: loss 0.180791\n",
      "batch 1277: loss 0.059231\n",
      "batch 1278: loss 0.070029\n",
      "batch 1279: loss 0.059360\n",
      "batch 1280: loss 0.133349\n",
      "batch 1281: loss 0.107341\n",
      "batch 1282: loss 0.115213\n",
      "batch 1283: loss 0.242197\n",
      "batch 1284: loss 0.111697\n",
      "batch 1285: loss 0.154681\n",
      "batch 1286: loss 0.154689\n",
      "batch 1287: loss 0.140553\n",
      "batch 1288: loss 0.188670\n",
      "batch 1289: loss 0.417391\n",
      "batch 1290: loss 0.091768\n",
      "batch 1291: loss 0.065214\n",
      "batch 1292: loss 0.178752\n",
      "batch 1293: loss 0.102399\n",
      "batch 1294: loss 0.104080\n",
      "batch 1295: loss 0.180651\n",
      "batch 1296: loss 0.253420\n",
      "batch 1297: loss 0.150406\n",
      "batch 1298: loss 0.128118\n",
      "batch 1299: loss 0.156944\n",
      "batch 1300: loss 0.097395\n",
      "batch 1301: loss 0.202031\n",
      "batch 1302: loss 0.182577\n",
      "batch 1303: loss 0.108264\n",
      "batch 1304: loss 0.097773\n",
      "batch 1305: loss 0.191283\n",
      "batch 1306: loss 0.157259\n",
      "batch 1307: loss 0.261067\n",
      "batch 1308: loss 0.040943\n",
      "batch 1309: loss 0.068419\n",
      "batch 1310: loss 0.260921\n",
      "batch 1311: loss 0.136662\n",
      "batch 1312: loss 0.314339\n",
      "batch 1313: loss 0.460558\n",
      "batch 1314: loss 0.214855\n",
      "batch 1315: loss 0.099927\n",
      "batch 1316: loss 0.253816\n",
      "batch 1317: loss 0.091184\n",
      "batch 1318: loss 0.158550\n",
      "batch 1319: loss 0.145779\n",
      "batch 1320: loss 0.082323\n",
      "batch 1321: loss 0.222061\n",
      "batch 1322: loss 0.030545\n",
      "batch 1323: loss 0.295628\n",
      "batch 1324: loss 0.100612\n",
      "batch 1325: loss 0.110840\n",
      "batch 1326: loss 0.155490\n",
      "batch 1327: loss 0.092474\n",
      "batch 1328: loss 0.174697\n",
      "batch 1329: loss 0.027663\n",
      "batch 1330: loss 0.183742\n",
      "batch 1331: loss 0.133346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1332: loss 0.108420\n",
      "batch 1333: loss 0.161353\n",
      "batch 1334: loss 0.193646\n",
      "batch 1335: loss 0.098706\n",
      "batch 1336: loss 0.098412\n",
      "batch 1337: loss 0.184345\n",
      "batch 1338: loss 0.292084\n",
      "batch 1339: loss 0.142562\n",
      "batch 1340: loss 0.178267\n",
      "batch 1341: loss 0.146524\n",
      "batch 1342: loss 0.103421\n",
      "batch 1343: loss 0.233666\n",
      "batch 1344: loss 0.143089\n",
      "batch 1345: loss 0.307664\n",
      "batch 1346: loss 0.289419\n",
      "batch 1347: loss 0.195126\n",
      "batch 1348: loss 0.101401\n",
      "batch 1349: loss 0.249201\n",
      "batch 1350: loss 0.125330\n",
      "batch 1351: loss 0.373374\n",
      "batch 1352: loss 0.287937\n",
      "batch 1353: loss 0.469142\n",
      "batch 1354: loss 0.063360\n",
      "batch 1355: loss 0.094057\n",
      "batch 1356: loss 0.109865\n",
      "batch 1357: loss 0.078330\n",
      "batch 1358: loss 0.174047\n",
      "batch 1359: loss 0.178290\n",
      "batch 1360: loss 0.125335\n",
      "batch 1361: loss 0.092282\n",
      "batch 1362: loss 0.182436\n",
      "batch 1363: loss 0.205936\n",
      "batch 1364: loss 0.120597\n",
      "batch 1365: loss 0.104306\n",
      "batch 1366: loss 0.175929\n",
      "batch 1367: loss 0.275998\n",
      "batch 1368: loss 0.126327\n",
      "batch 1369: loss 0.116055\n",
      "batch 1370: loss 0.189725\n",
      "batch 1371: loss 0.268483\n",
      "batch 1372: loss 0.074512\n",
      "batch 1373: loss 0.098167\n",
      "batch 1374: loss 0.212553\n",
      "batch 1375: loss 0.248179\n",
      "batch 1376: loss 0.148868\n",
      "batch 1377: loss 0.090602\n",
      "batch 1378: loss 0.488832\n",
      "batch 1379: loss 0.169592\n",
      "batch 1380: loss 0.130144\n",
      "batch 1381: loss 0.137936\n",
      "batch 1382: loss 0.058320\n",
      "batch 1383: loss 0.459019\n",
      "batch 1384: loss 0.094082\n",
      "batch 1385: loss 0.090198\n",
      "batch 1386: loss 0.083094\n",
      "batch 1387: loss 0.177856\n",
      "batch 1388: loss 0.247592\n",
      "batch 1389: loss 0.083126\n",
      "batch 1390: loss 0.102150\n",
      "batch 1391: loss 0.042773\n",
      "batch 1392: loss 0.090546\n",
      "batch 1393: loss 0.106192\n",
      "batch 1394: loss 0.366481\n",
      "batch 1395: loss 0.155916\n",
      "batch 1396: loss 0.056464\n",
      "batch 1397: loss 0.076668\n",
      "batch 1398: loss 0.275856\n",
      "batch 1399: loss 0.131139\n",
      "batch 1400: loss 0.163064\n",
      "batch 1401: loss 0.128089\n",
      "batch 1402: loss 0.298786\n",
      "batch 1403: loss 0.269603\n",
      "batch 1404: loss 0.056766\n",
      "batch 1405: loss 0.122808\n",
      "batch 1406: loss 0.243548\n",
      "batch 1407: loss 0.276576\n",
      "batch 1408: loss 0.070372\n",
      "batch 1409: loss 0.071319\n",
      "batch 1410: loss 0.082538\n",
      "batch 1411: loss 0.105397\n",
      "batch 1412: loss 0.333441\n",
      "batch 1413: loss 0.060137\n",
      "batch 1414: loss 0.051189\n",
      "batch 1415: loss 0.122528\n",
      "batch 1416: loss 0.229795\n",
      "batch 1417: loss 0.124446\n",
      "batch 1418: loss 0.108465\n",
      "batch 1419: loss 0.063805\n",
      "batch 1420: loss 0.160797\n",
      "batch 1421: loss 0.139813\n",
      "batch 1422: loss 0.129134\n",
      "batch 1423: loss 0.030223\n",
      "batch 1424: loss 0.079406\n",
      "batch 1425: loss 0.234333\n",
      "batch 1426: loss 0.055060\n",
      "batch 1427: loss 0.184932\n",
      "batch 1428: loss 0.189219\n",
      "batch 1429: loss 0.100426\n",
      "batch 1430: loss 0.210319\n",
      "batch 1431: loss 0.060251\n",
      "batch 1432: loss 0.128740\n",
      "batch 1433: loss 0.226747\n",
      "batch 1434: loss 0.116004\n",
      "batch 1435: loss 0.092977\n",
      "batch 1436: loss 0.243988\n",
      "batch 1437: loss 0.089779\n",
      "batch 1438: loss 0.111516\n",
      "batch 1439: loss 0.198778\n",
      "batch 1440: loss 0.161579\n",
      "batch 1441: loss 0.233639\n",
      "batch 1442: loss 0.077134\n",
      "batch 1443: loss 0.161972\n",
      "batch 1444: loss 0.317439\n",
      "batch 1445: loss 0.126373\n",
      "batch 1446: loss 0.150033\n",
      "batch 1447: loss 0.386049\n",
      "batch 1448: loss 0.177583\n",
      "batch 1449: loss 0.309397\n",
      "batch 1450: loss 0.046042\n",
      "batch 1451: loss 0.200254\n",
      "batch 1452: loss 0.188453\n",
      "batch 1453: loss 0.285722\n",
      "batch 1454: loss 0.065791\n",
      "batch 1455: loss 0.186635\n",
      "batch 1456: loss 0.052627\n",
      "batch 1457: loss 0.168006\n",
      "batch 1458: loss 0.150106\n",
      "batch 1459: loss 0.052492\n",
      "batch 1460: loss 0.169492\n",
      "batch 1461: loss 0.279496\n",
      "batch 1462: loss 0.073444\n",
      "batch 1463: loss 0.209160\n",
      "batch 1464: loss 0.148624\n",
      "batch 1465: loss 0.196847\n",
      "batch 1466: loss 0.146827\n",
      "batch 1467: loss 0.299277\n",
      "batch 1468: loss 0.104967\n",
      "batch 1469: loss 0.140460\n",
      "batch 1470: loss 0.287066\n",
      "batch 1471: loss 0.041639\n",
      "batch 1472: loss 0.042994\n",
      "batch 1473: loss 0.223720\n",
      "batch 1474: loss 0.057694\n",
      "batch 1475: loss 0.050279\n",
      "batch 1476: loss 0.196437\n",
      "batch 1477: loss 0.103736\n",
      "batch 1478: loss 0.144136\n",
      "batch 1479: loss 0.077847\n",
      "batch 1480: loss 0.044405\n",
      "batch 1481: loss 0.070019\n",
      "batch 1482: loss 0.152071\n",
      "batch 1483: loss 0.062043\n",
      "batch 1484: loss 0.150281\n",
      "batch 1485: loss 0.086050\n",
      "batch 1486: loss 0.352676\n",
      "batch 1487: loss 0.109188\n",
      "batch 1488: loss 0.200883\n",
      "batch 1489: loss 0.151159\n",
      "batch 1490: loss 0.050128\n",
      "batch 1491: loss 0.068400\n",
      "batch 1492: loss 0.250469\n",
      "batch 1493: loss 0.130687\n",
      "batch 1494: loss 0.157368\n",
      "batch 1495: loss 0.115013\n",
      "batch 1496: loss 0.175190\n",
      "batch 1497: loss 0.182920\n",
      "batch 1498: loss 0.261331\n",
      "batch 1499: loss 0.072054\n",
      "batch 1500: loss 0.104129\n",
      "batch 1501: loss 0.040115\n",
      "batch 1502: loss 0.107529\n",
      "batch 1503: loss 0.096937\n",
      "batch 1504: loss 0.079812\n",
      "batch 1505: loss 0.176861\n",
      "batch 1506: loss 0.146686\n",
      "batch 1507: loss 0.114666\n",
      "batch 1508: loss 0.085858\n",
      "batch 1509: loss 0.143925\n",
      "batch 1510: loss 0.252997\n",
      "batch 1511: loss 0.058155\n",
      "batch 1512: loss 0.224901\n",
      "batch 1513: loss 0.056132\n",
      "batch 1514: loss 0.093616\n",
      "batch 1515: loss 0.142000\n",
      "batch 1516: loss 0.100465\n",
      "batch 1517: loss 0.083086\n",
      "batch 1518: loss 0.111277\n",
      "batch 1519: loss 0.134167\n",
      "batch 1520: loss 0.152990\n",
      "batch 1521: loss 0.226014\n",
      "batch 1522: loss 0.112735\n",
      "batch 1523: loss 0.135123\n",
      "batch 1524: loss 0.093561\n",
      "batch 1525: loss 0.066500\n",
      "batch 1526: loss 0.129591\n",
      "batch 1527: loss 0.176189\n",
      "batch 1528: loss 0.085413\n",
      "batch 1529: loss 0.025762\n",
      "batch 1530: loss 0.063600\n",
      "batch 1531: loss 0.085730\n",
      "batch 1532: loss 0.093007\n",
      "batch 1533: loss 0.118506\n",
      "batch 1534: loss 0.069639\n",
      "batch 1535: loss 0.148121\n",
      "batch 1536: loss 0.114089\n",
      "batch 1537: loss 0.232663\n",
      "batch 1538: loss 0.154111\n",
      "batch 1539: loss 0.175313\n",
      "batch 1540: loss 0.049572\n",
      "batch 1541: loss 0.190580\n",
      "batch 1542: loss 0.246964\n",
      "batch 1543: loss 0.027190\n",
      "batch 1544: loss 0.354393\n",
      "batch 1545: loss 0.066306\n",
      "batch 1546: loss 0.124991\n",
      "batch 1547: loss 0.044137\n",
      "batch 1548: loss 0.203980\n",
      "batch 1549: loss 0.124655\n",
      "batch 1550: loss 0.204173\n",
      "batch 1551: loss 0.096082\n",
      "batch 1552: loss 0.286119\n",
      "batch 1553: loss 0.082155\n",
      "batch 1554: loss 0.151863\n",
      "batch 1555: loss 0.087610\n",
      "batch 1556: loss 0.097498\n",
      "batch 1557: loss 0.156031\n",
      "batch 1558: loss 0.058315\n",
      "batch 1559: loss 0.137626\n",
      "batch 1560: loss 0.231214\n",
      "batch 1561: loss 0.093210\n",
      "batch 1562: loss 0.170010\n",
      "batch 1563: loss 0.093211\n",
      "batch 1564: loss 0.130168\n",
      "batch 1565: loss 0.199325\n",
      "batch 1566: loss 0.114031\n",
      "batch 1567: loss 0.216979\n",
      "batch 1568: loss 0.206189\n",
      "batch 1569: loss 0.121523\n",
      "batch 1570: loss 0.132400\n",
      "batch 1571: loss 0.262655\n",
      "batch 1572: loss 0.081215\n",
      "batch 1573: loss 0.081225\n",
      "batch 1574: loss 0.144216\n",
      "batch 1575: loss 0.171922\n",
      "batch 1576: loss 0.046939\n",
      "batch 1577: loss 0.154730\n",
      "batch 1578: loss 0.045593\n",
      "batch 1579: loss 0.102094\n",
      "batch 1580: loss 0.087940\n",
      "batch 1581: loss 0.069895\n",
      "batch 1582: loss 0.261887\n",
      "batch 1583: loss 0.064920\n",
      "batch 1584: loss 0.187965\n",
      "batch 1585: loss 0.143490\n",
      "batch 1586: loss 0.220001\n",
      "batch 1587: loss 0.067501\n",
      "batch 1588: loss 0.045774\n",
      "batch 1589: loss 0.267716\n",
      "batch 1590: loss 0.214047\n",
      "batch 1591: loss 0.326144\n",
      "batch 1592: loss 0.110494\n",
      "batch 1593: loss 0.171933\n",
      "batch 1594: loss 0.167224\n",
      "batch 1595: loss 0.102290\n",
      "batch 1596: loss 0.107361\n",
      "batch 1597: loss 0.123086\n",
      "batch 1598: loss 0.381459\n",
      "batch 1599: loss 0.124399\n",
      "batch 1600: loss 0.219728\n",
      "batch 1601: loss 0.096976\n",
      "batch 1602: loss 0.176764\n",
      "batch 1603: loss 0.053754\n",
      "batch 1604: loss 0.115348\n",
      "batch 1605: loss 0.096221\n",
      "batch 1606: loss 0.112686\n",
      "batch 1607: loss 0.247483\n",
      "batch 1608: loss 0.067895\n",
      "batch 1609: loss 0.228206\n",
      "batch 1610: loss 0.167814\n",
      "batch 1611: loss 0.098328\n",
      "batch 1612: loss 0.320018\n",
      "batch 1613: loss 0.091896\n",
      "batch 1614: loss 0.131064\n",
      "batch 1615: loss 0.254625\n",
      "batch 1616: loss 0.150955\n",
      "batch 1617: loss 0.075190\n",
      "batch 1618: loss 0.087720\n",
      "batch 1619: loss 0.132783\n",
      "batch 1620: loss 0.263835\n",
      "batch 1621: loss 0.076893\n",
      "batch 1622: loss 0.265795\n",
      "batch 1623: loss 0.176966\n",
      "batch 1624: loss 0.045039\n",
      "batch 1625: loss 0.100771\n",
      "batch 1626: loss 0.135312\n",
      "batch 1627: loss 0.239225\n",
      "batch 1628: loss 0.034420\n",
      "batch 1629: loss 0.271462\n",
      "batch 1630: loss 0.087810\n",
      "batch 1631: loss 0.064034\n",
      "batch 1632: loss 0.114362\n",
      "batch 1633: loss 0.198997\n",
      "batch 1634: loss 0.301192\n",
      "batch 1635: loss 0.123418\n",
      "batch 1636: loss 0.086941\n",
      "batch 1637: loss 0.228956\n",
      "batch 1638: loss 0.249970\n",
      "batch 1639: loss 0.331447\n",
      "batch 1640: loss 0.167560\n",
      "batch 1641: loss 0.192552\n",
      "batch 1642: loss 0.042169\n",
      "batch 1643: loss 0.159755\n",
      "batch 1644: loss 0.199557\n",
      "batch 1645: loss 0.181795\n",
      "batch 1646: loss 0.044733\n",
      "batch 1647: loss 0.101410\n",
      "batch 1648: loss 0.104133\n",
      "batch 1649: loss 0.107604\n",
      "batch 1650: loss 0.268379\n",
      "batch 1651: loss 0.107449\n",
      "batch 1652: loss 0.082012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1653: loss 0.137665\n",
      "batch 1654: loss 0.122972\n",
      "batch 1655: loss 0.218709\n",
      "batch 1656: loss 0.231130\n",
      "batch 1657: loss 0.141205\n",
      "batch 1658: loss 0.021103\n",
      "batch 1659: loss 0.165515\n",
      "batch 1660: loss 0.076575\n",
      "batch 1661: loss 0.119971\n",
      "batch 1662: loss 0.062528\n",
      "batch 1663: loss 0.046269\n",
      "batch 1664: loss 0.312767\n",
      "batch 1665: loss 0.093986\n",
      "batch 1666: loss 0.076674\n",
      "batch 1667: loss 0.100662\n",
      "batch 1668: loss 0.133134\n",
      "batch 1669: loss 0.060880\n",
      "batch 1670: loss 0.044527\n",
      "batch 1671: loss 0.392951\n",
      "batch 1672: loss 0.047841\n",
      "batch 1673: loss 0.147441\n",
      "batch 1674: loss 0.150332\n",
      "batch 1675: loss 0.081217\n",
      "batch 1676: loss 0.086010\n",
      "batch 1677: loss 0.156796\n",
      "batch 1678: loss 0.255053\n",
      "batch 1679: loss 0.030327\n",
      "batch 1680: loss 0.120486\n",
      "batch 1681: loss 0.071654\n",
      "batch 1682: loss 0.455598\n",
      "batch 1683: loss 0.137173\n",
      "batch 1684: loss 0.147296\n",
      "batch 1685: loss 0.096371\n",
      "batch 1686: loss 0.115493\n",
      "batch 1687: loss 0.080156\n",
      "batch 1688: loss 0.152720\n",
      "batch 1689: loss 0.115194\n",
      "batch 1690: loss 0.040630\n",
      "batch 1691: loss 0.062426\n",
      "batch 1692: loss 0.040464\n",
      "batch 1693: loss 0.077895\n",
      "batch 1694: loss 0.352899\n",
      "batch 1695: loss 0.250027\n",
      "batch 1696: loss 0.087405\n",
      "batch 1697: loss 0.032479\n",
      "batch 1698: loss 0.257919\n",
      "batch 1699: loss 0.105862\n",
      "batch 1700: loss 0.037444\n",
      "batch 1701: loss 0.108335\n",
      "batch 1702: loss 0.179251\n",
      "batch 1703: loss 0.169710\n",
      "batch 1704: loss 0.044453\n",
      "batch 1705: loss 0.057415\n",
      "batch 1706: loss 0.135969\n",
      "batch 1707: loss 0.107474\n",
      "batch 1708: loss 0.075871\n",
      "batch 1709: loss 0.083182\n",
      "batch 1710: loss 0.034893\n",
      "batch 1711: loss 0.170936\n",
      "batch 1712: loss 0.070674\n",
      "batch 1713: loss 0.254848\n",
      "batch 1714: loss 0.088133\n",
      "batch 1715: loss 0.371477\n",
      "batch 1716: loss 0.037318\n",
      "batch 1717: loss 0.152339\n",
      "batch 1718: loss 0.101093\n",
      "batch 1719: loss 0.160547\n",
      "batch 1720: loss 0.110734\n",
      "batch 1721: loss 0.139709\n",
      "batch 1722: loss 0.091506\n",
      "batch 1723: loss 0.124316\n",
      "batch 1724: loss 0.119010\n",
      "batch 1725: loss 0.213582\n",
      "batch 1726: loss 0.087291\n",
      "batch 1727: loss 0.170980\n",
      "batch 1728: loss 0.070783\n",
      "batch 1729: loss 0.173690\n",
      "batch 1730: loss 0.039837\n",
      "batch 1731: loss 0.045055\n",
      "batch 1732: loss 0.169157\n",
      "batch 1733: loss 0.065062\n",
      "batch 1734: loss 0.186559\n",
      "batch 1735: loss 0.110231\n",
      "batch 1736: loss 0.095979\n",
      "batch 1737: loss 0.069549\n",
      "batch 1738: loss 0.019956\n",
      "batch 1739: loss 0.074092\n",
      "batch 1740: loss 0.050915\n",
      "batch 1741: loss 0.061059\n",
      "batch 1742: loss 0.056929\n",
      "batch 1743: loss 0.094626\n",
      "batch 1744: loss 0.260807\n",
      "batch 1745: loss 0.054571\n",
      "batch 1746: loss 0.042238\n",
      "batch 1747: loss 0.164935\n",
      "batch 1748: loss 0.061905\n",
      "batch 1749: loss 0.188016\n",
      "batch 1750: loss 0.061933\n",
      "batch 1751: loss 0.136991\n",
      "batch 1752: loss 0.065308\n",
      "batch 1753: loss 0.166468\n",
      "batch 1754: loss 0.069480\n",
      "batch 1755: loss 0.051609\n",
      "batch 1756: loss 0.033983\n",
      "batch 1757: loss 0.101522\n",
      "batch 1758: loss 0.252188\n",
      "batch 1759: loss 0.103934\n",
      "batch 1760: loss 0.097572\n",
      "batch 1761: loss 0.337609\n",
      "batch 1762: loss 0.044635\n",
      "batch 1763: loss 0.090671\n",
      "batch 1764: loss 0.186518\n",
      "batch 1765: loss 0.068666\n",
      "batch 1766: loss 0.135656\n",
      "batch 1767: loss 0.139403\n",
      "batch 1768: loss 0.262628\n",
      "batch 1769: loss 0.068200\n",
      "batch 1770: loss 0.055107\n",
      "batch 1771: loss 0.103195\n",
      "batch 1772: loss 0.084856\n",
      "batch 1773: loss 0.210447\n",
      "batch 1774: loss 0.191521\n",
      "batch 1775: loss 0.048517\n",
      "batch 1776: loss 0.259272\n",
      "batch 1777: loss 0.088427\n",
      "batch 1778: loss 0.070586\n",
      "batch 1779: loss 0.096081\n",
      "batch 1780: loss 0.190742\n",
      "batch 1781: loss 0.184070\n",
      "batch 1782: loss 0.139605\n",
      "batch 1783: loss 0.286858\n",
      "batch 1784: loss 0.078681\n",
      "batch 1785: loss 0.130487\n",
      "batch 1786: loss 0.048757\n",
      "batch 1787: loss 0.067208\n",
      "batch 1788: loss 0.120859\n",
      "batch 1789: loss 0.151870\n",
      "batch 1790: loss 0.350998\n",
      "batch 1791: loss 0.166711\n",
      "batch 1792: loss 0.076832\n",
      "batch 1793: loss 0.128068\n",
      "batch 1794: loss 0.236151\n",
      "batch 1795: loss 0.220824\n",
      "batch 1796: loss 0.025997\n",
      "batch 1797: loss 0.095100\n",
      "batch 1798: loss 0.070393\n",
      "batch 1799: loss 0.093917\n",
      "batch 1800: loss 0.189772\n",
      "batch 1801: loss 0.139644\n",
      "batch 1802: loss 0.131567\n",
      "batch 1803: loss 0.103702\n",
      "batch 1804: loss 0.178706\n",
      "batch 1805: loss 0.091460\n",
      "batch 1806: loss 0.124619\n",
      "batch 1807: loss 0.213664\n",
      "batch 1808: loss 0.185041\n",
      "batch 1809: loss 0.072448\n",
      "batch 1810: loss 0.275128\n",
      "batch 1811: loss 0.121550\n",
      "batch 1812: loss 0.181214\n",
      "batch 1813: loss 0.347615\n",
      "batch 1814: loss 0.078302\n",
      "batch 1815: loss 0.234864\n",
      "batch 1816: loss 0.038596\n",
      "batch 1817: loss 0.149690\n",
      "batch 1818: loss 0.107479\n",
      "batch 1819: loss 0.073339\n",
      "batch 1820: loss 0.055319\n",
      "batch 1821: loss 0.065713\n",
      "batch 1822: loss 0.151674\n",
      "batch 1823: loss 0.170400\n",
      "batch 1824: loss 0.111578\n",
      "batch 1825: loss 0.085678\n",
      "batch 1826: loss 0.039014\n",
      "batch 1827: loss 0.048807\n",
      "batch 1828: loss 0.130769\n",
      "batch 1829: loss 0.377731\n",
      "batch 1830: loss 0.017268\n",
      "batch 1831: loss 0.063130\n",
      "batch 1832: loss 0.135739\n",
      "batch 1833: loss 0.087867\n",
      "batch 1834: loss 0.167033\n",
      "batch 1835: loss 0.157086\n",
      "batch 1836: loss 0.055518\n",
      "batch 1837: loss 0.065337\n",
      "batch 1838: loss 0.180956\n",
      "batch 1839: loss 0.203628\n",
      "batch 1840: loss 0.275084\n",
      "batch 1841: loss 0.033431\n",
      "batch 1842: loss 0.063528\n",
      "batch 1843: loss 0.062759\n",
      "batch 1844: loss 0.280616\n",
      "batch 1845: loss 0.068946\n",
      "batch 1846: loss 0.079945\n",
      "batch 1847: loss 0.142936\n",
      "batch 1848: loss 0.150485\n",
      "batch 1849: loss 0.082552\n",
      "batch 1850: loss 0.075704\n",
      "batch 1851: loss 0.119765\n",
      "batch 1852: loss 0.179489\n",
      "batch 1853: loss 0.147568\n",
      "batch 1854: loss 0.099422\n",
      "batch 1855: loss 0.094141\n",
      "batch 1856: loss 0.084983\n",
      "batch 1857: loss 0.241919\n",
      "batch 1858: loss 0.138398\n",
      "batch 1859: loss 0.119059\n",
      "batch 1860: loss 0.117237\n",
      "batch 1861: loss 0.073324\n",
      "batch 1862: loss 0.044295\n",
      "batch 1863: loss 0.025600\n",
      "batch 1864: loss 0.041213\n",
      "batch 1865: loss 0.027682\n",
      "batch 1866: loss 0.033741\n",
      "batch 1867: loss 0.282454\n",
      "batch 1868: loss 0.065328\n",
      "batch 1869: loss 0.132457\n",
      "batch 1870: loss 0.047558\n",
      "batch 1871: loss 0.137308\n",
      "batch 1872: loss 0.067779\n",
      "batch 1873: loss 0.203193\n",
      "batch 1874: loss 0.275798\n",
      "batch 1875: loss 0.026942\n",
      "batch 1876: loss 0.162428\n",
      "batch 1877: loss 0.204386\n",
      "batch 1878: loss 0.043742\n",
      "batch 1879: loss 0.021063\n",
      "batch 1880: loss 0.122959\n",
      "batch 1881: loss 0.127501\n",
      "batch 1882: loss 0.025889\n",
      "batch 1883: loss 0.105943\n",
      "batch 1884: loss 0.289144\n",
      "batch 1885: loss 0.097100\n",
      "batch 1886: loss 0.046999\n",
      "batch 1887: loss 0.206301\n",
      "batch 1888: loss 0.066266\n",
      "batch 1889: loss 0.103030\n",
      "batch 1890: loss 0.093805\n",
      "batch 1891: loss 0.197255\n",
      "batch 1892: loss 0.065751\n",
      "batch 1893: loss 0.126769\n",
      "batch 1894: loss 0.036854\n",
      "batch 1895: loss 0.177553\n",
      "batch 1896: loss 0.115422\n",
      "batch 1897: loss 0.103668\n",
      "batch 1898: loss 0.168827\n",
      "batch 1899: loss 0.026147\n",
      "batch 1900: loss 0.273593\n",
      "batch 1901: loss 0.096796\n",
      "batch 1902: loss 0.230508\n",
      "batch 1903: loss 0.375710\n",
      "batch 1904: loss 0.079602\n",
      "batch 1905: loss 0.051947\n",
      "batch 1906: loss 0.035066\n",
      "batch 1907: loss 0.327806\n",
      "batch 1908: loss 0.109477\n",
      "batch 1909: loss 0.118694\n",
      "batch 1910: loss 0.075494\n",
      "batch 1911: loss 0.189968\n",
      "batch 1912: loss 0.054308\n",
      "batch 1913: loss 0.130378\n",
      "batch 1914: loss 0.083512\n",
      "batch 1915: loss 0.091039\n",
      "batch 1916: loss 0.123169\n",
      "batch 1917: loss 0.132500\n",
      "batch 1918: loss 0.182794\n",
      "batch 1919: loss 0.051370\n",
      "batch 1920: loss 0.250528\n",
      "batch 1921: loss 0.325967\n",
      "batch 1922: loss 0.171270\n",
      "batch 1923: loss 0.116511\n",
      "batch 1924: loss 0.125054\n",
      "batch 1925: loss 0.231717\n",
      "batch 1926: loss 0.170938\n",
      "batch 1927: loss 0.082058\n",
      "batch 1928: loss 0.138045\n",
      "batch 1929: loss 0.192811\n",
      "batch 1930: loss 0.104403\n",
      "batch 1931: loss 0.210958\n",
      "batch 1932: loss 0.119103\n",
      "batch 1933: loss 0.280806\n",
      "batch 1934: loss 0.059016\n",
      "batch 1935: loss 0.063145\n",
      "batch 1936: loss 0.330360\n",
      "batch 1937: loss 0.064256\n",
      "batch 1938: loss 0.194794\n",
      "batch 1939: loss 0.051037\n",
      "batch 1940: loss 0.299207\n",
      "batch 1941: loss 0.079348\n",
      "batch 1942: loss 0.247964\n",
      "batch 1943: loss 0.045393\n",
      "batch 1944: loss 0.046415\n",
      "batch 1945: loss 0.043426\n",
      "batch 1946: loss 0.019261\n",
      "batch 1947: loss 0.030262\n",
      "batch 1948: loss 0.143163\n",
      "batch 1949: loss 0.015940\n",
      "batch 1950: loss 0.083894\n",
      "batch 1951: loss 0.073259\n",
      "batch 1952: loss 0.115251\n",
      "batch 1953: loss 0.117969\n",
      "batch 1954: loss 0.225464\n",
      "batch 1955: loss 0.097062\n",
      "batch 1956: loss 0.334115\n",
      "batch 1957: loss 0.028951\n",
      "batch 1958: loss 0.119829\n",
      "batch 1959: loss 0.098913\n",
      "batch 1960: loss 0.197534\n",
      "batch 1961: loss 0.119839\n",
      "batch 1962: loss 0.153242\n",
      "batch 1963: loss 0.075369\n",
      "batch 1964: loss 0.260068\n",
      "batch 1965: loss 0.032322\n",
      "batch 1966: loss 0.121139\n",
      "batch 1967: loss 0.083644\n",
      "batch 1968: loss 0.279443\n",
      "batch 1969: loss 0.123691\n",
      "batch 1970: loss 0.054921\n",
      "batch 1971: loss 0.090517\n",
      "batch 1972: loss 0.129717\n",
      "batch 1973: loss 0.040759\n",
      "batch 1974: loss 0.108868\n",
      "batch 1975: loss 0.076005\n",
      "batch 1976: loss 0.031418\n",
      "batch 1977: loss 0.131618\n",
      "batch 1978: loss 0.012892\n",
      "batch 1979: loss 0.217336\n",
      "batch 1980: loss 0.047994\n",
      "batch 1981: loss 0.105876\n",
      "batch 1982: loss 0.161930\n",
      "batch 1983: loss 0.390003\n",
      "batch 1984: loss 0.140283\n",
      "batch 1985: loss 0.137535\n",
      "batch 1986: loss 0.224506\n",
      "batch 1987: loss 0.101773\n",
      "batch 1988: loss 0.128437\n",
      "batch 1989: loss 0.048041\n",
      "batch 1990: loss 0.045878\n",
      "batch 1991: loss 0.134580\n",
      "batch 1992: loss 0.217988\n",
      "batch 1993: loss 0.062876\n",
      "batch 1994: loss 0.181456\n",
      "batch 1995: loss 0.030321\n",
      "batch 1996: loss 0.103374\n",
      "batch 1997: loss 0.086517\n",
      "batch 1998: loss 0.086968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1999: loss 0.081239\n",
      "batch 2000: loss 0.182242\n",
      "batch 2001: loss 0.152795\n",
      "batch 2002: loss 0.044224\n",
      "batch 2003: loss 0.063918\n",
      "batch 2004: loss 0.092937\n",
      "batch 2005: loss 0.125149\n",
      "batch 2006: loss 0.146928\n",
      "batch 2007: loss 0.195771\n",
      "batch 2008: loss 0.120309\n",
      "batch 2009: loss 0.074203\n",
      "batch 2010: loss 0.027275\n",
      "batch 2011: loss 0.081362\n",
      "batch 2012: loss 0.098603\n",
      "batch 2013: loss 0.146827\n",
      "batch 2014: loss 0.273916\n",
      "batch 2015: loss 0.033157\n",
      "batch 2016: loss 0.069536\n",
      "batch 2017: loss 0.004274\n",
      "batch 2018: loss 0.042132\n",
      "batch 2019: loss 0.102464\n",
      "batch 2020: loss 0.062296\n",
      "batch 2021: loss 0.025280\n",
      "batch 2022: loss 0.152736\n",
      "batch 2023: loss 0.089130\n",
      "batch 2024: loss 0.202581\n",
      "batch 2025: loss 0.280044\n",
      "batch 2026: loss 0.032381\n",
      "batch 2027: loss 0.219582\n",
      "batch 2028: loss 0.196285\n",
      "batch 2029: loss 0.058156\n",
      "batch 2030: loss 0.063743\n",
      "batch 2031: loss 0.047296\n",
      "batch 2032: loss 0.040720\n",
      "batch 2033: loss 0.021988\n",
      "batch 2034: loss 0.059420\n",
      "batch 2035: loss 0.293812\n",
      "batch 2036: loss 0.442371\n",
      "batch 2037: loss 0.043610\n",
      "batch 2038: loss 0.083486\n",
      "batch 2039: loss 0.067380\n",
      "batch 2040: loss 0.088858\n",
      "batch 2041: loss 0.245449\n",
      "batch 2042: loss 0.068372\n",
      "batch 2043: loss 0.155469\n",
      "batch 2044: loss 0.245364\n",
      "batch 2045: loss 0.075933\n",
      "batch 2046: loss 0.112564\n",
      "batch 2047: loss 0.050340\n",
      "batch 2048: loss 0.050143\n",
      "batch 2049: loss 0.138874\n",
      "batch 2050: loss 0.060494\n",
      "batch 2051: loss 0.038259\n",
      "batch 2052: loss 0.182880\n",
      "batch 2053: loss 0.205500\n",
      "batch 2054: loss 0.075424\n",
      "batch 2055: loss 0.040613\n",
      "batch 2056: loss 0.095642\n",
      "batch 2057: loss 0.044449\n",
      "batch 2058: loss 0.062294\n",
      "batch 2059: loss 0.033137\n",
      "batch 2060: loss 0.089482\n",
      "batch 2061: loss 0.087270\n",
      "batch 2062: loss 0.223674\n",
      "batch 2063: loss 0.300919\n",
      "batch 2064: loss 0.038922\n",
      "batch 2065: loss 0.089694\n",
      "batch 2066: loss 0.117009\n",
      "batch 2067: loss 0.066439\n",
      "batch 2068: loss 0.110590\n",
      "batch 2069: loss 0.065972\n",
      "batch 2070: loss 0.075738\n",
      "batch 2071: loss 0.049721\n",
      "batch 2072: loss 0.110109\n",
      "batch 2073: loss 0.032656\n",
      "batch 2074: loss 0.069023\n",
      "batch 2075: loss 0.136451\n",
      "batch 2076: loss 0.143618\n",
      "batch 2077: loss 0.352984\n",
      "batch 2078: loss 0.063701\n",
      "batch 2079: loss 0.106136\n",
      "batch 2080: loss 0.023936\n",
      "batch 2081: loss 0.031060\n",
      "batch 2082: loss 0.218251\n",
      "batch 2083: loss 0.143991\n",
      "batch 2084: loss 0.150243\n",
      "batch 2085: loss 0.135550\n",
      "batch 2086: loss 0.045883\n",
      "batch 2087: loss 0.183309\n",
      "batch 2088: loss 0.087054\n",
      "batch 2089: loss 0.096129\n",
      "batch 2090: loss 0.055270\n",
      "batch 2091: loss 0.019931\n",
      "batch 2092: loss 0.113007\n",
      "batch 2093: loss 0.085807\n",
      "batch 2094: loss 0.081866\n",
      "batch 2095: loss 0.052886\n",
      "batch 2096: loss 0.060639\n",
      "batch 2097: loss 0.174430\n",
      "batch 2098: loss 0.075160\n",
      "batch 2099: loss 0.164615\n",
      "batch 2100: loss 0.154637\n",
      "batch 2101: loss 0.190920\n",
      "batch 2102: loss 0.015367\n",
      "batch 2103: loss 0.082756\n",
      "batch 2104: loss 0.191480\n",
      "batch 2105: loss 0.125623\n",
      "batch 2106: loss 0.058617\n",
      "batch 2107: loss 0.065787\n",
      "batch 2108: loss 0.099015\n",
      "batch 2109: loss 0.064818\n",
      "batch 2110: loss 0.306252\n",
      "batch 2111: loss 0.047944\n",
      "batch 2112: loss 0.044082\n",
      "batch 2113: loss 0.064802\n",
      "batch 2114: loss 0.071502\n",
      "batch 2115: loss 0.200627\n",
      "batch 2116: loss 0.155954\n",
      "batch 2117: loss 0.304040\n",
      "batch 2118: loss 0.133985\n",
      "batch 2119: loss 0.023486\n",
      "batch 2120: loss 0.044096\n",
      "batch 2121: loss 0.051488\n",
      "batch 2122: loss 0.210550\n",
      "batch 2123: loss 0.327239\n",
      "batch 2124: loss 0.048941\n",
      "batch 2125: loss 0.080749\n",
      "batch 2126: loss 0.161234\n",
      "batch 2127: loss 0.102007\n",
      "batch 2128: loss 0.125757\n",
      "batch 2129: loss 0.194534\n",
      "batch 2130: loss 0.137848\n",
      "batch 2131: loss 0.033269\n",
      "batch 2132: loss 0.021440\n",
      "batch 2133: loss 0.076053\n",
      "batch 2134: loss 0.158654\n",
      "batch 2135: loss 0.138195\n",
      "batch 2136: loss 0.136408\n",
      "batch 2137: loss 0.065184\n",
      "batch 2138: loss 0.186277\n",
      "batch 2139: loss 0.222347\n",
      "batch 2140: loss 0.027538\n",
      "batch 2141: loss 0.071513\n",
      "batch 2142: loss 0.195317\n",
      "batch 2143: loss 0.055654\n",
      "batch 2144: loss 0.031294\n",
      "batch 2145: loss 0.108807\n",
      "batch 2146: loss 0.105839\n",
      "batch 2147: loss 0.055431\n",
      "batch 2148: loss 0.178751\n",
      "batch 2149: loss 0.113789\n",
      "batch 2150: loss 0.036044\n",
      "batch 2151: loss 0.039444\n",
      "batch 2152: loss 0.144382\n",
      "batch 2153: loss 0.260859\n",
      "batch 2154: loss 0.022164\n",
      "batch 2155: loss 0.031238\n",
      "batch 2156: loss 0.098031\n",
      "batch 2157: loss 0.043330\n",
      "batch 2158: loss 0.147220\n",
      "batch 2159: loss 0.011480\n",
      "batch 2160: loss 0.097150\n",
      "batch 2161: loss 0.115733\n",
      "batch 2162: loss 0.062894\n",
      "batch 2163: loss 0.044858\n",
      "batch 2164: loss 0.153343\n",
      "batch 2165: loss 0.108718\n",
      "batch 2166: loss 0.066271\n",
      "batch 2167: loss 0.049867\n",
      "batch 2168: loss 0.196277\n",
      "batch 2169: loss 0.300544\n",
      "batch 2170: loss 0.091091\n",
      "batch 2171: loss 0.174731\n",
      "batch 2172: loss 0.048820\n",
      "batch 2173: loss 0.160036\n",
      "batch 2174: loss 0.025734\n",
      "batch 2175: loss 0.176647\n",
      "batch 2176: loss 0.028476\n",
      "batch 2177: loss 0.155414\n",
      "batch 2178: loss 0.108935\n",
      "batch 2179: loss 0.241097\n",
      "batch 2180: loss 0.057297\n",
      "batch 2181: loss 0.042523\n",
      "batch 2182: loss 0.125849\n",
      "batch 2183: loss 0.217401\n",
      "batch 2184: loss 0.089250\n",
      "batch 2185: loss 0.037128\n",
      "batch 2186: loss 0.039849\n",
      "batch 2187: loss 0.152074\n",
      "batch 2188: loss 0.014456\n",
      "batch 2189: loss 0.092763\n",
      "batch 2190: loss 0.079557\n",
      "batch 2191: loss 0.067562\n",
      "batch 2192: loss 0.099154\n",
      "batch 2193: loss 0.079087\n",
      "batch 2194: loss 0.165229\n",
      "batch 2195: loss 0.127589\n",
      "batch 2196: loss 0.173023\n",
      "batch 2197: loss 0.258428\n",
      "batch 2198: loss 0.106137\n",
      "batch 2199: loss 0.086184\n",
      "batch 2200: loss 0.030197\n",
      "batch 2201: loss 0.177740\n",
      "batch 2202: loss 0.168877\n",
      "batch 2203: loss 0.153874\n",
      "batch 2204: loss 0.081106\n",
      "batch 2205: loss 0.095385\n",
      "batch 2206: loss 0.055029\n",
      "batch 2207: loss 0.029672\n",
      "batch 2208: loss 0.048074\n",
      "batch 2209: loss 0.064608\n",
      "batch 2210: loss 0.258186\n",
      "batch 2211: loss 0.102393\n",
      "batch 2212: loss 0.058132\n",
      "batch 2213: loss 0.154448\n",
      "batch 2214: loss 0.032058\n",
      "batch 2215: loss 0.082391\n",
      "batch 2216: loss 0.146057\n",
      "batch 2217: loss 0.099632\n",
      "batch 2218: loss 0.086629\n",
      "batch 2219: loss 0.198337\n",
      "batch 2220: loss 0.089963\n",
      "batch 2221: loss 0.081653\n",
      "batch 2222: loss 0.209508\n",
      "batch 2223: loss 0.008645\n",
      "batch 2224: loss 0.163809\n",
      "batch 2225: loss 0.085247\n",
      "batch 2226: loss 0.040781\n",
      "batch 2227: loss 0.148078\n",
      "batch 2228: loss 0.137905\n",
      "batch 2229: loss 0.076429\n",
      "batch 2230: loss 0.030884\n",
      "batch 2231: loss 0.081562\n",
      "batch 2232: loss 0.096376\n",
      "batch 2233: loss 0.079598\n",
      "batch 2234: loss 0.443549\n",
      "batch 2235: loss 0.119098\n",
      "batch 2236: loss 0.031547\n",
      "batch 2237: loss 0.226724\n",
      "batch 2238: loss 0.114455\n",
      "batch 2239: loss 0.014601\n",
      "batch 2240: loss 0.127897\n",
      "batch 2241: loss 0.118580\n",
      "batch 2242: loss 0.415242\n",
      "batch 2243: loss 0.201591\n",
      "batch 2244: loss 0.091548\n",
      "batch 2245: loss 0.060701\n",
      "batch 2246: loss 0.057751\n",
      "batch 2247: loss 0.093902\n",
      "batch 2248: loss 0.129300\n",
      "batch 2249: loss 0.059174\n",
      "batch 2250: loss 0.021087\n",
      "batch 2251: loss 0.068679\n",
      "batch 2252: loss 0.143557\n",
      "batch 2253: loss 0.082251\n",
      "batch 2254: loss 0.256198\n",
      "batch 2255: loss 0.226578\n",
      "batch 2256: loss 0.151185\n",
      "batch 2257: loss 0.077792\n",
      "batch 2258: loss 0.053367\n",
      "batch 2259: loss 0.054479\n",
      "batch 2260: loss 0.106200\n",
      "batch 2261: loss 0.073582\n",
      "batch 2262: loss 0.174111\n",
      "batch 2263: loss 0.012031\n",
      "batch 2264: loss 0.233957\n",
      "batch 2265: loss 0.320875\n",
      "batch 2266: loss 0.046382\n",
      "batch 2267: loss 0.055755\n",
      "batch 2268: loss 0.043761\n",
      "batch 2269: loss 0.093555\n",
      "batch 2270: loss 0.101084\n",
      "batch 2271: loss 0.022832\n",
      "batch 2272: loss 0.043599\n",
      "batch 2273: loss 0.141480\n",
      "batch 2274: loss 0.028986\n",
      "batch 2275: loss 0.065152\n",
      "batch 2276: loss 0.042947\n",
      "batch 2277: loss 0.088429\n",
      "batch 2278: loss 0.059446\n",
      "batch 2279: loss 0.068209\n",
      "batch 2280: loss 0.049535\n",
      "batch 2281: loss 0.083493\n",
      "batch 2282: loss 0.076342\n",
      "batch 2283: loss 0.103272\n",
      "batch 2284: loss 0.039250\n",
      "batch 2285: loss 0.030281\n",
      "batch 2286: loss 0.084618\n",
      "batch 2287: loss 0.232463\n",
      "batch 2288: loss 0.071866\n",
      "batch 2289: loss 0.054252\n",
      "batch 2290: loss 0.149478\n",
      "batch 2291: loss 0.176218\n",
      "batch 2292: loss 0.121834\n",
      "batch 2293: loss 0.146580\n",
      "batch 2294: loss 0.075600\n",
      "batch 2295: loss 0.021060\n",
      "batch 2296: loss 0.357295\n",
      "batch 2297: loss 0.091358\n",
      "batch 2298: loss 0.145010\n",
      "batch 2299: loss 0.065767\n",
      "batch 2300: loss 0.105715\n",
      "batch 2301: loss 0.071076\n",
      "batch 2302: loss 0.054706\n",
      "batch 2303: loss 0.013288\n",
      "batch 2304: loss 0.127994\n",
      "batch 2305: loss 0.019502\n",
      "batch 2306: loss 0.037156\n",
      "batch 2307: loss 0.167473\n",
      "batch 2308: loss 0.205826\n",
      "batch 2309: loss 0.153301\n",
      "batch 2310: loss 0.228704\n",
      "batch 2311: loss 0.083046\n",
      "batch 2312: loss 0.113749\n",
      "batch 2313: loss 0.087843\n",
      "batch 2314: loss 0.080065\n",
      "batch 2315: loss 0.025438\n",
      "batch 2316: loss 0.318105\n",
      "batch 2317: loss 0.191255\n",
      "batch 2318: loss 0.033200\n",
      "batch 2319: loss 0.107479\n",
      "batch 2320: loss 0.145731\n",
      "batch 2321: loss 0.044260\n",
      "batch 2322: loss 0.037892\n",
      "batch 2323: loss 0.070339\n",
      "batch 2324: loss 0.065251\n",
      "batch 2325: loss 0.191247\n",
      "batch 2326: loss 0.148238\n",
      "batch 2327: loss 0.061784\n",
      "batch 2328: loss 0.116696\n",
      "batch 2329: loss 0.147106\n",
      "batch 2330: loss 0.045536\n",
      "batch 2331: loss 0.238160\n",
      "batch 2332: loss 0.010022\n",
      "batch 2333: loss 0.094169\n",
      "batch 2334: loss 0.189317\n",
      "batch 2335: loss 0.156857\n",
      "batch 2336: loss 0.011087\n",
      "batch 2337: loss 0.065343\n",
      "batch 2338: loss 0.226477\n",
      "batch 2339: loss 0.221233\n",
      "batch 2340: loss 0.058528\n",
      "batch 2341: loss 0.144637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2342: loss 0.049703\n",
      "batch 2343: loss 0.093230\n",
      "batch 2344: loss 0.100412\n",
      "batch 2345: loss 0.042733\n",
      "batch 2346: loss 0.079692\n",
      "batch 2347: loss 0.211299\n",
      "batch 2348: loss 0.229251\n",
      "batch 2349: loss 0.280431\n",
      "batch 2350: loss 0.114532\n",
      "batch 2351: loss 0.163572\n",
      "batch 2352: loss 0.095436\n",
      "batch 2353: loss 0.159246\n",
      "batch 2354: loss 0.130655\n",
      "batch 2355: loss 0.109675\n",
      "batch 2356: loss 0.018581\n",
      "batch 2357: loss 0.165064\n",
      "batch 2358: loss 0.018480\n",
      "batch 2359: loss 0.102053\n",
      "batch 2360: loss 0.113865\n",
      "batch 2361: loss 0.084242\n",
      "batch 2362: loss 0.060566\n",
      "batch 2363: loss 0.042116\n",
      "batch 2364: loss 0.112032\n",
      "batch 2365: loss 0.186591\n",
      "batch 2366: loss 0.053553\n",
      "batch 2367: loss 0.139149\n",
      "batch 2368: loss 0.023960\n",
      "batch 2369: loss 0.250174\n",
      "batch 2370: loss 0.031659\n",
      "batch 2371: loss 0.319478\n",
      "batch 2372: loss 0.030369\n",
      "batch 2373: loss 0.025964\n",
      "batch 2374: loss 0.087462\n",
      "batch 2375: loss 0.078477\n",
      "batch 2376: loss 0.208879\n",
      "batch 2377: loss 0.212456\n",
      "batch 2378: loss 0.059304\n",
      "batch 2379: loss 0.098019\n",
      "batch 2380: loss 0.084432\n",
      "batch 2381: loss 0.363939\n",
      "batch 2382: loss 0.194191\n",
      "batch 2383: loss 0.057762\n",
      "batch 2384: loss 0.253048\n",
      "batch 2385: loss 0.343084\n",
      "batch 2386: loss 0.038635\n",
      "batch 2387: loss 0.065853\n",
      "batch 2388: loss 0.066847\n",
      "batch 2389: loss 0.102047\n",
      "batch 2390: loss 0.090180\n",
      "batch 2391: loss 0.127836\n",
      "batch 2392: loss 0.031937\n",
      "batch 2393: loss 0.026629\n",
      "batch 2394: loss 0.160382\n",
      "batch 2395: loss 0.081667\n",
      "batch 2396: loss 0.085795\n",
      "batch 2397: loss 0.032263\n",
      "batch 2398: loss 0.192710\n",
      "batch 2399: loss 0.027166\n",
      "batch 2400: loss 0.299946\n",
      "batch 2401: loss 0.059628\n",
      "batch 2402: loss 0.091811\n",
      "batch 2403: loss 0.136583\n",
      "batch 2404: loss 0.160094\n",
      "batch 2405: loss 0.045468\n",
      "batch 2406: loss 0.223218\n",
      "batch 2407: loss 0.063835\n",
      "batch 2408: loss 0.107077\n",
      "batch 2409: loss 0.114452\n",
      "batch 2410: loss 0.114720\n",
      "batch 2411: loss 0.018390\n",
      "batch 2412: loss 0.026299\n",
      "batch 2413: loss 0.016554\n",
      "batch 2414: loss 0.058035\n",
      "batch 2415: loss 0.337246\n",
      "batch 2416: loss 0.084559\n",
      "batch 2417: loss 0.057163\n",
      "batch 2418: loss 0.054504\n",
      "batch 2419: loss 0.160604\n",
      "batch 2420: loss 0.143263\n",
      "batch 2421: loss 0.056300\n",
      "batch 2422: loss 0.148731\n",
      "batch 2423: loss 0.064516\n",
      "batch 2424: loss 0.021587\n",
      "batch 2425: loss 0.103178\n",
      "batch 2426: loss 0.052892\n",
      "batch 2427: loss 0.172546\n",
      "batch 2428: loss 0.139182\n",
      "batch 2429: loss 0.103654\n",
      "batch 2430: loss 0.148303\n",
      "batch 2431: loss 0.028508\n",
      "batch 2432: loss 0.066333\n",
      "batch 2433: loss 0.117288\n",
      "batch 2434: loss 0.272508\n",
      "batch 2435: loss 0.249329\n",
      "batch 2436: loss 0.066088\n",
      "batch 2437: loss 0.102223\n",
      "batch 2438: loss 0.267539\n",
      "batch 2439: loss 0.093952\n",
      "batch 2440: loss 0.081448\n",
      "batch 2441: loss 0.068677\n",
      "batch 2442: loss 0.070769\n",
      "batch 2443: loss 0.068727\n",
      "batch 2444: loss 0.055613\n",
      "batch 2445: loss 0.039559\n",
      "batch 2446: loss 0.082848\n",
      "batch 2447: loss 0.176986\n",
      "batch 2448: loss 0.098704\n",
      "batch 2449: loss 0.041496\n",
      "batch 2450: loss 0.053965\n",
      "batch 2451: loss 0.047805\n",
      "batch 2452: loss 0.078044\n",
      "batch 2453: loss 0.122669\n",
      "batch 2454: loss 0.098730\n",
      "batch 2455: loss 0.223295\n",
      "batch 2456: loss 0.130434\n",
      "batch 2457: loss 0.084960\n",
      "batch 2458: loss 0.055649\n",
      "batch 2459: loss 0.046071\n",
      "batch 2460: loss 0.221051\n",
      "batch 2461: loss 0.135608\n",
      "batch 2462: loss 0.060277\n",
      "batch 2463: loss 0.031264\n",
      "batch 2464: loss 0.021944\n",
      "batch 2465: loss 0.067913\n",
      "batch 2466: loss 0.069311\n",
      "batch 2467: loss 0.066275\n",
      "batch 2468: loss 0.048794\n",
      "batch 2469: loss 0.090374\n",
      "batch 2470: loss 0.230417\n",
      "batch 2471: loss 0.086590\n",
      "batch 2472: loss 0.113559\n",
      "batch 2473: loss 0.087350\n",
      "batch 2474: loss 0.089957\n",
      "batch 2475: loss 0.103984\n",
      "batch 2476: loss 0.075355\n",
      "batch 2477: loss 0.039717\n",
      "batch 2478: loss 0.128907\n",
      "batch 2479: loss 0.085504\n",
      "batch 2480: loss 0.129852\n",
      "batch 2481: loss 0.532389\n",
      "batch 2482: loss 0.035849\n",
      "batch 2483: loss 0.024852\n",
      "batch 2484: loss 0.034480\n",
      "batch 2485: loss 0.075259\n",
      "batch 2486: loss 0.198274\n",
      "batch 2487: loss 0.011570\n",
      "batch 2488: loss 0.172391\n",
      "batch 2489: loss 0.095944\n",
      "batch 2490: loss 0.122779\n",
      "batch 2491: loss 0.069324\n",
      "batch 2492: loss 0.282709\n",
      "batch 2493: loss 0.106500\n",
      "batch 2494: loss 0.084796\n",
      "batch 2495: loss 0.051395\n",
      "batch 2496: loss 0.279166\n",
      "batch 2497: loss 0.060432\n",
      "batch 2498: loss 0.155028\n",
      "batch 2499: loss 0.045331\n",
      "batch 2500: loss 0.047053\n",
      "batch 2501: loss 0.049339\n",
      "batch 2502: loss 0.082379\n",
      "batch 2503: loss 0.098651\n",
      "batch 2504: loss 0.185146\n",
      "batch 2505: loss 0.158927\n",
      "batch 2506: loss 0.029958\n",
      "batch 2507: loss 0.031162\n",
      "batch 2508: loss 0.064657\n",
      "batch 2509: loss 0.030137\n",
      "batch 2510: loss 0.017600\n",
      "batch 2511: loss 0.032393\n",
      "batch 2512: loss 0.043758\n",
      "batch 2513: loss 0.199450\n",
      "batch 2514: loss 0.305104\n",
      "batch 2515: loss 0.018992\n",
      "batch 2516: loss 0.034245\n",
      "batch 2517: loss 0.263792\n",
      "batch 2518: loss 0.080880\n",
      "batch 2519: loss 0.092868\n",
      "batch 2520: loss 0.040296\n",
      "batch 2521: loss 0.121026\n",
      "batch 2522: loss 0.103164\n",
      "batch 2523: loss 0.060054\n",
      "batch 2524: loss 0.023504\n",
      "batch 2525: loss 0.025811\n",
      "batch 2526: loss 0.021412\n",
      "batch 2527: loss 0.135712\n",
      "batch 2528: loss 0.225146\n",
      "batch 2529: loss 0.075808\n",
      "batch 2530: loss 0.078987\n",
      "batch 2531: loss 0.013250\n",
      "batch 2532: loss 0.212940\n",
      "batch 2533: loss 0.071301\n",
      "batch 2534: loss 0.075557\n",
      "batch 2535: loss 0.243442\n",
      "batch 2536: loss 0.059863\n",
      "batch 2537: loss 0.119613\n",
      "batch 2538: loss 0.035639\n",
      "batch 2539: loss 0.126201\n",
      "batch 2540: loss 0.086744\n",
      "batch 2541: loss 0.061347\n",
      "batch 2542: loss 0.040989\n",
      "batch 2543: loss 0.051113\n",
      "batch 2544: loss 0.148104\n",
      "batch 2545: loss 0.160198\n",
      "batch 2546: loss 0.102798\n",
      "batch 2547: loss 0.145002\n",
      "batch 2548: loss 0.034211\n",
      "batch 2549: loss 0.102330\n",
      "batch 2550: loss 0.147206\n",
      "batch 2551: loss 0.086819\n",
      "batch 2552: loss 0.057562\n",
      "batch 2553: loss 0.084739\n",
      "batch 2554: loss 0.217442\n",
      "batch 2555: loss 0.106178\n",
      "batch 2556: loss 0.045409\n",
      "batch 2557: loss 0.058358\n",
      "batch 2558: loss 0.052063\n",
      "batch 2559: loss 0.040028\n",
      "batch 2560: loss 0.061890\n",
      "batch 2561: loss 0.075350\n",
      "batch 2562: loss 0.053703\n",
      "batch 2563: loss 0.045061\n",
      "batch 2564: loss 0.224679\n",
      "batch 2565: loss 0.008484\n",
      "batch 2566: loss 0.181503\n",
      "batch 2567: loss 0.035575\n",
      "batch 2568: loss 0.168250\n",
      "batch 2569: loss 0.272990\n",
      "batch 2570: loss 0.071173\n",
      "batch 2571: loss 0.087032\n",
      "batch 2572: loss 0.252479\n",
      "batch 2573: loss 0.089117\n",
      "batch 2574: loss 0.180096\n",
      "batch 2575: loss 0.321606\n",
      "batch 2576: loss 0.122932\n",
      "batch 2577: loss 0.295165\n",
      "batch 2578: loss 0.263959\n",
      "batch 2579: loss 0.046056\n",
      "batch 2580: loss 0.232431\n",
      "batch 2581: loss 0.235182\n",
      "batch 2582: loss 0.075378\n",
      "batch 2583: loss 0.076434\n",
      "batch 2584: loss 0.225646\n",
      "batch 2585: loss 0.095534\n",
      "batch 2586: loss 0.012192\n",
      "batch 2587: loss 0.103733\n",
      "batch 2588: loss 0.096281\n",
      "batch 2589: loss 0.091747\n",
      "batch 2590: loss 0.040315\n",
      "batch 2591: loss 0.027104\n",
      "batch 2592: loss 0.097193\n",
      "batch 2593: loss 0.048960\n",
      "batch 2594: loss 0.079266\n",
      "batch 2595: loss 0.074640\n",
      "batch 2596: loss 0.063656\n",
      "batch 2597: loss 0.019384\n",
      "batch 2598: loss 0.079586\n",
      "batch 2599: loss 0.050431\n",
      "batch 2600: loss 0.018767\n",
      "batch 2601: loss 0.207168\n",
      "batch 2602: loss 0.057171\n",
      "batch 2603: loss 0.066058\n",
      "batch 2604: loss 0.043654\n",
      "batch 2605: loss 0.019961\n",
      "batch 2606: loss 0.078044\n",
      "batch 2607: loss 0.072933\n",
      "batch 2608: loss 0.186388\n",
      "batch 2609: loss 0.223293\n",
      "batch 2610: loss 0.128552\n",
      "batch 2611: loss 0.134288\n",
      "batch 2612: loss 0.120954\n",
      "batch 2613: loss 0.127884\n",
      "batch 2614: loss 0.377913\n",
      "batch 2615: loss 0.168556\n",
      "batch 2616: loss 0.052463\n",
      "batch 2617: loss 0.066828\n",
      "batch 2618: loss 0.066764\n",
      "batch 2619: loss 0.064649\n",
      "batch 2620: loss 0.031298\n",
      "batch 2621: loss 0.122008\n",
      "batch 2622: loss 0.079328\n",
      "batch 2623: loss 0.084037\n",
      "batch 2624: loss 0.182535\n",
      "batch 2625: loss 0.173753\n",
      "batch 2626: loss 0.240303\n",
      "batch 2627: loss 0.045639\n",
      "batch 2628: loss 0.054926\n",
      "batch 2629: loss 0.221943\n",
      "batch 2630: loss 0.074628\n",
      "batch 2631: loss 0.080622\n",
      "batch 2632: loss 0.039855\n",
      "batch 2633: loss 0.061791\n",
      "batch 2634: loss 0.026204\n",
      "batch 2635: loss 0.085556\n",
      "batch 2636: loss 0.022734\n",
      "batch 2637: loss 0.051841\n",
      "batch 2638: loss 0.366640\n",
      "batch 2639: loss 0.199249\n",
      "batch 2640: loss 0.026555\n",
      "batch 2641: loss 0.075387\n",
      "batch 2642: loss 0.086091\n",
      "batch 2643: loss 0.056575\n",
      "batch 2644: loss 0.042796\n",
      "batch 2645: loss 0.050720\n",
      "batch 2646: loss 0.026087\n",
      "batch 2647: loss 0.081924\n",
      "batch 2648: loss 0.005093\n",
      "batch 2649: loss 0.083963\n",
      "batch 2650: loss 0.214113\n",
      "batch 2651: loss 0.038518\n",
      "batch 2652: loss 0.041347\n",
      "batch 2653: loss 0.074167\n",
      "batch 2654: loss 0.075183\n",
      "batch 2655: loss 0.027921\n",
      "batch 2656: loss 0.121406\n",
      "batch 2657: loss 0.054197\n",
      "batch 2658: loss 0.149512\n",
      "batch 2659: loss 0.047477\n",
      "batch 2660: loss 0.097603\n",
      "batch 2661: loss 0.186620\n",
      "batch 2662: loss 0.218869\n",
      "batch 2663: loss 0.066474\n",
      "batch 2664: loss 0.205245\n",
      "batch 2665: loss 0.103581\n",
      "batch 2666: loss 0.175083\n",
      "batch 2667: loss 0.263527\n",
      "batch 2668: loss 0.099115\n",
      "batch 2669: loss 0.164806\n",
      "batch 2670: loss 0.045976\n",
      "batch 2671: loss 0.010959\n",
      "batch 2672: loss 0.276209\n",
      "batch 2673: loss 0.072132\n",
      "batch 2674: loss 0.019498\n",
      "batch 2675: loss 0.030341\n",
      "batch 2676: loss 0.052462\n",
      "batch 2677: loss 0.155079\n",
      "batch 2678: loss 0.411192\n",
      "batch 2679: loss 0.039440\n",
      "batch 2680: loss 0.150992\n",
      "batch 2681: loss 0.052108\n",
      "batch 2682: loss 0.141172\n",
      "batch 2683: loss 0.101823\n",
      "batch 2684: loss 0.106945\n",
      "batch 2685: loss 0.030915\n",
      "batch 2686: loss 0.042446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2687: loss 0.028768\n",
      "batch 2688: loss 0.109817\n",
      "batch 2689: loss 0.080873\n",
      "batch 2690: loss 0.021700\n",
      "batch 2691: loss 0.072432\n",
      "batch 2692: loss 0.064206\n",
      "batch 2693: loss 0.025222\n",
      "batch 2694: loss 0.086307\n",
      "batch 2695: loss 0.076004\n",
      "batch 2696: loss 0.012480\n",
      "batch 2697: loss 0.052197\n",
      "batch 2698: loss 0.049579\n",
      "batch 2699: loss 0.242408\n",
      "batch 2700: loss 0.047452\n",
      "batch 2701: loss 0.027878\n",
      "batch 2702: loss 0.116016\n",
      "batch 2703: loss 0.132081\n",
      "batch 2704: loss 0.139559\n",
      "batch 2705: loss 0.021431\n",
      "batch 2706: loss 0.088694\n",
      "batch 2707: loss 0.041103\n",
      "batch 2708: loss 0.056534\n",
      "batch 2709: loss 0.116160\n",
      "batch 2710: loss 0.073084\n",
      "batch 2711: loss 0.085825\n",
      "batch 2712: loss 0.216167\n",
      "batch 2713: loss 0.072352\n",
      "batch 2714: loss 0.031419\n",
      "batch 2715: loss 0.066066\n",
      "batch 2716: loss 0.019459\n",
      "batch 2717: loss 0.184787\n",
      "batch 2718: loss 0.076269\n",
      "batch 2719: loss 0.051924\n",
      "batch 2720: loss 0.125162\n",
      "batch 2721: loss 0.030660\n",
      "batch 2722: loss 0.048597\n",
      "batch 2723: loss 0.049259\n",
      "batch 2724: loss 0.025952\n",
      "batch 2725: loss 0.114467\n",
      "batch 2726: loss 0.131761\n",
      "batch 2727: loss 0.041941\n",
      "batch 2728: loss 0.154542\n",
      "batch 2729: loss 0.103283\n",
      "batch 2730: loss 0.016980\n",
      "batch 2731: loss 0.139704\n",
      "batch 2732: loss 0.077158\n",
      "batch 2733: loss 0.032948\n",
      "batch 2734: loss 0.055096\n",
      "batch 2735: loss 0.089001\n",
      "batch 2736: loss 0.038194\n",
      "batch 2737: loss 0.146887\n",
      "batch 2738: loss 0.152269\n",
      "batch 2739: loss 0.163707\n",
      "batch 2740: loss 0.217705\n",
      "batch 2741: loss 0.103042\n",
      "batch 2742: loss 0.053107\n",
      "batch 2743: loss 0.023656\n",
      "batch 2744: loss 0.213464\n",
      "batch 2745: loss 0.033542\n",
      "batch 2746: loss 0.051066\n",
      "batch 2747: loss 0.098994\n",
      "batch 2748: loss 0.010636\n",
      "batch 2749: loss 0.069842\n",
      "batch 2750: loss 0.107309\n",
      "batch 2751: loss 0.090575\n",
      "batch 2752: loss 0.323545\n",
      "batch 2753: loss 0.033682\n",
      "batch 2754: loss 0.093118\n",
      "batch 2755: loss 0.021379\n",
      "batch 2756: loss 0.072564\n",
      "batch 2757: loss 0.033986\n",
      "batch 2758: loss 0.069055\n",
      "batch 2759: loss 0.265291\n",
      "batch 2760: loss 0.020133\n",
      "batch 2761: loss 0.107858\n",
      "batch 2762: loss 0.011347\n",
      "batch 2763: loss 0.061790\n",
      "batch 2764: loss 0.073428\n",
      "batch 2765: loss 0.195944\n",
      "batch 2766: loss 0.134393\n",
      "batch 2767: loss 0.244656\n",
      "batch 2768: loss 0.096834\n",
      "batch 2769: loss 0.174030\n",
      "batch 2770: loss 0.151164\n",
      "batch 2771: loss 0.162339\n",
      "batch 2772: loss 0.087259\n",
      "batch 2773: loss 0.021174\n",
      "batch 2774: loss 0.013612\n",
      "batch 2775: loss 0.046420\n",
      "batch 2776: loss 0.020252\n",
      "batch 2777: loss 0.057282\n",
      "batch 2778: loss 0.118500\n",
      "batch 2779: loss 0.036760\n",
      "batch 2780: loss 0.031499\n",
      "batch 2781: loss 0.278246\n",
      "batch 2782: loss 0.018576\n",
      "batch 2783: loss 0.080681\n",
      "batch 2784: loss 0.024597\n",
      "batch 2785: loss 0.138810\n",
      "batch 2786: loss 0.180160\n",
      "batch 2787: loss 0.098265\n",
      "batch 2788: loss 0.076622\n",
      "batch 2789: loss 0.027712\n",
      "batch 2790: loss 0.041467\n",
      "batch 2791: loss 0.062964\n",
      "batch 2792: loss 0.038789\n",
      "batch 2793: loss 0.052878\n",
      "batch 2794: loss 0.033360\n",
      "batch 2795: loss 0.103742\n",
      "batch 2796: loss 0.077812\n",
      "batch 2797: loss 0.014101\n",
      "batch 2798: loss 0.049863\n",
      "batch 2799: loss 0.024090\n",
      "batch 2800: loss 0.018554\n",
      "batch 2801: loss 0.166142\n",
      "batch 2802: loss 0.085072\n",
      "batch 2803: loss 0.076116\n",
      "batch 2804: loss 0.045481\n",
      "batch 2805: loss 0.389687\n",
      "batch 2806: loss 0.036509\n",
      "batch 2807: loss 0.061281\n",
      "batch 2808: loss 0.196586\n",
      "batch 2809: loss 0.404189\n",
      "batch 2810: loss 0.202378\n",
      "batch 2811: loss 0.098078\n",
      "batch 2812: loss 0.121532\n",
      "batch 2813: loss 0.023463\n",
      "batch 2814: loss 0.110933\n",
      "batch 2815: loss 0.074822\n",
      "batch 2816: loss 0.145986\n",
      "batch 2817: loss 0.119786\n",
      "batch 2818: loss 0.030263\n",
      "batch 2819: loss 0.114547\n",
      "batch 2820: loss 0.148189\n",
      "batch 2821: loss 0.091515\n",
      "batch 2822: loss 0.183241\n",
      "batch 2823: loss 0.129224\n",
      "batch 2824: loss 0.047590\n",
      "batch 2825: loss 0.167837\n",
      "batch 2826: loss 0.190887\n",
      "batch 2827: loss 0.058874\n",
      "batch 2828: loss 0.201495\n",
      "batch 2829: loss 0.021251\n",
      "batch 2830: loss 0.017729\n",
      "batch 2831: loss 0.015696\n",
      "batch 2832: loss 0.027277\n",
      "batch 2833: loss 0.275841\n",
      "batch 2834: loss 0.200554\n",
      "batch 2835: loss 0.121380\n",
      "batch 2836: loss 0.088149\n",
      "batch 2837: loss 0.067990\n",
      "batch 2838: loss 0.195236\n",
      "batch 2839: loss 0.021929\n",
      "batch 2840: loss 0.204308\n",
      "batch 2841: loss 0.083534\n",
      "batch 2842: loss 0.354033\n",
      "batch 2843: loss 0.080757\n",
      "batch 2844: loss 0.062283\n",
      "batch 2845: loss 0.163320\n",
      "batch 2846: loss 0.100184\n",
      "batch 2847: loss 0.032223\n",
      "batch 2848: loss 0.093594\n",
      "batch 2849: loss 0.057541\n",
      "batch 2850: loss 0.049020\n",
      "batch 2851: loss 0.093398\n",
      "batch 2852: loss 0.022530\n",
      "batch 2853: loss 0.038851\n",
      "batch 2854: loss 0.127325\n",
      "batch 2855: loss 0.116655\n",
      "batch 2856: loss 0.200275\n",
      "batch 2857: loss 0.059475\n",
      "batch 2858: loss 0.060934\n",
      "batch 2859: loss 0.072047\n",
      "batch 2860: loss 0.078035\n",
      "batch 2861: loss 0.023714\n",
      "batch 2862: loss 0.083696\n",
      "batch 2863: loss 0.228650\n",
      "batch 2864: loss 0.031141\n",
      "batch 2865: loss 0.361877\n",
      "batch 2866: loss 0.055243\n",
      "batch 2867: loss 0.124214\n",
      "batch 2868: loss 0.103137\n",
      "batch 2869: loss 0.067318\n",
      "batch 2870: loss 0.058143\n",
      "batch 2871: loss 0.026993\n",
      "batch 2872: loss 0.130155\n",
      "batch 2873: loss 0.161068\n",
      "batch 2874: loss 0.046379\n",
      "batch 2875: loss 0.130423\n",
      "batch 2876: loss 0.227209\n",
      "batch 2877: loss 0.093978\n",
      "batch 2878: loss 0.061708\n",
      "batch 2879: loss 0.160648\n",
      "batch 2880: loss 0.169250\n",
      "batch 2881: loss 0.110924\n",
      "batch 2882: loss 0.034668\n",
      "batch 2883: loss 0.053320\n",
      "batch 2884: loss 0.098780\n",
      "batch 2885: loss 0.034606\n",
      "batch 2886: loss 0.241529\n",
      "batch 2887: loss 0.174010\n",
      "batch 2888: loss 0.021673\n",
      "batch 2889: loss 0.040772\n",
      "batch 2890: loss 0.011019\n",
      "batch 2891: loss 0.034556\n",
      "batch 2892: loss 0.063461\n",
      "batch 2893: loss 0.075393\n",
      "batch 2894: loss 0.145686\n",
      "batch 2895: loss 0.032362\n",
      "batch 2896: loss 0.191794\n",
      "batch 2897: loss 0.035871\n",
      "batch 2898: loss 0.039696\n",
      "batch 2899: loss 0.092671\n",
      "batch 2900: loss 0.011927\n",
      "batch 2901: loss 0.060925\n",
      "batch 2902: loss 0.060792\n",
      "batch 2903: loss 0.021422\n",
      "batch 2904: loss 0.062075\n",
      "batch 2905: loss 0.126445\n",
      "batch 2906: loss 0.056024\n",
      "batch 2907: loss 0.329158\n",
      "batch 2908: loss 0.032508\n",
      "batch 2909: loss 0.071884\n",
      "batch 2910: loss 0.011978\n",
      "batch 2911: loss 0.075614\n",
      "batch 2912: loss 0.022844\n",
      "batch 2913: loss 0.112139\n",
      "batch 2914: loss 0.124906\n",
      "batch 2915: loss 0.087351\n",
      "batch 2916: loss 0.056564\n",
      "batch 2917: loss 0.212883\n",
      "batch 2918: loss 0.129979\n",
      "batch 2919: loss 0.108199\n",
      "batch 2920: loss 0.068716\n",
      "batch 2921: loss 0.030117\n",
      "batch 2922: loss 0.028244\n",
      "batch 2923: loss 0.044450\n",
      "batch 2924: loss 0.065820\n",
      "batch 2925: loss 0.049309\n",
      "batch 2926: loss 0.215679\n",
      "batch 2927: loss 0.030543\n",
      "batch 2928: loss 0.057434\n",
      "batch 2929: loss 0.044407\n",
      "batch 2930: loss 0.098876\n",
      "batch 2931: loss 0.059076\n",
      "batch 2932: loss 0.141860\n",
      "batch 2933: loss 0.047735\n",
      "batch 2934: loss 0.046093\n",
      "batch 2935: loss 0.216822\n",
      "batch 2936: loss 0.124036\n",
      "batch 2937: loss 0.052517\n",
      "batch 2938: loss 0.012869\n",
      "batch 2939: loss 0.022651\n",
      "batch 2940: loss 0.077196\n",
      "batch 2941: loss 0.023928\n",
      "batch 2942: loss 0.046859\n",
      "batch 2943: loss 0.125758\n",
      "batch 2944: loss 0.075842\n",
      "batch 2945: loss 0.090213\n",
      "batch 2946: loss 0.029636\n",
      "batch 2947: loss 0.021327\n",
      "batch 2948: loss 0.140992\n",
      "batch 2949: loss 0.076439\n",
      "batch 2950: loss 0.092747\n",
      "batch 2951: loss 0.187800\n",
      "batch 2952: loss 0.049546\n",
      "batch 2953: loss 0.174361\n",
      "batch 2954: loss 0.036571\n",
      "batch 2955: loss 0.023338\n",
      "batch 2956: loss 0.019760\n",
      "batch 2957: loss 0.032314\n",
      "batch 2958: loss 0.011348\n",
      "batch 2959: loss 0.015709\n",
      "batch 2960: loss 0.110568\n",
      "batch 2961: loss 0.150268\n",
      "batch 2962: loss 0.073073\n",
      "batch 2963: loss 0.101031\n",
      "batch 2964: loss 0.035712\n",
      "batch 2965: loss 0.012690\n",
      "batch 2966: loss 0.097220\n",
      "batch 2967: loss 0.254800\n",
      "batch 2968: loss 0.131337\n",
      "batch 2969: loss 0.065782\n",
      "batch 2970: loss 0.089454\n",
      "batch 2971: loss 0.088535\n",
      "batch 2972: loss 0.102968\n",
      "batch 2973: loss 0.133423\n",
      "batch 2974: loss 0.069229\n",
      "batch 2975: loss 0.229779\n",
      "batch 2976: loss 0.432796\n",
      "batch 2977: loss 0.080832\n",
      "batch 2978: loss 0.035334\n",
      "batch 2979: loss 0.083238\n",
      "batch 2980: loss 0.200461\n",
      "batch 2981: loss 0.022779\n",
      "batch 2982: loss 0.273351\n",
      "batch 2983: loss 0.245378\n",
      "batch 2984: loss 0.054684\n",
      "batch 2985: loss 0.228091\n",
      "batch 2986: loss 0.029632\n",
      "batch 2987: loss 0.057717\n",
      "batch 2988: loss 0.156689\n",
      "batch 2989: loss 0.271015\n",
      "batch 2990: loss 0.176939\n",
      "batch 2991: loss 0.208331\n",
      "batch 2992: loss 0.014914\n",
      "batch 2993: loss 0.113216\n",
      "batch 2994: loss 0.033360\n",
      "batch 2995: loss 0.131602\n",
      "batch 2996: loss 0.359298\n",
      "batch 2997: loss 0.045382\n",
      "batch 2998: loss 0.057709\n",
      "batch 2999: loss 0.050693\n",
      "batch 3000: loss 0.084679\n",
      "batch 3001: loss 0.068167\n",
      "batch 3002: loss 0.061237\n",
      "batch 3003: loss 0.046377\n",
      "batch 3004: loss 0.238465\n",
      "batch 3005: loss 0.045394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3006: loss 0.096236\n",
      "batch 3007: loss 0.129393\n",
      "batch 3008: loss 0.136235\n",
      "batch 3009: loss 0.023810\n",
      "batch 3010: loss 0.073841\n",
      "batch 3011: loss 0.075305\n",
      "batch 3012: loss 0.149539\n",
      "batch 3013: loss 0.239087\n",
      "batch 3014: loss 0.033588\n",
      "batch 3015: loss 0.049844\n",
      "batch 3016: loss 0.170665\n",
      "batch 3017: loss 0.167267\n",
      "batch 3018: loss 0.084633\n",
      "batch 3019: loss 0.128367\n",
      "batch 3020: loss 0.308781\n",
      "batch 3021: loss 0.112713\n",
      "batch 3022: loss 0.121767\n",
      "batch 3023: loss 0.239170\n",
      "batch 3024: loss 0.055598\n",
      "batch 3025: loss 0.095566\n",
      "batch 3026: loss 0.056912\n",
      "batch 3027: loss 0.047629\n",
      "batch 3028: loss 0.240995\n",
      "batch 3029: loss 0.096922\n",
      "batch 3030: loss 0.118793\n",
      "batch 3031: loss 0.167329\n",
      "batch 3032: loss 0.023292\n",
      "batch 3033: loss 0.206107\n",
      "batch 3034: loss 0.115127\n",
      "batch 3035: loss 0.130066\n",
      "batch 3036: loss 0.023799\n",
      "batch 3037: loss 0.142039\n",
      "batch 3038: loss 0.073479\n",
      "batch 3039: loss 0.029860\n",
      "batch 3040: loss 0.048749\n",
      "batch 3041: loss 0.249323\n",
      "batch 3042: loss 0.032497\n",
      "batch 3043: loss 0.150842\n",
      "batch 3044: loss 0.079552\n",
      "batch 3045: loss 0.061019\n",
      "batch 3046: loss 0.051094\n",
      "batch 3047: loss 0.279224\n",
      "batch 3048: loss 0.095475\n",
      "batch 3049: loss 0.082582\n",
      "batch 3050: loss 0.253894\n",
      "batch 3051: loss 0.072154\n",
      "batch 3052: loss 0.272525\n",
      "batch 3053: loss 0.056880\n",
      "batch 3054: loss 0.067890\n",
      "batch 3055: loss 0.284676\n",
      "batch 3056: loss 0.126851\n",
      "batch 3057: loss 0.095286\n",
      "batch 3058: loss 0.055899\n",
      "batch 3059: loss 0.139703\n",
      "batch 3060: loss 0.071712\n",
      "batch 3061: loss 0.027502\n",
      "batch 3062: loss 0.075636\n",
      "batch 3063: loss 0.077433\n",
      "batch 3064: loss 0.073602\n",
      "batch 3065: loss 0.152145\n",
      "batch 3066: loss 0.087680\n",
      "batch 3067: loss 0.034013\n",
      "batch 3068: loss 0.047860\n",
      "batch 3069: loss 0.021973\n",
      "batch 3070: loss 0.054844\n",
      "batch 3071: loss 0.049672\n",
      "batch 3072: loss 0.042548\n",
      "batch 3073: loss 0.100996\n",
      "batch 3074: loss 0.071907\n",
      "batch 3075: loss 0.055240\n",
      "batch 3076: loss 0.040521\n",
      "batch 3077: loss 0.226903\n",
      "batch 3078: loss 0.152684\n",
      "batch 3079: loss 0.082207\n",
      "batch 3080: loss 0.021250\n",
      "batch 3081: loss 0.082661\n",
      "batch 3082: loss 0.234143\n",
      "batch 3083: loss 0.020646\n",
      "batch 3084: loss 0.236016\n",
      "batch 3085: loss 0.031795\n",
      "batch 3086: loss 0.092275\n",
      "batch 3087: loss 0.060587\n",
      "batch 3088: loss 0.075290\n",
      "batch 3089: loss 0.079683\n",
      "batch 3090: loss 0.030546\n",
      "batch 3091: loss 0.020572\n",
      "batch 3092: loss 0.188393\n",
      "batch 3093: loss 0.281987\n",
      "batch 3094: loss 0.019117\n",
      "batch 3095: loss 0.104440\n",
      "batch 3096: loss 0.011079\n",
      "batch 3097: loss 0.148126\n",
      "batch 3098: loss 0.140539\n",
      "batch 3099: loss 0.048450\n",
      "batch 3100: loss 0.047516\n",
      "batch 3101: loss 0.099950\n",
      "batch 3102: loss 0.051672\n",
      "batch 3103: loss 0.160783\n",
      "batch 3104: loss 0.109210\n",
      "batch 3105: loss 0.079444\n",
      "batch 3106: loss 0.129516\n",
      "batch 3107: loss 0.029555\n",
      "batch 3108: loss 0.025625\n",
      "batch 3109: loss 0.045818\n",
      "batch 3110: loss 0.173037\n",
      "batch 3111: loss 0.106102\n",
      "batch 3112: loss 0.039537\n",
      "batch 3113: loss 0.112300\n",
      "batch 3114: loss 0.043538\n",
      "batch 3115: loss 0.039519\n",
      "batch 3116: loss 0.036869\n",
      "batch 3117: loss 0.058616\n",
      "batch 3118: loss 0.080238\n",
      "batch 3119: loss 0.064484\n",
      "batch 3120: loss 0.057272\n",
      "batch 3121: loss 0.082977\n",
      "batch 3122: loss 0.037319\n",
      "batch 3123: loss 0.023005\n",
      "batch 3124: loss 0.082738\n",
      "batch 3125: loss 0.008469\n",
      "batch 3126: loss 0.082086\n",
      "batch 3127: loss 0.156261\n",
      "batch 3128: loss 0.014924\n",
      "batch 3129: loss 0.151378\n",
      "batch 3130: loss 0.092572\n",
      "batch 3131: loss 0.255324\n",
      "batch 3132: loss 0.136289\n",
      "batch 3133: loss 0.043428\n",
      "batch 3134: loss 0.078513\n",
      "batch 3135: loss 0.012464\n",
      "batch 3136: loss 0.040068\n",
      "batch 3137: loss 0.082510\n",
      "batch 3138: loss 0.133224\n",
      "batch 3139: loss 0.159512\n",
      "batch 3140: loss 0.036394\n",
      "batch 3141: loss 0.080671\n",
      "batch 3142: loss 0.086128\n",
      "batch 3143: loss 0.022049\n",
      "batch 3144: loss 0.033822\n",
      "batch 3145: loss 0.087817\n",
      "batch 3146: loss 0.099330\n",
      "batch 3147: loss 0.099372\n",
      "batch 3148: loss 0.099541\n",
      "batch 3149: loss 0.088491\n",
      "batch 3150: loss 0.121785\n",
      "batch 3151: loss 0.035295\n",
      "batch 3152: loss 0.258943\n",
      "batch 3153: loss 0.164397\n",
      "batch 3154: loss 0.143037\n",
      "batch 3155: loss 0.088987\n",
      "batch 3156: loss 0.028429\n",
      "batch 3157: loss 0.038978\n",
      "batch 3158: loss 0.327265\n",
      "batch 3159: loss 0.148240\n",
      "batch 3160: loss 0.085088\n",
      "batch 3161: loss 0.020945\n",
      "batch 3162: loss 0.067011\n",
      "batch 3163: loss 0.066398\n",
      "batch 3164: loss 0.087367\n",
      "batch 3165: loss 0.081472\n",
      "batch 3166: loss 0.059355\n",
      "batch 3167: loss 0.127481\n",
      "batch 3168: loss 0.069596\n",
      "batch 3169: loss 0.095916\n",
      "batch 3170: loss 0.132886\n",
      "batch 3171: loss 0.250157\n",
      "batch 3172: loss 0.102891\n",
      "batch 3173: loss 0.151768\n",
      "batch 3174: loss 0.038465\n",
      "batch 3175: loss 0.178148\n",
      "batch 3176: loss 0.053438\n",
      "batch 3177: loss 0.101095\n",
      "batch 3178: loss 0.038969\n",
      "batch 3179: loss 0.123485\n",
      "batch 3180: loss 0.078153\n",
      "batch 3181: loss 0.078118\n",
      "batch 3182: loss 0.036270\n",
      "batch 3183: loss 0.041495\n",
      "batch 3184: loss 0.242698\n",
      "batch 3185: loss 0.060639\n",
      "batch 3186: loss 0.105803\n",
      "batch 3187: loss 0.041359\n",
      "batch 3188: loss 0.131970\n",
      "batch 3189: loss 0.049337\n",
      "batch 3190: loss 0.062742\n",
      "batch 3191: loss 0.161085\n",
      "batch 3192: loss 0.109938\n",
      "batch 3193: loss 0.088421\n",
      "batch 3194: loss 0.015814\n",
      "batch 3195: loss 0.061449\n",
      "batch 3196: loss 0.011941\n",
      "batch 3197: loss 0.087861\n",
      "batch 3198: loss 0.015577\n",
      "batch 3199: loss 0.112514\n",
      "batch 3200: loss 0.107888\n",
      "batch 3201: loss 0.170080\n",
      "batch 3202: loss 0.056601\n",
      "batch 3203: loss 0.131561\n",
      "batch 3204: loss 0.038142\n",
      "batch 3205: loss 0.099947\n",
      "batch 3206: loss 0.102634\n",
      "batch 3207: loss 0.101718\n",
      "batch 3208: loss 0.049255\n",
      "batch 3209: loss 0.052322\n",
      "batch 3210: loss 0.174062\n",
      "batch 3211: loss 0.248032\n",
      "batch 3212: loss 0.113688\n",
      "batch 3213: loss 0.163144\n",
      "batch 3214: loss 0.080065\n",
      "batch 3215: loss 0.061891\n",
      "batch 3216: loss 0.076058\n",
      "batch 3217: loss 0.092313\n",
      "batch 3218: loss 0.128774\n",
      "batch 3219: loss 0.030842\n",
      "batch 3220: loss 0.019272\n",
      "batch 3221: loss 0.124553\n",
      "batch 3222: loss 0.228819\n",
      "batch 3223: loss 0.019213\n",
      "batch 3224: loss 0.032035\n",
      "batch 3225: loss 0.111661\n",
      "batch 3226: loss 0.022112\n",
      "batch 3227: loss 0.031507\n",
      "batch 3228: loss 0.125689\n",
      "batch 3229: loss 0.156410\n",
      "batch 3230: loss 0.023489\n",
      "batch 3231: loss 0.013162\n",
      "batch 3232: loss 0.049498\n",
      "batch 3233: loss 0.187169\n",
      "batch 3234: loss 0.018938\n",
      "batch 3235: loss 0.462474\n",
      "batch 3236: loss 0.047503\n",
      "batch 3237: loss 0.089395\n",
      "batch 3238: loss 0.063782\n",
      "batch 3239: loss 0.008009\n",
      "batch 3240: loss 0.030183\n",
      "batch 3241: loss 0.121020\n",
      "batch 3242: loss 0.123787\n",
      "batch 3243: loss 0.180756\n",
      "batch 3244: loss 0.209407\n",
      "batch 3245: loss 0.090514\n",
      "batch 3246: loss 0.010834\n",
      "batch 3247: loss 0.070779\n",
      "batch 3248: loss 0.109157\n",
      "batch 3249: loss 0.052457\n",
      "batch 3250: loss 0.101232\n",
      "batch 3251: loss 0.129104\n",
      "batch 3252: loss 0.146818\n",
      "batch 3253: loss 0.407633\n",
      "batch 3254: loss 0.186597\n",
      "batch 3255: loss 0.026729\n",
      "batch 3256: loss 0.066536\n",
      "batch 3257: loss 0.091061\n",
      "batch 3258: loss 0.129364\n",
      "batch 3259: loss 0.046759\n",
      "batch 3260: loss 0.016277\n",
      "batch 3261: loss 0.051515\n",
      "batch 3262: loss 0.005242\n",
      "batch 3263: loss 0.077839\n",
      "batch 3264: loss 0.207316\n",
      "batch 3265: loss 0.113528\n",
      "batch 3266: loss 0.122476\n",
      "batch 3267: loss 0.013749\n",
      "batch 3268: loss 0.159116\n",
      "batch 3269: loss 0.046627\n",
      "batch 3270: loss 0.068953\n",
      "batch 3271: loss 0.149068\n",
      "batch 3272: loss 0.032076\n",
      "batch 3273: loss 0.029744\n",
      "batch 3274: loss 0.035200\n",
      "batch 3275: loss 0.188296\n",
      "batch 3276: loss 0.020162\n",
      "batch 3277: loss 0.048945\n",
      "batch 3278: loss 0.020503\n",
      "batch 3279: loss 0.203882\n",
      "batch 3280: loss 0.047006\n",
      "batch 3281: loss 0.073703\n",
      "batch 3282: loss 0.028351\n",
      "batch 3283: loss 0.137394\n",
      "batch 3284: loss 0.059380\n",
      "batch 3285: loss 0.007481\n",
      "batch 3286: loss 0.050480\n",
      "batch 3287: loss 0.112815\n",
      "batch 3288: loss 0.245667\n",
      "batch 3289: loss 0.120228\n",
      "batch 3290: loss 0.032761\n",
      "batch 3291: loss 0.105488\n",
      "batch 3292: loss 0.017758\n",
      "batch 3293: loss 0.038911\n",
      "batch 3294: loss 0.091934\n",
      "batch 3295: loss 0.330498\n",
      "batch 3296: loss 0.063866\n",
      "batch 3297: loss 0.035142\n",
      "batch 3298: loss 0.214091\n",
      "batch 3299: loss 0.126042\n",
      "batch 3300: loss 0.123097\n",
      "batch 3301: loss 0.021738\n",
      "batch 3302: loss 0.086103\n",
      "batch 3303: loss 0.082752\n",
      "batch 3304: loss 0.271581\n",
      "batch 3305: loss 0.024572\n",
      "batch 3306: loss 0.053319\n",
      "batch 3307: loss 0.113762\n",
      "batch 3308: loss 0.046204\n",
      "batch 3309: loss 0.051437\n",
      "batch 3310: loss 0.062453\n",
      "batch 3311: loss 0.125869\n",
      "batch 3312: loss 0.016045\n",
      "batch 3313: loss 0.010356\n",
      "batch 3314: loss 0.075110\n",
      "batch 3315: loss 0.050828\n",
      "batch 3316: loss 0.017976\n",
      "batch 3317: loss 0.027377\n",
      "batch 3318: loss 0.011769\n",
      "batch 3319: loss 0.036581\n",
      "batch 3320: loss 0.029645\n",
      "batch 3321: loss 0.219111\n",
      "batch 3322: loss 0.037104\n",
      "batch 3323: loss 0.020114\n",
      "batch 3324: loss 0.119559\n",
      "batch 3325: loss 0.027794\n",
      "batch 3326: loss 0.029863\n",
      "batch 3327: loss 0.057761\n",
      "batch 3328: loss 0.020668\n",
      "batch 3329: loss 0.124402\n",
      "batch 3330: loss 0.123197\n",
      "batch 3331: loss 0.107396\n",
      "batch 3332: loss 0.061306\n",
      "batch 3333: loss 0.116415\n",
      "batch 3334: loss 0.171831\n",
      "batch 3335: loss 0.067351\n",
      "batch 3336: loss 0.406753\n",
      "batch 3337: loss 0.019923\n",
      "batch 3338: loss 0.152440\n",
      "batch 3339: loss 0.386701\n",
      "batch 3340: loss 0.093454\n",
      "batch 3341: loss 0.012756\n",
      "batch 3342: loss 0.040838\n",
      "batch 3343: loss 0.062291\n",
      "batch 3344: loss 0.092080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3345: loss 0.186221\n",
      "batch 3346: loss 0.041424\n",
      "batch 3347: loss 0.011100\n",
      "batch 3348: loss 0.094803\n",
      "batch 3349: loss 0.087771\n",
      "batch 3350: loss 0.084402\n",
      "batch 3351: loss 0.088635\n",
      "batch 3352: loss 0.046262\n",
      "batch 3353: loss 0.057244\n",
      "batch 3354: loss 0.145244\n",
      "batch 3355: loss 0.028458\n",
      "batch 3356: loss 0.079486\n",
      "batch 3357: loss 0.039799\n",
      "batch 3358: loss 0.010903\n",
      "batch 3359: loss 0.037818\n",
      "batch 3360: loss 0.024161\n",
      "batch 3361: loss 0.020602\n",
      "batch 3362: loss 0.014053\n",
      "batch 3363: loss 0.018965\n",
      "batch 3364: loss 0.009781\n",
      "batch 3365: loss 0.025024\n",
      "batch 3366: loss 0.169363\n",
      "batch 3367: loss 0.084732\n",
      "batch 3368: loss 0.135589\n",
      "batch 3369: loss 0.086258\n",
      "batch 3370: loss 0.034436\n",
      "batch 3371: loss 0.078822\n",
      "batch 3372: loss 0.017730\n",
      "batch 3373: loss 0.192898\n",
      "batch 3374: loss 0.024876\n",
      "batch 3375: loss 0.005026\n",
      "batch 3376: loss 0.014920\n",
      "batch 3377: loss 0.122432\n",
      "batch 3378: loss 0.148401\n",
      "batch 3379: loss 0.079168\n",
      "batch 3380: loss 0.110325\n",
      "batch 3381: loss 0.023531\n",
      "batch 3382: loss 0.055226\n",
      "batch 3383: loss 0.231282\n",
      "batch 3384: loss 0.148027\n",
      "batch 3385: loss 0.020913\n",
      "batch 3386: loss 0.082138\n",
      "batch 3387: loss 0.297603\n",
      "batch 3388: loss 0.042656\n",
      "batch 3389: loss 0.045368\n",
      "batch 3390: loss 0.024387\n",
      "batch 3391: loss 0.122682\n",
      "batch 3392: loss 0.081933\n",
      "batch 3393: loss 0.031723\n",
      "batch 3394: loss 0.067804\n",
      "batch 3395: loss 0.094340\n",
      "batch 3396: loss 0.118839\n",
      "batch 3397: loss 0.131426\n",
      "batch 3398: loss 0.215578\n",
      "batch 3399: loss 0.173848\n",
      "batch 3400: loss 0.054627\n",
      "batch 3401: loss 0.050676\n",
      "batch 3402: loss 0.053166\n",
      "batch 3403: loss 0.039140\n",
      "batch 3404: loss 0.043197\n",
      "batch 3405: loss 0.029928\n",
      "batch 3406: loss 0.021741\n",
      "batch 3407: loss 0.115866\n",
      "batch 3408: loss 0.021769\n",
      "batch 3409: loss 0.029796\n",
      "batch 3410: loss 0.015498\n",
      "batch 3411: loss 0.050184\n",
      "batch 3412: loss 0.044076\n",
      "batch 3413: loss 0.043327\n",
      "batch 3414: loss 0.027526\n",
      "batch 3415: loss 0.017756\n",
      "batch 3416: loss 0.048511\n",
      "batch 3417: loss 0.075372\n",
      "batch 3418: loss 0.016945\n",
      "batch 3419: loss 0.102810\n",
      "batch 3420: loss 0.050734\n",
      "batch 3421: loss 0.101343\n",
      "batch 3422: loss 0.077291\n",
      "batch 3423: loss 0.017024\n",
      "batch 3424: loss 0.169326\n",
      "batch 3425: loss 0.095293\n",
      "batch 3426: loss 0.026835\n",
      "batch 3427: loss 0.158904\n",
      "batch 3428: loss 0.113293\n",
      "batch 3429: loss 0.091815\n",
      "batch 3430: loss 0.014757\n",
      "batch 3431: loss 0.023942\n",
      "batch 3432: loss 0.185697\n",
      "batch 3433: loss 0.032529\n",
      "batch 3434: loss 0.018719\n",
      "batch 3435: loss 0.118728\n",
      "batch 3436: loss 0.073494\n",
      "batch 3437: loss 0.008227\n",
      "batch 3438: loss 0.044606\n",
      "batch 3439: loss 0.019948\n",
      "batch 3440: loss 0.037803\n",
      "batch 3441: loss 0.151514\n",
      "batch 3442: loss 0.014252\n",
      "batch 3443: loss 0.263393\n",
      "batch 3444: loss 0.086252\n",
      "batch 3445: loss 0.051660\n",
      "batch 3446: loss 0.208605\n",
      "batch 3447: loss 0.144037\n",
      "batch 3448: loss 0.075723\n",
      "batch 3449: loss 0.035509\n",
      "batch 3450: loss 0.060362\n",
      "batch 3451: loss 0.027740\n",
      "batch 3452: loss 0.047541\n",
      "batch 3453: loss 0.037527\n",
      "batch 3454: loss 0.049076\n",
      "batch 3455: loss 0.008883\n",
      "batch 3456: loss 0.027973\n",
      "batch 3457: loss 0.121204\n",
      "batch 3458: loss 0.124849\n",
      "batch 3459: loss 0.021232\n",
      "batch 3460: loss 0.071200\n",
      "batch 3461: loss 0.109155\n",
      "batch 3462: loss 0.034700\n",
      "batch 3463: loss 0.077842\n",
      "batch 3464: loss 0.015388\n",
      "batch 3465: loss 0.351719\n",
      "batch 3466: loss 0.027038\n",
      "batch 3467: loss 0.085317\n",
      "batch 3468: loss 0.035115\n",
      "batch 3469: loss 0.293955\n",
      "batch 3470: loss 0.024364\n",
      "batch 3471: loss 0.090773\n",
      "batch 3472: loss 0.131178\n",
      "batch 3473: loss 0.031306\n",
      "batch 3474: loss 0.133351\n",
      "batch 3475: loss 0.105602\n",
      "batch 3476: loss 0.090744\n",
      "batch 3477: loss 0.050425\n",
      "batch 3478: loss 0.150126\n",
      "batch 3479: loss 0.010995\n",
      "batch 3480: loss 0.027763\n",
      "batch 3481: loss 0.032318\n",
      "batch 3482: loss 0.042386\n",
      "batch 3483: loss 0.017373\n",
      "batch 3484: loss 0.100491\n",
      "batch 3485: loss 0.055278\n",
      "batch 3486: loss 0.133349\n",
      "batch 3487: loss 0.024948\n",
      "batch 3488: loss 0.094762\n",
      "batch 3489: loss 0.013478\n",
      "batch 3490: loss 0.202320\n",
      "batch 3491: loss 0.044161\n",
      "batch 3492: loss 0.037504\n",
      "batch 3493: loss 0.066457\n",
      "batch 3494: loss 0.024467\n",
      "batch 3495: loss 0.119693\n",
      "batch 3496: loss 0.037205\n",
      "batch 3497: loss 0.008291\n",
      "batch 3498: loss 0.144906\n",
      "batch 3499: loss 0.091923\n",
      "batch 3500: loss 0.090717\n",
      "batch 3501: loss 0.082170\n",
      "batch 3502: loss 0.066563\n",
      "batch 3503: loss 0.048216\n",
      "batch 3504: loss 0.141335\n",
      "batch 3505: loss 0.034825\n",
      "batch 3506: loss 0.023209\n",
      "batch 3507: loss 0.036010\n",
      "batch 3508: loss 0.149820\n",
      "batch 3509: loss 0.121079\n",
      "batch 3510: loss 0.018779\n",
      "batch 3511: loss 0.010234\n",
      "batch 3512: loss 0.081707\n",
      "batch 3513: loss 0.010755\n",
      "batch 3514: loss 0.033955\n",
      "batch 3515: loss 0.118563\n",
      "batch 3516: loss 0.089975\n",
      "batch 3517: loss 0.063676\n",
      "batch 3518: loss 0.015062\n",
      "batch 3519: loss 0.044384\n",
      "batch 3520: loss 0.375425\n",
      "batch 3521: loss 0.025300\n",
      "batch 3522: loss 0.034336\n",
      "batch 3523: loss 0.066696\n",
      "batch 3524: loss 0.032379\n",
      "batch 3525: loss 0.017488\n",
      "batch 3526: loss 0.056249\n",
      "batch 3527: loss 0.182193\n",
      "batch 3528: loss 0.032556\n",
      "batch 3529: loss 0.013557\n",
      "batch 3530: loss 0.113980\n",
      "batch 3531: loss 0.338566\n",
      "batch 3532: loss 0.015487\n",
      "batch 3533: loss 0.052826\n",
      "batch 3534: loss 0.033561\n",
      "batch 3535: loss 0.062680\n",
      "batch 3536: loss 0.016264\n",
      "batch 3537: loss 0.060225\n",
      "batch 3538: loss 0.044974\n",
      "batch 3539: loss 0.062117\n",
      "batch 3540: loss 0.020526\n",
      "batch 3541: loss 0.133670\n",
      "batch 3542: loss 0.101771\n",
      "batch 3543: loss 0.138731\n",
      "batch 3544: loss 0.014946\n",
      "batch 3545: loss 0.075324\n",
      "batch 3546: loss 0.097063\n",
      "batch 3547: loss 0.181266\n",
      "batch 3548: loss 0.222403\n",
      "batch 3549: loss 0.069607\n",
      "batch 3550: loss 0.240682\n",
      "batch 3551: loss 0.030124\n",
      "batch 3552: loss 0.276198\n",
      "batch 3553: loss 0.236373\n",
      "batch 3554: loss 0.138925\n",
      "batch 3555: loss 0.061803\n",
      "batch 3556: loss 0.101987\n",
      "batch 3557: loss 0.091541\n",
      "batch 3558: loss 0.027334\n",
      "batch 3559: loss 0.033020\n",
      "batch 3560: loss 0.087795\n",
      "batch 3561: loss 0.014165\n",
      "batch 3562: loss 0.029586\n",
      "batch 3563: loss 0.032934\n",
      "batch 3564: loss 0.029311\n",
      "batch 3565: loss 0.029303\n",
      "batch 3566: loss 0.007967\n",
      "batch 3567: loss 0.047069\n",
      "batch 3568: loss 0.044015\n",
      "batch 3569: loss 0.051979\n",
      "batch 3570: loss 0.023487\n",
      "batch 3571: loss 0.061168\n",
      "batch 3572: loss 0.014618\n",
      "batch 3573: loss 0.025786\n",
      "batch 3574: loss 0.157072\n",
      "batch 3575: loss 0.055975\n",
      "batch 3576: loss 0.012999\n",
      "batch 3577: loss 0.172084\n",
      "batch 3578: loss 0.047439\n",
      "batch 3579: loss 0.036332\n",
      "batch 3580: loss 0.072739\n",
      "batch 3581: loss 0.072913\n",
      "batch 3582: loss 0.034205\n",
      "batch 3583: loss 0.020165\n",
      "batch 3584: loss 0.138916\n",
      "batch 3585: loss 0.340056\n",
      "batch 3586: loss 0.042798\n",
      "batch 3587: loss 0.037278\n",
      "batch 3588: loss 0.052887\n",
      "batch 3589: loss 0.172020\n",
      "batch 3590: loss 0.222233\n",
      "batch 3591: loss 0.149403\n",
      "batch 3592: loss 0.159167\n",
      "batch 3593: loss 0.052158\n",
      "batch 3594: loss 0.286286\n",
      "batch 3595: loss 0.019077\n",
      "batch 3596: loss 0.244247\n",
      "batch 3597: loss 0.152065\n",
      "batch 3598: loss 0.031322\n",
      "batch 3599: loss 0.236307\n",
      "batch 3600: loss 0.087976\n",
      "batch 3601: loss 0.078083\n",
      "batch 3602: loss 0.032071\n",
      "batch 3603: loss 0.023195\n",
      "batch 3604: loss 0.026736\n",
      "batch 3605: loss 0.188846\n",
      "batch 3606: loss 0.146857\n",
      "batch 3607: loss 0.050259\n",
      "batch 3608: loss 0.039961\n",
      "batch 3609: loss 0.070837\n",
      "batch 3610: loss 0.130884\n",
      "batch 3611: loss 0.155318\n",
      "batch 3612: loss 0.092896\n",
      "batch 3613: loss 0.075334\n",
      "batch 3614: loss 0.077323\n",
      "batch 3615: loss 0.023937\n",
      "batch 3616: loss 0.086685\n",
      "batch 3617: loss 0.126822\n",
      "batch 3618: loss 0.045052\n",
      "batch 3619: loss 0.035304\n",
      "batch 3620: loss 0.031100\n",
      "batch 3621: loss 0.028863\n",
      "batch 3622: loss 0.120180\n",
      "batch 3623: loss 0.080676\n",
      "batch 3624: loss 0.125158\n",
      "batch 3625: loss 0.139617\n",
      "batch 3626: loss 0.104516\n",
      "batch 3627: loss 0.089165\n",
      "batch 3628: loss 0.028154\n",
      "batch 3629: loss 0.090496\n",
      "batch 3630: loss 0.018576\n",
      "batch 3631: loss 0.102551\n",
      "batch 3632: loss 0.105847\n",
      "batch 3633: loss 0.099095\n",
      "batch 3634: loss 0.173667\n",
      "batch 3635: loss 0.049891\n",
      "batch 3636: loss 0.042729\n",
      "batch 3637: loss 0.115664\n",
      "batch 3638: loss 0.074150\n",
      "batch 3639: loss 0.080222\n",
      "batch 3640: loss 0.106311\n",
      "batch 3641: loss 0.142983\n",
      "batch 3642: loss 0.050938\n",
      "batch 3643: loss 0.149345\n",
      "batch 3644: loss 0.183188\n",
      "batch 3645: loss 0.121133\n",
      "batch 3646: loss 0.066619\n",
      "batch 3647: loss 0.277529\n",
      "batch 3648: loss 0.023247\n",
      "batch 3649: loss 0.129989\n",
      "batch 3650: loss 0.039285\n",
      "batch 3651: loss 0.091447\n",
      "batch 3652: loss 0.059662\n",
      "batch 3653: loss 0.133058\n",
      "batch 3654: loss 0.057544\n",
      "batch 3655: loss 0.159944\n",
      "batch 3656: loss 0.155466\n",
      "batch 3657: loss 0.227975\n",
      "batch 3658: loss 0.018783\n",
      "batch 3659: loss 0.053797\n",
      "batch 3660: loss 0.012742\n",
      "batch 3661: loss 0.057745\n",
      "batch 3662: loss 0.025697\n",
      "batch 3663: loss 0.055161\n",
      "batch 3664: loss 0.142551\n",
      "batch 3665: loss 0.304049\n",
      "batch 3666: loss 0.020621\n",
      "batch 3667: loss 0.120923\n",
      "batch 3668: loss 0.156041\n",
      "batch 3669: loss 0.048009\n",
      "batch 3670: loss 0.126462\n",
      "batch 3671: loss 0.074029\n",
      "batch 3672: loss 0.059548\n",
      "batch 3673: loss 0.028325\n",
      "batch 3674: loss 0.153455\n",
      "batch 3675: loss 0.072931\n",
      "batch 3676: loss 0.044885\n",
      "batch 3677: loss 0.024253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3678: loss 0.041510\n",
      "batch 3679: loss 0.038816\n",
      "batch 3680: loss 0.035756\n",
      "batch 3681: loss 0.092629\n",
      "batch 3682: loss 0.030600\n",
      "batch 3683: loss 0.066297\n",
      "batch 3684: loss 0.396790\n",
      "batch 3685: loss 0.045994\n",
      "batch 3686: loss 0.051021\n",
      "batch 3687: loss 0.101682\n",
      "batch 3688: loss 0.022218\n",
      "batch 3689: loss 0.012454\n",
      "batch 3690: loss 0.087925\n",
      "batch 3691: loss 0.080853\n",
      "batch 3692: loss 0.051387\n",
      "batch 3693: loss 0.137348\n",
      "batch 3694: loss 0.022106\n",
      "batch 3695: loss 0.044595\n",
      "batch 3696: loss 0.078319\n",
      "batch 3697: loss 0.043317\n",
      "batch 3698: loss 0.039110\n",
      "batch 3699: loss 0.338066\n",
      "batch 3700: loss 0.244529\n",
      "batch 3701: loss 0.105149\n",
      "batch 3702: loss 0.038963\n",
      "batch 3703: loss 0.029376\n",
      "batch 3704: loss 0.080898\n",
      "batch 3705: loss 0.186988\n",
      "batch 3706: loss 0.012138\n",
      "batch 3707: loss 0.031487\n",
      "batch 3708: loss 0.027042\n",
      "batch 3709: loss 0.096129\n",
      "batch 3710: loss 0.062994\n",
      "batch 3711: loss 0.018211\n",
      "batch 3712: loss 0.019060\n",
      "batch 3713: loss 0.012787\n",
      "batch 3714: loss 0.181703\n",
      "batch 3715: loss 0.012506\n",
      "batch 3716: loss 0.069106\n",
      "batch 3717: loss 0.144289\n",
      "batch 3718: loss 0.045043\n",
      "batch 3719: loss 0.102937\n",
      "batch 3720: loss 0.032942\n",
      "batch 3721: loss 0.092154\n",
      "batch 3722: loss 0.021912\n",
      "batch 3723: loss 0.118100\n",
      "batch 3724: loss 0.195522\n",
      "batch 3725: loss 0.035359\n",
      "batch 3726: loss 0.102956\n",
      "batch 3727: loss 0.191026\n",
      "batch 3728: loss 0.338405\n",
      "batch 3729: loss 0.228464\n",
      "batch 3730: loss 0.025391\n",
      "batch 3731: loss 0.016003\n",
      "batch 3732: loss 0.107969\n",
      "batch 3733: loss 0.153734\n",
      "batch 3734: loss 0.085290\n",
      "batch 3735: loss 0.038192\n",
      "batch 3736: loss 0.047394\n",
      "batch 3737: loss 0.097350\n",
      "batch 3738: loss 0.014417\n",
      "batch 3739: loss 0.052011\n",
      "batch 3740: loss 0.118355\n",
      "batch 3741: loss 0.090686\n",
      "batch 3742: loss 0.028965\n",
      "batch 3743: loss 0.114475\n",
      "batch 3744: loss 0.098926\n",
      "batch 3745: loss 0.057821\n",
      "batch 3746: loss 0.120644\n",
      "batch 3747: loss 0.016596\n",
      "batch 3748: loss 0.031441\n",
      "batch 3749: loss 0.006832\n",
      "batch 3750: loss 0.329045\n",
      "batch 3751: loss 0.118723\n",
      "batch 3752: loss 0.023655\n",
      "batch 3753: loss 0.083879\n",
      "batch 3754: loss 0.031399\n",
      "batch 3755: loss 0.060199\n",
      "batch 3756: loss 0.010367\n",
      "batch 3757: loss 0.063260\n",
      "batch 3758: loss 0.018164\n",
      "batch 3759: loss 0.061146\n",
      "batch 3760: loss 0.027185\n",
      "batch 3761: loss 0.073976\n",
      "batch 3762: loss 0.059516\n",
      "batch 3763: loss 0.036760\n",
      "batch 3764: loss 0.041125\n",
      "batch 3765: loss 0.130518\n",
      "batch 3766: loss 0.067887\n",
      "batch 3767: loss 0.018984\n",
      "batch 3768: loss 0.085071\n",
      "batch 3769: loss 0.058746\n",
      "batch 3770: loss 0.061640\n",
      "batch 3771: loss 0.016181\n",
      "batch 3772: loss 0.039076\n",
      "batch 3773: loss 0.047767\n",
      "batch 3774: loss 0.309872\n",
      "batch 3775: loss 0.269519\n",
      "batch 3776: loss 0.261992\n",
      "batch 3777: loss 0.028385\n",
      "batch 3778: loss 0.153646\n",
      "batch 3779: loss 0.093759\n",
      "batch 3780: loss 0.114670\n",
      "batch 3781: loss 0.162921\n",
      "batch 3782: loss 0.121568\n",
      "batch 3783: loss 0.161181\n",
      "batch 3784: loss 0.030567\n",
      "batch 3785: loss 0.028762\n",
      "batch 3786: loss 0.037029\n",
      "batch 3787: loss 0.004028\n",
      "batch 3788: loss 0.107871\n",
      "batch 3789: loss 0.115932\n",
      "batch 3790: loss 0.042590\n",
      "batch 3791: loss 0.210399\n",
      "batch 3792: loss 0.070393\n",
      "batch 3793: loss 0.175100\n",
      "batch 3794: loss 0.015732\n",
      "batch 3795: loss 0.075931\n",
      "batch 3796: loss 0.022029\n",
      "batch 3797: loss 0.131363\n",
      "batch 3798: loss 0.213383\n",
      "batch 3799: loss 0.098395\n",
      "batch 3800: loss 0.057522\n",
      "batch 3801: loss 0.122414\n",
      "batch 3802: loss 0.092361\n",
      "batch 3803: loss 0.015668\n",
      "batch 3804: loss 0.012937\n",
      "batch 3805: loss 0.032690\n",
      "batch 3806: loss 0.210509\n",
      "batch 3807: loss 0.019975\n",
      "batch 3808: loss 0.031794\n",
      "batch 3809: loss 0.214960\n",
      "batch 3810: loss 0.015624\n",
      "batch 3811: loss 0.041819\n",
      "batch 3812: loss 0.161392\n",
      "batch 3813: loss 0.038036\n",
      "batch 3814: loss 0.072044\n",
      "batch 3815: loss 0.058867\n",
      "batch 3816: loss 0.067152\n",
      "batch 3817: loss 0.029105\n",
      "batch 3818: loss 0.071203\n",
      "batch 3819: loss 0.031250\n",
      "batch 3820: loss 0.035578\n",
      "batch 3821: loss 0.072965\n",
      "batch 3822: loss 0.024590\n",
      "batch 3823: loss 0.093508\n",
      "batch 3824: loss 0.079972\n",
      "batch 3825: loss 0.032491\n",
      "batch 3826: loss 0.085889\n",
      "batch 3827: loss 0.100225\n",
      "batch 3828: loss 0.038711\n",
      "batch 3829: loss 0.163140\n",
      "batch 3830: loss 0.061416\n",
      "batch 3831: loss 0.149560\n",
      "batch 3832: loss 0.053622\n",
      "batch 3833: loss 0.128875\n",
      "batch 3834: loss 0.218938\n",
      "batch 3835: loss 0.174123\n",
      "batch 3836: loss 0.113256\n",
      "batch 3837: loss 0.030413\n",
      "batch 3838: loss 0.027385\n",
      "batch 3839: loss 0.022268\n",
      "batch 3840: loss 0.090202\n",
      "batch 3841: loss 0.162552\n",
      "batch 3842: loss 0.027134\n",
      "batch 3843: loss 0.039235\n",
      "batch 3844: loss 0.017835\n",
      "batch 3845: loss 0.046896\n",
      "batch 3846: loss 0.121517\n",
      "batch 3847: loss 0.037013\n",
      "batch 3848: loss 0.095853\n",
      "batch 3849: loss 0.022648\n",
      "batch 3850: loss 0.019066\n",
      "batch 3851: loss 0.109214\n",
      "batch 3852: loss 0.036076\n",
      "batch 3853: loss 0.064278\n",
      "batch 3854: loss 0.014707\n",
      "batch 3855: loss 0.046968\n",
      "batch 3856: loss 0.104359\n",
      "batch 3857: loss 0.019308\n",
      "batch 3858: loss 0.026140\n",
      "batch 3859: loss 0.116908\n",
      "batch 3860: loss 0.154397\n",
      "batch 3861: loss 0.010201\n",
      "batch 3862: loss 0.346586\n",
      "batch 3863: loss 0.025078\n",
      "batch 3864: loss 0.030707\n",
      "batch 3865: loss 0.017077\n",
      "batch 3866: loss 0.040710\n",
      "batch 3867: loss 0.056083\n",
      "batch 3868: loss 0.057449\n",
      "batch 3869: loss 0.039445\n",
      "batch 3870: loss 0.142336\n",
      "batch 3871: loss 0.016725\n",
      "batch 3872: loss 0.137546\n",
      "batch 3873: loss 0.051164\n",
      "batch 3874: loss 0.012398\n",
      "batch 3875: loss 0.110085\n",
      "batch 3876: loss 0.054081\n",
      "batch 3877: loss 0.024535\n",
      "batch 3878: loss 0.062017\n",
      "batch 3879: loss 0.075080\n",
      "batch 3880: loss 0.089898\n",
      "batch 3881: loss 0.118420\n",
      "batch 3882: loss 0.039152\n",
      "batch 3883: loss 0.034218\n",
      "batch 3884: loss 0.109300\n",
      "batch 3885: loss 0.049687\n",
      "batch 3886: loss 0.227665\n",
      "batch 3887: loss 0.031623\n",
      "batch 3888: loss 0.019324\n",
      "batch 3889: loss 0.114565\n",
      "batch 3890: loss 0.122947\n",
      "batch 3891: loss 0.014933\n",
      "batch 3892: loss 0.067234\n",
      "batch 3893: loss 0.038440\n",
      "batch 3894: loss 0.095541\n",
      "batch 3895: loss 0.039072\n",
      "batch 3896: loss 0.028264\n",
      "batch 3897: loss 0.017597\n",
      "batch 3898: loss 0.102455\n",
      "batch 3899: loss 0.024864\n",
      "batch 3900: loss 0.166941\n",
      "batch 3901: loss 0.123510\n",
      "batch 3902: loss 0.049671\n",
      "batch 3903: loss 0.034686\n",
      "batch 3904: loss 0.102146\n",
      "batch 3905: loss 0.126654\n",
      "batch 3906: loss 0.069660\n",
      "batch 3907: loss 0.063200\n",
      "batch 3908: loss 0.018923\n",
      "batch 3909: loss 0.073815\n",
      "batch 3910: loss 0.036012\n",
      "batch 3911: loss 0.041762\n",
      "batch 3912: loss 0.179142\n",
      "batch 3913: loss 0.105394\n",
      "batch 3914: loss 0.105262\n",
      "batch 3915: loss 0.099258\n",
      "batch 3916: loss 0.059014\n",
      "batch 3917: loss 0.026640\n",
      "batch 3918: loss 0.065858\n",
      "batch 3919: loss 0.098146\n",
      "batch 3920: loss 0.019221\n",
      "batch 3921: loss 0.089894\n",
      "batch 3922: loss 0.119380\n",
      "batch 3923: loss 0.055004\n",
      "batch 3924: loss 0.120953\n",
      "batch 3925: loss 0.127807\n",
      "batch 3926: loss 0.192329\n",
      "batch 3927: loss 0.040984\n",
      "batch 3928: loss 0.087017\n",
      "batch 3929: loss 0.248402\n",
      "batch 3930: loss 0.212327\n",
      "batch 3931: loss 0.060712\n",
      "batch 3932: loss 0.401843\n",
      "batch 3933: loss 0.043419\n",
      "batch 3934: loss 0.339356\n",
      "batch 3935: loss 0.147296\n",
      "batch 3936: loss 0.019555\n",
      "batch 3937: loss 0.027773\n",
      "batch 3938: loss 0.106995\n",
      "batch 3939: loss 0.032176\n",
      "batch 3940: loss 0.131697\n",
      "batch 3941: loss 0.069703\n",
      "batch 3942: loss 0.048618\n",
      "batch 3943: loss 0.123706\n",
      "batch 3944: loss 0.065388\n",
      "batch 3945: loss 0.254981\n",
      "batch 3946: loss 0.033926\n",
      "batch 3947: loss 0.022758\n",
      "batch 3948: loss 0.089117\n",
      "batch 3949: loss 0.044816\n",
      "batch 3950: loss 0.243104\n",
      "batch 3951: loss 0.142434\n",
      "batch 3952: loss 0.103063\n",
      "batch 3953: loss 0.079287\n",
      "batch 3954: loss 0.039094\n",
      "batch 3955: loss 0.156936\n",
      "batch 3956: loss 0.155074\n",
      "batch 3957: loss 0.039722\n",
      "batch 3958: loss 0.010008\n",
      "batch 3959: loss 0.177367\n",
      "batch 3960: loss 0.267468\n",
      "batch 3961: loss 0.080334\n",
      "batch 3962: loss 0.145440\n",
      "batch 3963: loss 0.239052\n",
      "batch 3964: loss 0.071149\n",
      "batch 3965: loss 0.306246\n",
      "batch 3966: loss 0.153774\n",
      "batch 3967: loss 0.075433\n",
      "batch 3968: loss 0.204895\n",
      "batch 3969: loss 0.045002\n",
      "batch 3970: loss 0.028017\n",
      "batch 3971: loss 0.068044\n",
      "batch 3972: loss 0.029411\n",
      "batch 3973: loss 0.098792\n",
      "batch 3974: loss 0.028212\n",
      "batch 3975: loss 0.013219\n",
      "batch 3976: loss 0.096318\n",
      "batch 3977: loss 0.029512\n",
      "batch 3978: loss 0.024955\n",
      "batch 3979: loss 0.017100\n",
      "batch 3980: loss 0.087194\n",
      "batch 3981: loss 0.039084\n",
      "batch 3982: loss 0.026049\n",
      "batch 3983: loss 0.020653\n",
      "batch 3984: loss 0.099953\n",
      "batch 3985: loss 0.089584\n",
      "batch 3986: loss 0.197474\n",
      "batch 3987: loss 0.085116\n",
      "batch 3988: loss 0.038309\n",
      "batch 3989: loss 0.069500\n",
      "batch 3990: loss 0.048715\n",
      "batch 3991: loss 0.059312\n",
      "batch 3992: loss 0.079977\n",
      "batch 3993: loss 0.028138\n",
      "batch 3994: loss 0.051451\n",
      "batch 3995: loss 0.054085\n",
      "batch 3996: loss 0.055932\n",
      "batch 3997: loss 0.028748\n",
      "batch 3998: loss 0.031431\n",
      "batch 3999: loss 0.017372\n",
      "batch 4000: loss 0.057988\n",
      "batch 4001: loss 0.065028\n",
      "batch 4002: loss 0.026667\n",
      "batch 4003: loss 0.037581\n",
      "batch 4004: loss 0.147233\n",
      "batch 4005: loss 0.073762\n",
      "batch 4006: loss 0.013350\n",
      "batch 4007: loss 0.013567\n",
      "batch 4008: loss 0.081257\n",
      "batch 4009: loss 0.144057\n",
      "batch 4010: loss 0.014745\n",
      "batch 4011: loss 0.040152\n",
      "batch 4012: loss 0.023104\n",
      "batch 4013: loss 0.128521\n",
      "batch 4014: loss 0.047240\n",
      "batch 4015: loss 0.009196\n",
      "batch 4016: loss 0.069621\n",
      "batch 4017: loss 0.020768\n",
      "batch 4018: loss 0.043181\n",
      "batch 4019: loss 0.086811\n",
      "batch 4020: loss 0.022042\n",
      "batch 4021: loss 0.166626\n",
      "batch 4022: loss 0.101931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4023: loss 0.014879\n",
      "batch 4024: loss 0.025031\n",
      "batch 4025: loss 0.050275\n",
      "batch 4026: loss 0.058741\n",
      "batch 4027: loss 0.194563\n",
      "batch 4028: loss 0.013297\n",
      "batch 4029: loss 0.010212\n",
      "batch 4030: loss 0.021281\n",
      "batch 4031: loss 0.359482\n",
      "batch 4032: loss 0.145610\n",
      "batch 4033: loss 0.039723\n",
      "batch 4034: loss 0.018279\n",
      "batch 4035: loss 0.155978\n",
      "batch 4036: loss 0.083382\n",
      "batch 4037: loss 0.084898\n",
      "batch 4038: loss 0.213180\n",
      "batch 4039: loss 0.093754\n",
      "batch 4040: loss 0.010950\n",
      "batch 4041: loss 0.034485\n",
      "batch 4042: loss 0.024718\n",
      "batch 4043: loss 0.201422\n",
      "batch 4044: loss 0.068749\n",
      "batch 4045: loss 0.016897\n",
      "batch 4046: loss 0.052528\n",
      "batch 4047: loss 0.030146\n",
      "batch 4048: loss 0.050564\n",
      "batch 4049: loss 0.096731\n",
      "batch 4050: loss 0.045758\n",
      "batch 4051: loss 0.058647\n",
      "batch 4052: loss 0.168968\n",
      "batch 4053: loss 0.235885\n",
      "batch 4054: loss 0.138793\n",
      "batch 4055: loss 0.012547\n",
      "batch 4056: loss 0.021557\n",
      "batch 4057: loss 0.196891\n",
      "batch 4058: loss 0.126009\n",
      "batch 4059: loss 0.026120\n",
      "batch 4060: loss 0.087818\n",
      "batch 4061: loss 0.213436\n",
      "batch 4062: loss 0.101726\n",
      "batch 4063: loss 0.181194\n",
      "batch 4064: loss 0.021894\n",
      "batch 4065: loss 0.129326\n",
      "batch 4066: loss 0.069517\n",
      "batch 4067: loss 0.032239\n",
      "batch 4068: loss 0.143076\n",
      "batch 4069: loss 0.020101\n",
      "batch 4070: loss 0.070192\n",
      "batch 4071: loss 0.127172\n",
      "batch 4072: loss 0.022378\n",
      "batch 4073: loss 0.031424\n",
      "batch 4074: loss 0.014047\n",
      "batch 4075: loss 0.019210\n",
      "batch 4076: loss 0.155865\n",
      "batch 4077: loss 0.015768\n",
      "batch 4078: loss 0.064252\n",
      "batch 4079: loss 0.046464\n",
      "batch 4080: loss 0.008270\n",
      "batch 4081: loss 0.082057\n",
      "batch 4082: loss 0.044504\n",
      "batch 4083: loss 0.087107\n",
      "batch 4084: loss 0.033848\n",
      "batch 4085: loss 0.059283\n",
      "batch 4086: loss 0.088522\n",
      "batch 4087: loss 0.059588\n",
      "batch 4088: loss 0.009933\n",
      "batch 4089: loss 0.110482\n",
      "batch 4090: loss 0.115301\n",
      "batch 4091: loss 0.019820\n",
      "batch 4092: loss 0.098441\n",
      "batch 4093: loss 0.025826\n",
      "batch 4094: loss 0.137669\n",
      "batch 4095: loss 0.048963\n",
      "batch 4096: loss 0.027676\n",
      "batch 4097: loss 0.081063\n",
      "batch 4098: loss 0.012728\n",
      "batch 4099: loss 0.061652\n",
      "batch 4100: loss 0.032688\n",
      "batch 4101: loss 0.035113\n",
      "batch 4102: loss 0.384334\n",
      "batch 4103: loss 0.056018\n",
      "batch 4104: loss 0.099860\n",
      "batch 4105: loss 0.227170\n",
      "batch 4106: loss 0.177373\n",
      "batch 4107: loss 0.072007\n",
      "batch 4108: loss 0.167156\n",
      "batch 4109: loss 0.032149\n",
      "batch 4110: loss 0.054246\n",
      "batch 4111: loss 0.021878\n",
      "batch 4112: loss 0.041423\n",
      "batch 4113: loss 0.129693\n",
      "batch 4114: loss 0.099334\n",
      "batch 4115: loss 0.035509\n",
      "batch 4116: loss 0.100496\n",
      "batch 4117: loss 0.014225\n",
      "batch 4118: loss 0.013446\n",
      "batch 4119: loss 0.219100\n",
      "batch 4120: loss 0.111252\n",
      "batch 4121: loss 0.325333\n",
      "batch 4122: loss 0.095181\n",
      "batch 4123: loss 0.089812\n",
      "batch 4124: loss 0.025952\n",
      "batch 4125: loss 0.134245\n",
      "batch 4126: loss 0.080541\n",
      "batch 4127: loss 0.075369\n",
      "batch 4128: loss 0.237872\n",
      "batch 4129: loss 0.015732\n",
      "batch 4130: loss 0.044549\n",
      "batch 4131: loss 0.078119\n",
      "batch 4132: loss 0.042634\n",
      "batch 4133: loss 0.040048\n",
      "batch 4134: loss 0.081966\n",
      "batch 4135: loss 0.044873\n",
      "batch 4136: loss 0.027239\n",
      "batch 4137: loss 0.047258\n",
      "batch 4138: loss 0.069740\n",
      "batch 4139: loss 0.029639\n",
      "batch 4140: loss 0.133201\n",
      "batch 4141: loss 0.035550\n",
      "batch 4142: loss 0.040789\n",
      "batch 4143: loss 0.106835\n",
      "batch 4144: loss 0.097759\n",
      "batch 4145: loss 0.041586\n",
      "batch 4146: loss 0.051989\n",
      "batch 4147: loss 0.145526\n",
      "batch 4148: loss 0.036751\n",
      "batch 4149: loss 0.022583\n",
      "batch 4150: loss 0.073663\n",
      "batch 4151: loss 0.045458\n",
      "batch 4152: loss 0.050216\n",
      "batch 4153: loss 0.072043\n",
      "batch 4154: loss 0.035246\n",
      "batch 4155: loss 0.085115\n",
      "batch 4156: loss 0.050850\n",
      "batch 4157: loss 0.068120\n",
      "batch 4158: loss 0.137116\n",
      "batch 4159: loss 0.083067\n",
      "batch 4160: loss 0.105155\n",
      "batch 4161: loss 0.022846\n",
      "batch 4162: loss 0.020469\n",
      "batch 4163: loss 0.114236\n",
      "batch 4164: loss 0.114498\n",
      "batch 4165: loss 0.038060\n",
      "batch 4166: loss 0.106245\n",
      "batch 4167: loss 0.021383\n",
      "batch 4168: loss 0.040145\n",
      "batch 4169: loss 0.130500\n",
      "batch 4170: loss 0.008169\n",
      "batch 4171: loss 0.121111\n",
      "batch 4172: loss 0.051742\n",
      "batch 4173: loss 0.014279\n",
      "batch 4174: loss 0.220172\n",
      "batch 4175: loss 0.080808\n",
      "batch 4176: loss 0.080469\n",
      "batch 4177: loss 0.066204\n",
      "batch 4178: loss 0.055817\n",
      "batch 4179: loss 0.032633\n",
      "batch 4180: loss 0.124967\n",
      "batch 4181: loss 0.156075\n",
      "batch 4182: loss 0.094059\n",
      "batch 4183: loss 0.181464\n",
      "batch 4184: loss 0.088195\n",
      "batch 4185: loss 0.129334\n",
      "batch 4186: loss 0.067472\n",
      "batch 4187: loss 0.245901\n",
      "batch 4188: loss 0.080405\n",
      "batch 4189: loss 0.027894\n",
      "batch 4190: loss 0.015600\n",
      "batch 4191: loss 0.027641\n",
      "batch 4192: loss 0.050070\n",
      "batch 4193: loss 0.106505\n",
      "batch 4194: loss 0.014721\n",
      "batch 4195: loss 0.014536\n",
      "batch 4196: loss 0.224318\n",
      "batch 4197: loss 0.056385\n",
      "batch 4198: loss 0.037067\n",
      "batch 4199: loss 0.120088\n",
      "batch 4200: loss 0.088138\n",
      "batch 4201: loss 0.110706\n",
      "batch 4202: loss 0.084445\n",
      "batch 4203: loss 0.023270\n",
      "batch 4204: loss 0.064686\n",
      "batch 4205: loss 0.038381\n",
      "batch 4206: loss 0.040829\n",
      "batch 4207: loss 0.017517\n",
      "batch 4208: loss 0.038102\n",
      "batch 4209: loss 0.143101\n",
      "batch 4210: loss 0.056555\n",
      "batch 4211: loss 0.058476\n",
      "batch 4212: loss 0.098210\n",
      "batch 4213: loss 0.066241\n",
      "batch 4214: loss 0.045665\n",
      "batch 4215: loss 0.024366\n",
      "batch 4216: loss 0.017547\n",
      "batch 4217: loss 0.015198\n",
      "batch 4218: loss 0.038253\n",
      "batch 4219: loss 0.045272\n",
      "batch 4220: loss 0.018813\n",
      "batch 4221: loss 0.015796\n",
      "batch 4222: loss 0.040091\n",
      "batch 4223: loss 0.049878\n",
      "batch 4224: loss 0.025542\n",
      "batch 4225: loss 0.105561\n",
      "batch 4226: loss 0.006980\n",
      "batch 4227: loss 0.270725\n",
      "batch 4228: loss 0.091609\n",
      "batch 4229: loss 0.179828\n",
      "batch 4230: loss 0.006900\n",
      "batch 4231: loss 0.080101\n",
      "batch 4232: loss 0.049404\n",
      "batch 4233: loss 0.125737\n",
      "batch 4234: loss 0.011309\n",
      "batch 4235: loss 0.007431\n",
      "batch 4236: loss 0.020580\n",
      "batch 4237: loss 0.011801\n",
      "batch 4238: loss 0.014392\n",
      "batch 4239: loss 0.079282\n",
      "batch 4240: loss 0.039079\n",
      "batch 4241: loss 0.242093\n",
      "batch 4242: loss 0.065417\n",
      "batch 4243: loss 0.073328\n",
      "batch 4244: loss 0.037984\n",
      "batch 4245: loss 0.040091\n",
      "batch 4246: loss 0.026243\n",
      "batch 4247: loss 0.090296\n",
      "batch 4248: loss 0.058800\n",
      "batch 4249: loss 0.169105\n",
      "batch 4250: loss 0.123461\n",
      "batch 4251: loss 0.110950\n",
      "batch 4252: loss 0.339418\n",
      "batch 4253: loss 0.060685\n",
      "batch 4254: loss 0.029864\n",
      "batch 4255: loss 0.071450\n",
      "batch 4256: loss 0.130846\n",
      "batch 4257: loss 0.010270\n",
      "batch 4258: loss 0.045003\n",
      "batch 4259: loss 0.209564\n",
      "batch 4260: loss 0.005945\n",
      "batch 4261: loss 0.033002\n",
      "batch 4262: loss 0.033273\n",
      "batch 4263: loss 0.007415\n",
      "batch 4264: loss 0.127257\n",
      "batch 4265: loss 0.030417\n",
      "batch 4266: loss 0.027437\n",
      "batch 4267: loss 0.018358\n",
      "batch 4268: loss 0.056925\n",
      "batch 4269: loss 0.091641\n",
      "batch 4270: loss 0.013869\n",
      "batch 4271: loss 0.017273\n",
      "batch 4272: loss 0.044280\n",
      "batch 4273: loss 0.204755\n",
      "batch 4274: loss 0.296538\n",
      "batch 4275: loss 0.057120\n",
      "batch 4276: loss 0.080476\n",
      "batch 4277: loss 0.009738\n",
      "batch 4278: loss 0.016560\n",
      "batch 4279: loss 0.065063\n",
      "batch 4280: loss 0.096861\n",
      "batch 4281: loss 0.215074\n",
      "batch 4282: loss 0.014520\n",
      "batch 4283: loss 0.052603\n",
      "batch 4284: loss 0.145287\n",
      "batch 4285: loss 0.074066\n",
      "batch 4286: loss 0.011461\n",
      "batch 4287: loss 0.028525\n",
      "batch 4288: loss 0.055697\n",
      "batch 4289: loss 0.138122\n",
      "batch 4290: loss 0.055736\n",
      "batch 4291: loss 0.030357\n",
      "batch 4292: loss 0.019940\n",
      "batch 4293: loss 0.090167\n",
      "batch 4294: loss 0.015913\n",
      "batch 4295: loss 0.042540\n",
      "batch 4296: loss 0.061408\n",
      "batch 4297: loss 0.097837\n",
      "batch 4298: loss 0.169507\n",
      "batch 4299: loss 0.296233\n",
      "batch 4300: loss 0.134933\n",
      "batch 4301: loss 0.250977\n",
      "batch 4302: loss 0.018012\n",
      "batch 4303: loss 0.040824\n",
      "batch 4304: loss 0.021384\n",
      "batch 4305: loss 0.064656\n",
      "batch 4306: loss 0.120923\n",
      "batch 4307: loss 0.057807\n",
      "batch 4308: loss 0.158404\n",
      "batch 4309: loss 0.092351\n",
      "batch 4310: loss 0.083099\n",
      "batch 4311: loss 0.018858\n",
      "batch 4312: loss 0.019714\n",
      "batch 4313: loss 0.016536\n",
      "batch 4314: loss 0.020567\n",
      "batch 4315: loss 0.028278\n",
      "batch 4316: loss 0.068106\n",
      "batch 4317: loss 0.023611\n",
      "batch 4318: loss 0.163236\n",
      "batch 4319: loss 0.065358\n",
      "batch 4320: loss 0.077260\n",
      "batch 4321: loss 0.037756\n",
      "batch 4322: loss 0.033416\n",
      "batch 4323: loss 0.078942\n",
      "batch 4324: loss 0.045129\n",
      "batch 4325: loss 0.026079\n",
      "batch 4326: loss 0.104405\n",
      "batch 4327: loss 0.063301\n",
      "batch 4328: loss 0.087480\n",
      "batch 4329: loss 0.185559\n",
      "batch 4330: loss 0.048758\n",
      "batch 4331: loss 0.074836\n",
      "batch 4332: loss 0.030842\n",
      "batch 4333: loss 0.038468\n",
      "batch 4334: loss 0.135770\n",
      "batch 4335: loss 0.017668\n",
      "batch 4336: loss 0.075207\n",
      "batch 4337: loss 0.117001\n",
      "batch 4338: loss 0.022880\n",
      "batch 4339: loss 0.052514\n",
      "batch 4340: loss 0.004415\n",
      "batch 4341: loss 0.019734\n",
      "batch 4342: loss 0.023633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4343: loss 0.061123\n",
      "batch 4344: loss 0.127976\n",
      "batch 4345: loss 0.050857\n",
      "batch 4346: loss 0.084945\n",
      "batch 4347: loss 0.060179\n",
      "batch 4348: loss 0.060749\n",
      "batch 4349: loss 0.076776\n",
      "batch 4350: loss 0.116200\n",
      "batch 4351: loss 0.020874\n",
      "batch 4352: loss 0.063085\n",
      "batch 4353: loss 0.015031\n",
      "batch 4354: loss 0.074213\n",
      "batch 4355: loss 0.037756\n",
      "batch 4356: loss 0.012176\n",
      "batch 4357: loss 0.301693\n",
      "batch 4358: loss 0.003130\n",
      "batch 4359: loss 0.027510\n",
      "batch 4360: loss 0.025946\n",
      "batch 4361: loss 0.023059\n",
      "batch 4362: loss 0.017593\n",
      "batch 4363: loss 0.159298\n",
      "batch 4364: loss 0.137292\n",
      "batch 4365: loss 0.097159\n",
      "batch 4366: loss 0.011669\n",
      "batch 4367: loss 0.026802\n",
      "batch 4368: loss 0.091387\n",
      "batch 4369: loss 0.045886\n",
      "batch 4370: loss 0.356094\n",
      "batch 4371: loss 0.074508\n",
      "batch 4372: loss 0.089135\n",
      "batch 4373: loss 0.089733\n",
      "batch 4374: loss 0.048039\n",
      "batch 4375: loss 0.121099\n",
      "batch 4376: loss 0.101482\n",
      "batch 4377: loss 0.025267\n",
      "batch 4378: loss 0.023516\n",
      "batch 4379: loss 0.022883\n",
      "batch 4380: loss 0.046158\n",
      "batch 4381: loss 0.019916\n",
      "batch 4382: loss 0.071872\n",
      "batch 4383: loss 0.028871\n",
      "batch 4384: loss 0.419248\n",
      "batch 4385: loss 0.094808\n",
      "batch 4386: loss 0.096762\n",
      "batch 4387: loss 0.050218\n",
      "batch 4388: loss 0.038499\n",
      "batch 4389: loss 0.083587\n",
      "batch 4390: loss 0.067237\n",
      "batch 4391: loss 0.212472\n",
      "batch 4392: loss 0.042931\n",
      "batch 4393: loss 0.045193\n",
      "batch 4394: loss 0.033830\n",
      "batch 4395: loss 0.049242\n",
      "batch 4396: loss 0.038368\n",
      "batch 4397: loss 0.024708\n",
      "batch 4398: loss 0.028957\n",
      "batch 4399: loss 0.013021\n",
      "batch 4400: loss 0.121194\n",
      "batch 4401: loss 0.086678\n",
      "batch 4402: loss 0.089977\n",
      "batch 4403: loss 0.137323\n",
      "batch 4404: loss 0.106771\n",
      "batch 4405: loss 0.017726\n",
      "batch 4406: loss 0.018969\n",
      "batch 4407: loss 0.070015\n",
      "batch 4408: loss 0.229886\n",
      "batch 4409: loss 0.120857\n",
      "batch 4410: loss 0.034191\n",
      "batch 4411: loss 0.037997\n",
      "batch 4412: loss 0.023937\n",
      "batch 4413: loss 0.111480\n",
      "batch 4414: loss 0.119763\n",
      "batch 4415: loss 0.005795\n",
      "batch 4416: loss 0.053754\n",
      "batch 4417: loss 0.013145\n",
      "batch 4418: loss 0.084060\n",
      "batch 4419: loss 0.089482\n",
      "batch 4420: loss 0.161649\n",
      "batch 4421: loss 0.058310\n",
      "batch 4422: loss 0.058197\n",
      "batch 4423: loss 0.033926\n",
      "batch 4424: loss 0.025993\n",
      "batch 4425: loss 0.081896\n",
      "batch 4426: loss 0.148557\n",
      "batch 4427: loss 0.034963\n",
      "batch 4428: loss 0.095910\n",
      "batch 4429: loss 0.144026\n",
      "batch 4430: loss 0.074673\n",
      "batch 4431: loss 0.066411\n",
      "batch 4432: loss 0.002316\n",
      "batch 4433: loss 0.159476\n",
      "batch 4434: loss 0.025336\n",
      "batch 4435: loss 0.090629\n",
      "batch 4436: loss 0.050282\n",
      "batch 4437: loss 0.017710\n",
      "batch 4438: loss 0.056548\n",
      "batch 4439: loss 0.018447\n",
      "batch 4440: loss 0.026674\n",
      "batch 4441: loss 0.149505\n",
      "batch 4442: loss 0.020746\n",
      "batch 4443: loss 0.025600\n",
      "batch 4444: loss 0.099228\n",
      "batch 4445: loss 0.025453\n",
      "batch 4446: loss 0.043291\n",
      "batch 4447: loss 0.149808\n",
      "batch 4448: loss 0.105607\n",
      "batch 4449: loss 0.003794\n",
      "batch 4450: loss 0.046337\n",
      "batch 4451: loss 0.068399\n",
      "batch 4452: loss 0.148906\n",
      "batch 4453: loss 0.112541\n",
      "batch 4454: loss 0.005821\n",
      "batch 4455: loss 0.014634\n",
      "batch 4456: loss 0.028531\n",
      "batch 4457: loss 0.110162\n",
      "batch 4458: loss 0.097996\n",
      "batch 4459: loss 0.022189\n",
      "batch 4460: loss 0.047720\n",
      "batch 4461: loss 0.020155\n",
      "batch 4462: loss 0.108089\n",
      "batch 4463: loss 0.049897\n",
      "batch 4464: loss 0.126674\n",
      "batch 4465: loss 0.250518\n",
      "batch 4466: loss 0.026411\n",
      "batch 4467: loss 0.127066\n",
      "batch 4468: loss 0.025786\n",
      "batch 4469: loss 0.077487\n",
      "batch 4470: loss 0.062868\n",
      "batch 4471: loss 0.069341\n",
      "batch 4472: loss 0.099568\n",
      "batch 4473: loss 0.067793\n",
      "batch 4474: loss 0.013642\n",
      "batch 4475: loss 0.027509\n",
      "batch 4476: loss 0.063131\n",
      "batch 4477: loss 0.095818\n",
      "batch 4478: loss 0.333068\n",
      "batch 4479: loss 0.036966\n",
      "batch 4480: loss 0.025083\n",
      "batch 4481: loss 0.016784\n",
      "batch 4482: loss 0.046620\n",
      "batch 4483: loss 0.045589\n",
      "batch 4484: loss 0.071100\n",
      "batch 4485: loss 0.112681\n",
      "batch 4486: loss 0.031617\n",
      "batch 4487: loss 0.018778\n",
      "batch 4488: loss 0.113214\n",
      "batch 4489: loss 0.043567\n",
      "batch 4490: loss 0.018612\n",
      "batch 4491: loss 0.021611\n",
      "batch 4492: loss 0.086930\n",
      "batch 4493: loss 0.022559\n",
      "batch 4494: loss 0.068241\n",
      "batch 4495: loss 0.013287\n",
      "batch 4496: loss 0.013581\n",
      "batch 4497: loss 0.096343\n",
      "batch 4498: loss 0.224158\n",
      "batch 4499: loss 0.055916\n",
      "batch 4500: loss 0.218810\n",
      "batch 4501: loss 0.024561\n",
      "batch 4502: loss 0.021349\n",
      "batch 4503: loss 0.048735\n",
      "batch 4504: loss 0.058300\n",
      "batch 4505: loss 0.012593\n",
      "batch 4506: loss 0.104137\n",
      "batch 4507: loss 0.012858\n",
      "batch 4508: loss 0.014829\n",
      "batch 4509: loss 0.020433\n",
      "batch 4510: loss 0.151386\n",
      "batch 4511: loss 0.102301\n",
      "batch 4512: loss 0.070125\n",
      "batch 4513: loss 0.075342\n",
      "batch 4514: loss 0.023364\n",
      "batch 4515: loss 0.083050\n",
      "batch 4516: loss 0.062071\n",
      "batch 4517: loss 0.115551\n",
      "batch 4518: loss 0.059113\n",
      "batch 4519: loss 0.077675\n",
      "batch 4520: loss 0.085363\n",
      "batch 4521: loss 0.051171\n",
      "batch 4522: loss 0.028751\n",
      "batch 4523: loss 0.010825\n",
      "batch 4524: loss 0.015269\n",
      "batch 4525: loss 0.022999\n",
      "batch 4526: loss 0.228148\n",
      "batch 4527: loss 0.035345\n",
      "batch 4528: loss 0.060067\n",
      "batch 4529: loss 0.103239\n",
      "batch 4530: loss 0.015296\n",
      "batch 4531: loss 0.095522\n",
      "batch 4532: loss 0.054985\n",
      "batch 4533: loss 0.013515\n",
      "batch 4534: loss 0.134908\n",
      "batch 4535: loss 0.012308\n",
      "batch 4536: loss 0.101030\n",
      "batch 4537: loss 0.062093\n",
      "batch 4538: loss 0.110651\n",
      "batch 4539: loss 0.075391\n",
      "batch 4540: loss 0.051202\n",
      "batch 4541: loss 0.493801\n",
      "batch 4542: loss 0.058774\n",
      "batch 4543: loss 0.050896\n",
      "batch 4544: loss 0.125334\n",
      "batch 4545: loss 0.043777\n",
      "batch 4546: loss 0.006521\n",
      "batch 4547: loss 0.028821\n",
      "batch 4548: loss 0.082677\n",
      "batch 4549: loss 0.091996\n",
      "batch 4550: loss 0.125530\n",
      "batch 4551: loss 0.080068\n",
      "batch 4552: loss 0.026737\n",
      "batch 4553: loss 0.032278\n",
      "batch 4554: loss 0.053827\n",
      "batch 4555: loss 0.048804\n",
      "batch 4556: loss 0.121942\n",
      "batch 4557: loss 0.048906\n",
      "batch 4558: loss 0.016835\n",
      "batch 4559: loss 0.012306\n",
      "batch 4560: loss 0.033759\n",
      "batch 4561: loss 0.138555\n",
      "batch 4562: loss 0.074714\n",
      "batch 4563: loss 0.063691\n",
      "batch 4564: loss 0.069835\n",
      "batch 4565: loss 0.036823\n",
      "batch 4566: loss 0.066821\n",
      "batch 4567: loss 0.023195\n",
      "batch 4568: loss 0.065616\n",
      "batch 4569: loss 0.102773\n",
      "batch 4570: loss 0.047560\n",
      "batch 4571: loss 0.020735\n",
      "batch 4572: loss 0.044855\n",
      "batch 4573: loss 0.100121\n",
      "batch 4574: loss 0.032760\n",
      "batch 4575: loss 0.014535\n",
      "batch 4576: loss 0.042863\n",
      "batch 4577: loss 0.090556\n",
      "batch 4578: loss 0.046285\n",
      "batch 4579: loss 0.287558\n",
      "batch 4580: loss 0.008522\n",
      "batch 4581: loss 0.007661\n",
      "batch 4582: loss 0.013842\n",
      "batch 4583: loss 0.025421\n",
      "batch 4584: loss 0.037453\n",
      "batch 4585: loss 0.017091\n",
      "batch 4586: loss 0.041328\n",
      "batch 4587: loss 0.019563\n",
      "batch 4588: loss 0.068762\n",
      "batch 4589: loss 0.122574\n",
      "batch 4590: loss 0.081988\n",
      "batch 4591: loss 0.048590\n",
      "batch 4592: loss 0.051863\n",
      "batch 4593: loss 0.132320\n",
      "batch 4594: loss 0.166806\n",
      "batch 4595: loss 0.036786\n",
      "batch 4596: loss 0.024395\n",
      "batch 4597: loss 0.184541\n",
      "batch 4598: loss 0.053393\n",
      "batch 4599: loss 0.023762\n",
      "batch 4600: loss 0.010613\n",
      "batch 4601: loss 0.042136\n",
      "batch 4602: loss 0.007888\n",
      "batch 4603: loss 0.006544\n",
      "batch 4604: loss 0.060630\n",
      "batch 4605: loss 0.069801\n",
      "batch 4606: loss 0.033003\n",
      "batch 4607: loss 0.016037\n",
      "batch 4608: loss 0.217536\n",
      "batch 4609: loss 0.010940\n",
      "batch 4610: loss 0.077177\n",
      "batch 4611: loss 0.079622\n",
      "batch 4612: loss 0.083962\n",
      "batch 4613: loss 0.112272\n",
      "batch 4614: loss 0.218251\n",
      "batch 4615: loss 0.018304\n",
      "batch 4616: loss 0.041972\n",
      "batch 4617: loss 0.098563\n",
      "batch 4618: loss 0.322280\n",
      "batch 4619: loss 0.006202\n",
      "batch 4620: loss 0.041267\n",
      "batch 4621: loss 0.060596\n",
      "batch 4622: loss 0.133395\n",
      "batch 4623: loss 0.027119\n",
      "batch 4624: loss 0.046768\n",
      "batch 4625: loss 0.017775\n",
      "batch 4626: loss 0.025078\n",
      "batch 4627: loss 0.020600\n",
      "batch 4628: loss 0.043556\n",
      "batch 4629: loss 0.013271\n",
      "batch 4630: loss 0.058303\n",
      "batch 4631: loss 0.022320\n",
      "batch 4632: loss 0.197720\n",
      "batch 4633: loss 0.040530\n",
      "batch 4634: loss 0.080742\n",
      "batch 4635: loss 0.098821\n",
      "batch 4636: loss 0.227365\n",
      "batch 4637: loss 0.015433\n",
      "batch 4638: loss 0.004269\n",
      "batch 4639: loss 0.028029\n",
      "batch 4640: loss 0.193692\n",
      "batch 4641: loss 0.030773\n",
      "batch 4642: loss 0.007316\n",
      "batch 4643: loss 0.010879\n",
      "batch 4644: loss 0.074918\n",
      "batch 4645: loss 0.013330\n",
      "batch 4646: loss 0.028768\n",
      "batch 4647: loss 0.010914\n",
      "batch 4648: loss 0.014979\n",
      "batch 4649: loss 0.006152\n",
      "batch 4650: loss 0.012236\n",
      "batch 4651: loss 0.115458\n",
      "batch 4652: loss 0.047711\n",
      "batch 4653: loss 0.019247\n",
      "batch 4654: loss 0.297999\n",
      "batch 4655: loss 0.087409\n",
      "batch 4656: loss 0.045023\n",
      "batch 4657: loss 0.092195\n",
      "batch 4658: loss 0.034183\n",
      "batch 4659: loss 0.035561\n",
      "batch 4660: loss 0.071124\n",
      "batch 4661: loss 0.077235\n",
      "batch 4662: loss 0.017159\n",
      "batch 4663: loss 0.010799\n",
      "batch 4664: loss 0.032524\n",
      "batch 4665: loss 0.135165\n",
      "batch 4666: loss 0.371856\n",
      "batch 4667: loss 0.227337\n",
      "batch 4668: loss 0.076470\n",
      "batch 4669: loss 0.149882\n",
      "batch 4670: loss 0.043799\n",
      "batch 4671: loss 0.019819\n",
      "batch 4672: loss 0.083621\n",
      "batch 4673: loss 0.082998\n",
      "batch 4674: loss 0.038398\n",
      "batch 4675: loss 0.023133\n",
      "batch 4676: loss 0.095121\n",
      "batch 4677: loss 0.022842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4678: loss 0.064380\n",
      "batch 4679: loss 0.065826\n",
      "batch 4680: loss 0.179925\n",
      "batch 4681: loss 0.228675\n",
      "batch 4682: loss 0.027302\n",
      "batch 4683: loss 0.017821\n",
      "batch 4684: loss 0.015114\n",
      "batch 4685: loss 0.010101\n",
      "batch 4686: loss 0.035687\n",
      "batch 4687: loss 0.046773\n",
      "batch 4688: loss 0.081744\n",
      "batch 4689: loss 0.142664\n",
      "batch 4690: loss 0.077093\n",
      "batch 4691: loss 0.013771\n",
      "batch 4692: loss 0.019290\n",
      "batch 4693: loss 0.121882\n",
      "batch 4694: loss 0.007091\n",
      "batch 4695: loss 0.079090\n",
      "batch 4696: loss 0.016581\n",
      "batch 4697: loss 0.040817\n",
      "batch 4698: loss 0.076563\n",
      "batch 4699: loss 0.036403\n",
      "batch 4700: loss 0.017149\n",
      "batch 4701: loss 0.095641\n",
      "batch 4702: loss 0.033032\n",
      "batch 4703: loss 0.022807\n",
      "batch 4704: loss 0.123039\n",
      "batch 4705: loss 0.107880\n",
      "batch 4706: loss 0.023904\n",
      "batch 4707: loss 0.052050\n",
      "batch 4708: loss 0.028069\n",
      "batch 4709: loss 0.055239\n",
      "batch 4710: loss 0.145685\n",
      "batch 4711: loss 0.084552\n",
      "batch 4712: loss 0.076980\n",
      "batch 4713: loss 0.153365\n",
      "batch 4714: loss 0.075195\n",
      "batch 4715: loss 0.007195\n",
      "batch 4716: loss 0.101611\n",
      "batch 4717: loss 0.172729\n",
      "batch 4718: loss 0.022461\n",
      "batch 4719: loss 0.181830\n",
      "batch 4720: loss 0.029660\n",
      "batch 4721: loss 0.027513\n",
      "batch 4722: loss 0.012462\n",
      "batch 4723: loss 0.029960\n",
      "batch 4724: loss 0.082073\n",
      "batch 4725: loss 0.071217\n",
      "batch 4726: loss 0.016799\n",
      "batch 4727: loss 0.048034\n",
      "batch 4728: loss 0.037659\n",
      "batch 4729: loss 0.107223\n",
      "batch 4730: loss 0.180953\n",
      "batch 4731: loss 0.148591\n",
      "batch 4732: loss 0.015437\n",
      "batch 4733: loss 0.009840\n",
      "batch 4734: loss 0.116199\n",
      "batch 4735: loss 0.191443\n",
      "batch 4736: loss 0.078055\n",
      "batch 4737: loss 0.031483\n",
      "batch 4738: loss 0.059508\n",
      "batch 4739: loss 0.044550\n",
      "batch 4740: loss 0.011810\n",
      "batch 4741: loss 0.015583\n",
      "batch 4742: loss 0.153760\n",
      "batch 4743: loss 0.035343\n",
      "batch 4744: loss 0.065738\n",
      "batch 4745: loss 0.035181\n",
      "batch 4746: loss 0.053785\n",
      "batch 4747: loss 0.021432\n",
      "batch 4748: loss 0.045203\n",
      "batch 4749: loss 0.012735\n",
      "batch 4750: loss 0.200283\n",
      "batch 4751: loss 0.049125\n",
      "batch 4752: loss 0.144659\n",
      "batch 4753: loss 0.039093\n",
      "batch 4754: loss 0.029501\n",
      "batch 4755: loss 0.010697\n",
      "batch 4756: loss 0.023309\n",
      "batch 4757: loss 0.156106\n",
      "batch 4758: loss 0.009303\n",
      "batch 4759: loss 0.008367\n",
      "batch 4760: loss 0.128133\n",
      "batch 4761: loss 0.033747\n",
      "batch 4762: loss 0.032534\n",
      "batch 4763: loss 0.012255\n",
      "batch 4764: loss 0.039305\n",
      "batch 4765: loss 0.016816\n",
      "batch 4766: loss 0.056007\n",
      "batch 4767: loss 0.105508\n",
      "batch 4768: loss 0.040330\n",
      "batch 4769: loss 0.019682\n",
      "batch 4770: loss 0.014815\n",
      "batch 4771: loss 0.210806\n",
      "batch 4772: loss 0.083772\n",
      "batch 4773: loss 0.135574\n",
      "batch 4774: loss 0.035107\n",
      "batch 4775: loss 0.031216\n",
      "batch 4776: loss 0.055698\n",
      "batch 4777: loss 0.107256\n",
      "batch 4778: loss 0.002903\n",
      "batch 4779: loss 0.035481\n",
      "batch 4780: loss 0.092292\n",
      "batch 4781: loss 0.138072\n",
      "batch 4782: loss 0.047988\n",
      "batch 4783: loss 0.065912\n",
      "batch 4784: loss 0.023879\n",
      "batch 4785: loss 0.147717\n",
      "batch 4786: loss 0.128535\n",
      "batch 4787: loss 0.002949\n",
      "batch 4788: loss 0.144620\n",
      "batch 4789: loss 0.016716\n",
      "batch 4790: loss 0.040394\n",
      "batch 4791: loss 0.082559\n",
      "batch 4792: loss 0.161148\n",
      "batch 4793: loss 0.022248\n",
      "batch 4794: loss 0.008539\n",
      "batch 4795: loss 0.080613\n",
      "batch 4796: loss 0.013862\n",
      "batch 4797: loss 0.006425\n",
      "batch 4798: loss 0.116016\n",
      "batch 4799: loss 0.063314\n",
      "batch 4800: loss 0.078173\n",
      "batch 4801: loss 0.071742\n",
      "batch 4802: loss 0.026214\n",
      "batch 4803: loss 0.059506\n",
      "batch 4804: loss 0.445264\n",
      "batch 4805: loss 0.345559\n",
      "batch 4806: loss 0.254589\n",
      "batch 4807: loss 0.269325\n",
      "batch 4808: loss 0.075000\n",
      "batch 4809: loss 0.117161\n",
      "batch 4810: loss 0.175438\n",
      "batch 4811: loss 0.101783\n",
      "batch 4812: loss 0.075524\n",
      "batch 4813: loss 0.012991\n",
      "batch 4814: loss 0.207221\n",
      "batch 4815: loss 0.209562\n",
      "batch 4816: loss 0.015616\n",
      "batch 4817: loss 0.037906\n",
      "batch 4818: loss 0.013775\n",
      "batch 4819: loss 0.047923\n",
      "batch 4820: loss 0.029322\n",
      "batch 4821: loss 0.042007\n",
      "batch 4822: loss 0.028174\n",
      "batch 4823: loss 0.017055\n",
      "batch 4824: loss 0.093591\n",
      "batch 4825: loss 0.032285\n",
      "batch 4826: loss 0.005990\n",
      "batch 4827: loss 0.061548\n",
      "batch 4828: loss 0.018979\n",
      "batch 4829: loss 0.039482\n",
      "batch 4830: loss 0.173767\n",
      "batch 4831: loss 0.025418\n",
      "batch 4832: loss 0.073100\n",
      "batch 4833: loss 0.028201\n",
      "batch 4834: loss 0.146216\n",
      "batch 4835: loss 0.104407\n",
      "batch 4836: loss 0.011339\n",
      "batch 4837: loss 0.159088\n",
      "batch 4838: loss 0.009551\n",
      "batch 4839: loss 0.060845\n",
      "batch 4840: loss 0.007007\n",
      "batch 4841: loss 0.050519\n",
      "batch 4842: loss 0.013519\n",
      "batch 4843: loss 0.067145\n",
      "batch 4844: loss 0.019683\n",
      "batch 4845: loss 0.084307\n",
      "batch 4846: loss 0.025369\n",
      "batch 4847: loss 0.025753\n",
      "batch 4848: loss 0.162794\n",
      "batch 4849: loss 0.044891\n",
      "batch 4850: loss 0.108159\n",
      "batch 4851: loss 0.141097\n",
      "batch 4852: loss 0.096256\n",
      "batch 4853: loss 0.068663\n",
      "batch 4854: loss 0.052285\n",
      "batch 4855: loss 0.051716\n",
      "batch 4856: loss 0.036681\n",
      "batch 4857: loss 0.325246\n",
      "batch 4858: loss 0.017522\n",
      "batch 4859: loss 0.186460\n",
      "batch 4860: loss 0.049581\n",
      "batch 4861: loss 0.078957\n",
      "batch 4862: loss 0.203373\n",
      "batch 4863: loss 0.008185\n",
      "batch 4864: loss 0.059277\n",
      "batch 4865: loss 0.014295\n",
      "batch 4866: loss 0.070763\n",
      "batch 4867: loss 0.028537\n",
      "batch 4868: loss 0.016066\n",
      "batch 4869: loss 0.027886\n",
      "batch 4870: loss 0.008829\n",
      "batch 4871: loss 0.068200\n",
      "batch 4872: loss 0.178407\n",
      "batch 4873: loss 0.031631\n",
      "batch 4874: loss 0.052391\n",
      "batch 4875: loss 0.010835\n",
      "batch 4876: loss 0.046235\n",
      "batch 4877: loss 0.054860\n",
      "batch 4878: loss 0.045597\n",
      "batch 4879: loss 0.013599\n",
      "batch 4880: loss 0.040866\n",
      "batch 4881: loss 0.102140\n",
      "batch 4882: loss 0.111591\n",
      "batch 4883: loss 0.013829\n",
      "batch 4884: loss 0.140077\n",
      "batch 4885: loss 0.020614\n",
      "batch 4886: loss 0.019508\n",
      "batch 4887: loss 0.030322\n",
      "batch 4888: loss 0.014801\n",
      "batch 4889: loss 0.009966\n",
      "batch 4890: loss 0.010220\n",
      "batch 4891: loss 0.054176\n",
      "batch 4892: loss 0.020605\n",
      "batch 4893: loss 0.052937\n",
      "batch 4894: loss 0.026082\n",
      "batch 4895: loss 0.039095\n",
      "batch 4896: loss 0.061077\n",
      "batch 4897: loss 0.020221\n",
      "batch 4898: loss 0.083665\n",
      "batch 4899: loss 0.043039\n",
      "batch 4900: loss 0.110372\n",
      "batch 4901: loss 0.059906\n",
      "batch 4902: loss 0.099428\n",
      "batch 4903: loss 0.005308\n",
      "batch 4904: loss 0.011672\n",
      "batch 4905: loss 0.011980\n",
      "batch 4906: loss 0.022797\n",
      "batch 4907: loss 0.055393\n",
      "batch 4908: loss 0.100108\n",
      "batch 4909: loss 0.047275\n",
      "batch 4910: loss 0.035889\n",
      "batch 4911: loss 0.022039\n",
      "batch 4912: loss 0.027752\n",
      "batch 4913: loss 0.154789\n",
      "batch 4914: loss 0.180431\n",
      "batch 4915: loss 0.092035\n",
      "batch 4916: loss 0.066694\n",
      "batch 4917: loss 0.106192\n",
      "batch 4918: loss 0.034356\n",
      "batch 4919: loss 0.012603\n",
      "batch 4920: loss 0.003831\n",
      "batch 4921: loss 0.041638\n",
      "batch 4922: loss 0.013938\n",
      "batch 4923: loss 0.017498\n",
      "batch 4924: loss 0.008825\n",
      "batch 4925: loss 0.184302\n",
      "batch 4926: loss 0.045335\n",
      "batch 4927: loss 0.011100\n",
      "batch 4928: loss 0.019606\n",
      "batch 4929: loss 0.103607\n",
      "batch 4930: loss 0.066256\n",
      "batch 4931: loss 0.025342\n",
      "batch 4932: loss 0.031208\n",
      "batch 4933: loss 0.018603\n",
      "batch 4934: loss 0.062027\n",
      "batch 4935: loss 0.054252\n",
      "batch 4936: loss 0.125159\n",
      "batch 4937: loss 0.108001\n",
      "batch 4938: loss 0.085536\n",
      "batch 4939: loss 0.068784\n",
      "batch 4940: loss 0.053646\n",
      "batch 4941: loss 0.246216\n",
      "batch 4942: loss 0.039827\n",
      "batch 4943: loss 0.005614\n",
      "batch 4944: loss 0.038324\n",
      "batch 4945: loss 0.052303\n",
      "batch 4946: loss 0.272223\n",
      "batch 4947: loss 0.111000\n",
      "batch 4948: loss 0.075220\n",
      "batch 4949: loss 0.034765\n",
      "batch 4950: loss 0.113095\n",
      "batch 4951: loss 0.013680\n",
      "batch 4952: loss 0.077247\n",
      "batch 4953: loss 0.043410\n",
      "batch 4954: loss 0.016630\n",
      "batch 4955: loss 0.014821\n",
      "batch 4956: loss 0.071314\n",
      "batch 4957: loss 0.029599\n",
      "batch 4958: loss 0.051224\n",
      "batch 4959: loss 0.024833\n",
      "batch 4960: loss 0.030354\n",
      "batch 4961: loss 0.064924\n",
      "batch 4962: loss 0.017708\n",
      "batch 4963: loss 0.011125\n",
      "batch 4964: loss 0.216336\n",
      "batch 4965: loss 0.004347\n",
      "batch 4966: loss 0.030946\n",
      "batch 4967: loss 0.014159\n",
      "batch 4968: loss 0.025507\n",
      "batch 4969: loss 0.114382\n",
      "batch 4970: loss 0.015208\n",
      "batch 4971: loss 0.307939\n",
      "batch 4972: loss 0.169184\n",
      "batch 4973: loss 0.077125\n",
      "batch 4974: loss 0.038573\n",
      "batch 4975: loss 0.057541\n",
      "batch 4976: loss 0.004630\n",
      "batch 4977: loss 0.059886\n",
      "batch 4978: loss 0.064849\n",
      "batch 4979: loss 0.033886\n",
      "batch 4980: loss 0.062327\n",
      "batch 4981: loss 0.021571\n",
      "batch 4982: loss 0.001970\n",
      "batch 4983: loss 0.041445\n",
      "batch 4984: loss 0.009348\n",
      "batch 4985: loss 0.019976\n",
      "batch 4986: loss 0.023307\n",
      "batch 4987: loss 0.023499\n",
      "batch 4988: loss 0.069346\n",
      "batch 4989: loss 0.026934\n",
      "batch 4990: loss 0.118111\n",
      "batch 4991: loss 0.037038\n",
      "batch 4992: loss 0.014415\n",
      "batch 4993: loss 0.017448\n",
      "batch 4994: loss 0.043874\n",
      "batch 4995: loss 0.035297\n",
      "batch 4996: loss 0.049865\n",
      "batch 4997: loss 0.022453\n",
      "batch 4998: loss 0.053902\n",
      "batch 4999: loss 0.069249\n",
      "batch 5000: loss 0.008470\n",
      "batch 5001: loss 0.037973\n",
      "batch 5002: loss 0.073297\n",
      "batch 5003: loss 0.018561\n",
      "batch 5004: loss 0.154533\n",
      "batch 5005: loss 0.085256\n",
      "batch 5006: loss 0.033843\n",
      "batch 5007: loss 0.167537\n",
      "batch 5008: loss 0.116309\n",
      "batch 5009: loss 0.044682\n",
      "batch 5010: loss 0.049447\n",
      "batch 5011: loss 0.040027\n",
      "batch 5012: loss 0.068168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5013: loss 0.078273\n",
      "batch 5014: loss 0.118155\n",
      "batch 5015: loss 0.069166\n",
      "batch 5016: loss 0.154311\n",
      "batch 5017: loss 0.171946\n",
      "batch 5018: loss 0.015201\n",
      "batch 5019: loss 0.013858\n",
      "batch 5020: loss 0.008954\n",
      "batch 5021: loss 0.039841\n",
      "batch 5022: loss 0.005172\n",
      "batch 5023: loss 0.010417\n",
      "batch 5024: loss 0.119260\n",
      "batch 5025: loss 0.044323\n",
      "batch 5026: loss 0.082670\n",
      "batch 5027: loss 0.105096\n",
      "batch 5028: loss 0.036712\n",
      "batch 5029: loss 0.152027\n",
      "batch 5030: loss 0.008172\n",
      "batch 5031: loss 0.099625\n",
      "batch 5032: loss 0.203980\n",
      "batch 5033: loss 0.404458\n",
      "batch 5034: loss 0.271370\n",
      "batch 5035: loss 0.166817\n",
      "batch 5036: loss 0.257174\n",
      "batch 5037: loss 0.106532\n",
      "batch 5038: loss 0.013944\n",
      "batch 5039: loss 0.010701\n",
      "batch 5040: loss 0.041897\n",
      "batch 5041: loss 0.178280\n",
      "batch 5042: loss 0.100898\n",
      "batch 5043: loss 0.060769\n",
      "batch 5044: loss 0.199808\n",
      "batch 5045: loss 0.091028\n",
      "batch 5046: loss 0.013726\n",
      "batch 5047: loss 0.015888\n",
      "batch 5048: loss 0.083116\n",
      "batch 5049: loss 0.039095\n",
      "batch 5050: loss 0.032741\n",
      "batch 5051: loss 0.031796\n",
      "batch 5052: loss 0.035149\n",
      "batch 5053: loss 0.248031\n",
      "batch 5054: loss 0.024782\n",
      "batch 5055: loss 0.024334\n",
      "batch 5056: loss 0.109432\n",
      "batch 5057: loss 0.016467\n",
      "batch 5058: loss 0.037080\n",
      "batch 5059: loss 0.059605\n",
      "batch 5060: loss 0.086940\n",
      "batch 5061: loss 0.107854\n",
      "batch 5062: loss 0.301825\n",
      "batch 5063: loss 0.059656\n",
      "batch 5064: loss 0.048538\n",
      "batch 5065: loss 0.134188\n",
      "batch 5066: loss 0.077400\n",
      "batch 5067: loss 0.153708\n",
      "batch 5068: loss 0.232569\n",
      "batch 5069: loss 0.007613\n",
      "batch 5070: loss 0.088938\n",
      "batch 5071: loss 0.137590\n",
      "batch 5072: loss 0.017236\n",
      "batch 5073: loss 0.030017\n",
      "batch 5074: loss 0.038042\n",
      "batch 5075: loss 0.044405\n",
      "batch 5076: loss 0.139447\n",
      "batch 5077: loss 0.046367\n",
      "batch 5078: loss 0.050388\n",
      "batch 5079: loss 0.005689\n",
      "batch 5080: loss 0.020410\n",
      "batch 5081: loss 0.027840\n",
      "batch 5082: loss 0.036787\n",
      "batch 5083: loss 0.024653\n",
      "batch 5084: loss 0.167423\n",
      "batch 5085: loss 0.022649\n",
      "batch 5086: loss 0.419717\n",
      "batch 5087: loss 0.035589\n",
      "batch 5088: loss 0.025122\n",
      "batch 5089: loss 0.008628\n",
      "batch 5090: loss 0.020202\n",
      "batch 5091: loss 0.024025\n",
      "batch 5092: loss 0.056289\n",
      "batch 5093: loss 0.048992\n",
      "batch 5094: loss 0.009055\n",
      "batch 5095: loss 0.124871\n",
      "batch 5096: loss 0.108260\n",
      "batch 5097: loss 0.114423\n",
      "batch 5098: loss 0.048947\n",
      "batch 5099: loss 0.009178\n",
      "batch 5100: loss 0.008978\n",
      "batch 5101: loss 0.049091\n",
      "batch 5102: loss 0.058458\n",
      "batch 5103: loss 0.032053\n",
      "batch 5104: loss 0.031705\n",
      "batch 5105: loss 0.030653\n",
      "batch 5106: loss 0.006973\n",
      "batch 5107: loss 0.050172\n",
      "batch 5108: loss 0.021608\n",
      "batch 5109: loss 0.039243\n",
      "batch 5110: loss 0.178446\n",
      "batch 5111: loss 0.140404\n",
      "batch 5112: loss 0.180611\n",
      "batch 5113: loss 0.106702\n",
      "batch 5114: loss 0.040909\n",
      "batch 5115: loss 0.088042\n",
      "batch 5116: loss 0.005959\n",
      "batch 5117: loss 0.099292\n",
      "batch 5118: loss 0.027831\n",
      "batch 5119: loss 0.043384\n",
      "batch 5120: loss 0.007887\n",
      "batch 5121: loss 0.049076\n",
      "batch 5122: loss 0.048640\n",
      "batch 5123: loss 0.010798\n",
      "batch 5124: loss 0.005054\n",
      "batch 5125: loss 0.024383\n",
      "batch 5126: loss 0.021119\n",
      "batch 5127: loss 0.049486\n",
      "batch 5128: loss 0.055616\n",
      "batch 5129: loss 0.052918\n",
      "batch 5130: loss 0.082305\n",
      "batch 5131: loss 0.055444\n",
      "batch 5132: loss 0.009406\n",
      "batch 5133: loss 0.111916\n",
      "batch 5134: loss 0.020345\n",
      "batch 5135: loss 0.019009\n",
      "batch 5136: loss 0.123186\n",
      "batch 5137: loss 0.133857\n",
      "batch 5138: loss 0.128518\n",
      "batch 5139: loss 0.008351\n",
      "batch 5140: loss 0.237904\n",
      "batch 5141: loss 0.042312\n",
      "batch 5142: loss 0.228398\n",
      "batch 5143: loss 0.160931\n",
      "batch 5144: loss 0.070482\n",
      "batch 5145: loss 0.048027\n",
      "batch 5146: loss 0.026813\n",
      "batch 5147: loss 0.005386\n",
      "batch 5148: loss 0.015228\n",
      "batch 5149: loss 0.027457\n",
      "batch 5150: loss 0.011686\n",
      "batch 5151: loss 0.143715\n",
      "batch 5152: loss 0.008410\n",
      "batch 5153: loss 0.080380\n",
      "batch 5154: loss 0.194410\n",
      "batch 5155: loss 0.010604\n",
      "batch 5156: loss 0.019258\n",
      "batch 5157: loss 0.073596\n",
      "batch 5158: loss 0.081839\n",
      "batch 5159: loss 0.134562\n",
      "batch 5160: loss 0.007929\n",
      "batch 5161: loss 0.087496\n",
      "batch 5162: loss 0.097735\n",
      "batch 5163: loss 0.068127\n",
      "batch 5164: loss 0.035223\n",
      "batch 5165: loss 0.014295\n",
      "batch 5166: loss 0.017111\n",
      "batch 5167: loss 0.007632\n",
      "batch 5168: loss 0.065614\n",
      "batch 5169: loss 0.013091\n",
      "batch 5170: loss 0.021538\n",
      "batch 5171: loss 0.026689\n",
      "batch 5172: loss 0.041275\n",
      "batch 5173: loss 0.103896\n",
      "batch 5174: loss 0.032377\n",
      "batch 5175: loss 0.054810\n",
      "batch 5176: loss 0.071733\n",
      "batch 5177: loss 0.200149\n",
      "batch 5178: loss 0.040170\n",
      "batch 5179: loss 0.129710\n",
      "batch 5180: loss 0.023605\n",
      "batch 5181: loss 0.014435\n",
      "batch 5182: loss 0.015087\n",
      "batch 5183: loss 0.188527\n",
      "batch 5184: loss 0.086455\n",
      "batch 5185: loss 0.022671\n",
      "batch 5186: loss 0.007410\n",
      "batch 5187: loss 0.049472\n",
      "batch 5188: loss 0.061734\n",
      "batch 5189: loss 0.031063\n",
      "batch 5190: loss 0.023501\n",
      "batch 5191: loss 0.037536\n",
      "batch 5192: loss 0.018971\n",
      "batch 5193: loss 0.091343\n",
      "batch 5194: loss 0.034905\n",
      "batch 5195: loss 0.212813\n",
      "batch 5196: loss 0.008079\n",
      "batch 5197: loss 0.130275\n",
      "batch 5198: loss 0.043235\n",
      "batch 5199: loss 0.023453\n",
      "batch 5200: loss 0.059410\n",
      "batch 5201: loss 0.115582\n",
      "batch 5202: loss 0.088741\n",
      "batch 5203: loss 0.018378\n",
      "batch 5204: loss 0.008863\n",
      "batch 5205: loss 0.287977\n",
      "batch 5206: loss 0.007336\n",
      "batch 5207: loss 0.014177\n",
      "batch 5208: loss 0.091035\n",
      "batch 5209: loss 0.012029\n",
      "batch 5210: loss 0.011894\n",
      "batch 5211: loss 0.033637\n",
      "batch 5212: loss 0.060353\n",
      "batch 5213: loss 0.043022\n",
      "batch 5214: loss 0.201251\n",
      "batch 5215: loss 0.063402\n",
      "batch 5216: loss 0.025873\n",
      "batch 5217: loss 0.006430\n",
      "batch 5218: loss 0.048402\n",
      "batch 5219: loss 0.049479\n",
      "batch 5220: loss 0.028341\n",
      "batch 5221: loss 0.041192\n",
      "batch 5222: loss 0.060596\n",
      "batch 5223: loss 0.033954\n",
      "batch 5224: loss 0.254300\n",
      "batch 5225: loss 0.054892\n",
      "batch 5226: loss 0.104879\n",
      "batch 5227: loss 0.133869\n",
      "batch 5228: loss 0.025077\n",
      "batch 5229: loss 0.036158\n",
      "batch 5230: loss 0.059353\n",
      "batch 5231: loss 0.194016\n",
      "batch 5232: loss 0.010439\n",
      "batch 5233: loss 0.017920\n",
      "batch 5234: loss 0.088099\n",
      "batch 5235: loss 0.019193\n",
      "batch 5236: loss 0.164101\n",
      "batch 5237: loss 0.019590\n",
      "batch 5238: loss 0.027749\n",
      "batch 5239: loss 0.019302\n",
      "batch 5240: loss 0.035616\n",
      "batch 5241: loss 0.083521\n",
      "batch 5242: loss 0.060782\n",
      "batch 5243: loss 0.010372\n",
      "batch 5244: loss 0.028936\n",
      "batch 5245: loss 0.058083\n",
      "batch 5246: loss 0.018156\n",
      "batch 5247: loss 0.093254\n",
      "batch 5248: loss 0.011878\n",
      "batch 5249: loss 0.070560\n",
      "batch 5250: loss 0.012587\n",
      "batch 5251: loss 0.133728\n",
      "batch 5252: loss 0.018584\n",
      "batch 5253: loss 0.169700\n",
      "batch 5254: loss 0.132600\n",
      "batch 5255: loss 0.029621\n",
      "batch 5256: loss 0.012268\n",
      "batch 5257: loss 0.019037\n",
      "batch 5258: loss 0.077993\n",
      "batch 5259: loss 0.009086\n",
      "batch 5260: loss 0.122516\n",
      "batch 5261: loss 0.080513\n",
      "batch 5262: loss 0.034618\n",
      "batch 5263: loss 0.024259\n",
      "batch 5264: loss 0.009624\n",
      "batch 5265: loss 0.302886\n",
      "batch 5266: loss 0.075594\n",
      "batch 5267: loss 0.012860\n",
      "batch 5268: loss 0.024377\n",
      "batch 5269: loss 0.021232\n",
      "batch 5270: loss 0.086476\n",
      "batch 5271: loss 0.276628\n",
      "batch 5272: loss 0.008313\n",
      "batch 5273: loss 0.099278\n",
      "batch 5274: loss 0.115612\n",
      "batch 5275: loss 0.009749\n",
      "batch 5276: loss 0.118437\n",
      "batch 5277: loss 0.048719\n",
      "batch 5278: loss 0.104972\n",
      "batch 5279: loss 0.071928\n",
      "batch 5280: loss 0.014251\n",
      "batch 5281: loss 0.077406\n",
      "batch 5282: loss 0.050242\n",
      "batch 5283: loss 0.065031\n",
      "batch 5284: loss 0.013192\n",
      "batch 5285: loss 0.030592\n",
      "batch 5286: loss 0.193977\n",
      "batch 5287: loss 0.106947\n",
      "batch 5288: loss 0.032415\n",
      "batch 5289: loss 0.091981\n",
      "batch 5290: loss 0.208434\n",
      "batch 5291: loss 0.022254\n",
      "batch 5292: loss 0.145659\n",
      "batch 5293: loss 0.026734\n",
      "batch 5294: loss 0.026567\n",
      "batch 5295: loss 0.012034\n",
      "batch 5296: loss 0.031464\n",
      "batch 5297: loss 0.101867\n",
      "batch 5298: loss 0.093902\n",
      "batch 5299: loss 0.023933\n",
      "batch 5300: loss 0.013916\n",
      "batch 5301: loss 0.086075\n",
      "batch 5302: loss 0.047096\n",
      "batch 5303: loss 0.018682\n",
      "batch 5304: loss 0.232226\n",
      "batch 5305: loss 0.115464\n",
      "batch 5306: loss 0.010683\n",
      "batch 5307: loss 0.083700\n",
      "batch 5308: loss 0.013642\n",
      "batch 5309: loss 0.010121\n",
      "batch 5310: loss 0.006683\n",
      "batch 5311: loss 0.024169\n",
      "batch 5312: loss 0.040686\n",
      "batch 5313: loss 0.051138\n",
      "batch 5314: loss 0.096297\n",
      "batch 5315: loss 0.004800\n",
      "batch 5316: loss 0.026031\n",
      "batch 5317: loss 0.028755\n",
      "batch 5318: loss 0.067345\n",
      "batch 5319: loss 0.218953\n",
      "batch 5320: loss 0.036567\n",
      "batch 5321: loss 0.050893\n",
      "batch 5322: loss 0.019557\n",
      "batch 5323: loss 0.048105\n",
      "batch 5324: loss 0.238552\n",
      "batch 5325: loss 0.018312\n",
      "batch 5326: loss 0.054797\n",
      "batch 5327: loss 0.023246\n",
      "batch 5328: loss 0.047798\n",
      "batch 5329: loss 0.097707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5330: loss 0.038773\n",
      "batch 5331: loss 0.016521\n",
      "batch 5332: loss 0.016125\n",
      "batch 5333: loss 0.154762\n",
      "batch 5334: loss 0.029513\n",
      "batch 5335: loss 0.009149\n",
      "batch 5336: loss 0.029511\n",
      "batch 5337: loss 0.086189\n",
      "batch 5338: loss 0.011376\n",
      "batch 5339: loss 0.016898\n",
      "batch 5340: loss 0.110335\n",
      "batch 5341: loss 0.038202\n",
      "batch 5342: loss 0.028929\n",
      "batch 5343: loss 0.132477\n",
      "batch 5344: loss 0.088856\n",
      "batch 5345: loss 0.032835\n",
      "batch 5346: loss 0.033788\n",
      "batch 5347: loss 0.021124\n",
      "batch 5348: loss 0.125027\n",
      "batch 5349: loss 0.090744\n",
      "batch 5350: loss 0.029536\n",
      "batch 5351: loss 0.016665\n",
      "batch 5352: loss 0.027385\n",
      "batch 5353: loss 0.161963\n",
      "batch 5354: loss 0.085698\n",
      "batch 5355: loss 0.148134\n",
      "batch 5356: loss 0.037220\n",
      "batch 5357: loss 0.029374\n",
      "batch 5358: loss 0.118824\n",
      "batch 5359: loss 0.093451\n",
      "batch 5360: loss 0.079056\n",
      "batch 5361: loss 0.011083\n",
      "batch 5362: loss 0.034041\n",
      "batch 5363: loss 0.013273\n",
      "batch 5364: loss 0.023614\n",
      "batch 5365: loss 0.034743\n",
      "batch 5366: loss 0.039496\n",
      "batch 5367: loss 0.156580\n",
      "batch 5368: loss 0.029821\n",
      "batch 5369: loss 0.060188\n",
      "batch 5370: loss 0.028871\n",
      "batch 5371: loss 0.101374\n",
      "batch 5372: loss 0.102307\n",
      "batch 5373: loss 0.168588\n",
      "batch 5374: loss 0.008695\n",
      "batch 5375: loss 0.011243\n",
      "batch 5376: loss 0.079558\n",
      "batch 5377: loss 0.006791\n",
      "batch 5378: loss 0.135662\n",
      "batch 5379: loss 0.015436\n",
      "batch 5380: loss 0.035395\n",
      "batch 5381: loss 0.085449\n",
      "batch 5382: loss 0.025324\n",
      "batch 5383: loss 0.061319\n",
      "batch 5384: loss 0.018764\n",
      "batch 5385: loss 0.123138\n",
      "batch 5386: loss 0.096923\n",
      "batch 5387: loss 0.036906\n",
      "batch 5388: loss 0.019225\n",
      "batch 5389: loss 0.048535\n",
      "batch 5390: loss 0.040529\n",
      "batch 5391: loss 0.211554\n",
      "batch 5392: loss 0.033483\n",
      "batch 5393: loss 0.302484\n",
      "batch 5394: loss 0.024777\n",
      "batch 5395: loss 0.144858\n",
      "batch 5396: loss 0.026044\n",
      "batch 5397: loss 0.271309\n",
      "batch 5398: loss 0.104973\n",
      "batch 5399: loss 0.004946\n",
      "batch 5400: loss 0.022925\n",
      "batch 5401: loss 0.009149\n",
      "batch 5402: loss 0.009734\n",
      "batch 5403: loss 0.013383\n",
      "batch 5404: loss 0.202264\n",
      "batch 5405: loss 0.027701\n",
      "batch 5406: loss 0.006473\n",
      "batch 5407: loss 0.012256\n",
      "batch 5408: loss 0.048697\n",
      "batch 5409: loss 0.040610\n",
      "batch 5410: loss 0.056080\n",
      "batch 5411: loss 0.083812\n",
      "batch 5412: loss 0.037844\n",
      "batch 5413: loss 0.007428\n",
      "batch 5414: loss 0.028449\n",
      "batch 5415: loss 0.072297\n",
      "batch 5416: loss 0.052945\n",
      "batch 5417: loss 0.162571\n",
      "batch 5418: loss 0.057823\n",
      "batch 5419: loss 0.150519\n",
      "batch 5420: loss 0.133591\n",
      "batch 5421: loss 0.017272\n",
      "batch 5422: loss 0.110418\n",
      "batch 5423: loss 0.208828\n",
      "batch 5424: loss 0.031392\n",
      "batch 5425: loss 0.003188\n",
      "batch 5426: loss 0.186474\n",
      "batch 5427: loss 0.179860\n",
      "batch 5428: loss 0.497271\n",
      "batch 5429: loss 0.099285\n",
      "batch 5430: loss 0.051990\n",
      "batch 5431: loss 0.020997\n",
      "batch 5432: loss 0.099090\n",
      "batch 5433: loss 0.058627\n",
      "batch 5434: loss 0.142411\n",
      "batch 5435: loss 0.015889\n",
      "batch 5436: loss 0.059823\n",
      "batch 5437: loss 0.057800\n",
      "batch 5438: loss 0.071818\n",
      "batch 5439: loss 0.020045\n",
      "batch 5440: loss 0.034156\n",
      "batch 5441: loss 0.031287\n",
      "batch 5442: loss 0.182701\n",
      "batch 5443: loss 0.013416\n",
      "batch 5444: loss 0.032909\n",
      "batch 5445: loss 0.022101\n",
      "batch 5446: loss 0.005922\n",
      "batch 5447: loss 0.161800\n",
      "batch 5448: loss 0.071134\n",
      "batch 5449: loss 0.048843\n",
      "batch 5450: loss 0.304272\n",
      "batch 5451: loss 0.007130\n",
      "batch 5452: loss 0.042009\n",
      "batch 5453: loss 0.002383\n",
      "batch 5454: loss 0.021414\n",
      "batch 5455: loss 0.188665\n",
      "batch 5456: loss 0.021560\n",
      "batch 5457: loss 0.076249\n",
      "batch 5458: loss 0.003201\n",
      "batch 5459: loss 0.113959\n",
      "batch 5460: loss 0.051064\n",
      "batch 5461: loss 0.013045\n",
      "batch 5462: loss 0.029601\n",
      "batch 5463: loss 0.044810\n",
      "batch 5464: loss 0.057222\n",
      "batch 5465: loss 0.121924\n",
      "batch 5466: loss 0.033651\n",
      "batch 5467: loss 0.008174\n",
      "batch 5468: loss 0.065638\n",
      "batch 5469: loss 0.126699\n",
      "batch 5470: loss 0.010602\n",
      "batch 5471: loss 0.011638\n",
      "batch 5472: loss 0.058890\n",
      "batch 5473: loss 0.006900\n",
      "batch 5474: loss 0.035087\n",
      "batch 5475: loss 0.026745\n",
      "batch 5476: loss 0.030070\n",
      "batch 5477: loss 0.080668\n",
      "batch 5478: loss 0.044699\n",
      "batch 5479: loss 0.144126\n",
      "batch 5480: loss 0.015533\n",
      "batch 5481: loss 0.012893\n",
      "batch 5482: loss 0.059673\n",
      "batch 5483: loss 0.075813\n",
      "batch 5484: loss 0.049145\n",
      "batch 5485: loss 0.042836\n",
      "batch 5486: loss 0.017969\n",
      "batch 5487: loss 0.024658\n",
      "batch 5488: loss 0.020912\n",
      "batch 5489: loss 0.077290\n",
      "batch 5490: loss 0.059657\n",
      "batch 5491: loss 0.037851\n",
      "batch 5492: loss 0.014141\n",
      "batch 5493: loss 0.149539\n",
      "batch 5494: loss 0.030116\n",
      "batch 5495: loss 0.010521\n",
      "batch 5496: loss 0.075028\n",
      "batch 5497: loss 0.018269\n",
      "batch 5498: loss 0.023978\n",
      "batch 5499: loss 0.099344\n",
      "batch 5500: loss 0.103446\n",
      "batch 5501: loss 0.080829\n",
      "batch 5502: loss 0.065944\n",
      "batch 5503: loss 0.043168\n",
      "batch 5504: loss 0.067862\n",
      "batch 5505: loss 0.104286\n",
      "batch 5506: loss 0.111345\n",
      "batch 5507: loss 0.177673\n",
      "batch 5508: loss 0.012536\n",
      "batch 5509: loss 0.040513\n",
      "batch 5510: loss 0.021452\n",
      "batch 5511: loss 0.058721\n",
      "batch 5512: loss 0.033428\n",
      "batch 5513: loss 0.069693\n",
      "batch 5514: loss 0.011514\n",
      "batch 5515: loss 0.044609\n",
      "batch 5516: loss 0.048207\n",
      "batch 5517: loss 0.015088\n",
      "batch 5518: loss 0.015541\n",
      "batch 5519: loss 0.255581\n",
      "batch 5520: loss 0.150520\n",
      "batch 5521: loss 0.041819\n",
      "batch 5522: loss 0.048199\n",
      "batch 5523: loss 0.014301\n",
      "batch 5524: loss 0.027633\n",
      "batch 5525: loss 0.054672\n",
      "batch 5526: loss 0.014134\n",
      "batch 5527: loss 0.165205\n",
      "batch 5528: loss 0.285341\n",
      "batch 5529: loss 0.024083\n",
      "batch 5530: loss 0.054944\n",
      "batch 5531: loss 0.017277\n",
      "batch 5532: loss 0.014566\n",
      "batch 5533: loss 0.108843\n",
      "batch 5534: loss 0.070943\n",
      "batch 5535: loss 0.020602\n",
      "batch 5536: loss 0.011842\n",
      "batch 5537: loss 0.002657\n",
      "batch 5538: loss 0.014848\n",
      "batch 5539: loss 0.030796\n",
      "batch 5540: loss 0.038794\n",
      "batch 5541: loss 0.080517\n",
      "batch 5542: loss 0.046022\n",
      "batch 5543: loss 0.030029\n",
      "batch 5544: loss 0.064378\n",
      "batch 5545: loss 0.067424\n",
      "batch 5546: loss 0.121134\n",
      "batch 5547: loss 0.018041\n",
      "batch 5548: loss 0.048844\n",
      "batch 5549: loss 0.015968\n",
      "batch 5550: loss 0.028039\n",
      "batch 5551: loss 0.010485\n",
      "batch 5552: loss 0.023220\n",
      "batch 5553: loss 0.030947\n",
      "batch 5554: loss 0.026390\n",
      "batch 5555: loss 0.387670\n",
      "batch 5556: loss 0.038073\n",
      "batch 5557: loss 0.029153\n",
      "batch 5558: loss 0.184561\n",
      "batch 5559: loss 0.046760\n",
      "batch 5560: loss 0.029234\n",
      "batch 5561: loss 0.018635\n",
      "batch 5562: loss 0.016673\n",
      "batch 5563: loss 0.009272\n",
      "batch 5564: loss 0.057299\n",
      "batch 5565: loss 0.052625\n",
      "batch 5566: loss 0.378667\n",
      "batch 5567: loss 0.025430\n",
      "batch 5568: loss 0.144996\n",
      "batch 5569: loss 0.045406\n",
      "batch 5570: loss 0.015960\n",
      "batch 5571: loss 0.140828\n",
      "batch 5572: loss 0.009460\n",
      "batch 5573: loss 0.077840\n",
      "batch 5574: loss 0.054729\n",
      "batch 5575: loss 0.025367\n",
      "batch 5576: loss 0.014398\n",
      "batch 5577: loss 0.002824\n",
      "batch 5578: loss 0.081394\n",
      "batch 5579: loss 0.018265\n",
      "batch 5580: loss 0.059855\n",
      "batch 5581: loss 0.098819\n",
      "batch 5582: loss 0.127498\n",
      "batch 5583: loss 0.028746\n",
      "batch 5584: loss 0.114276\n",
      "batch 5585: loss 0.018929\n",
      "batch 5586: loss 0.025410\n",
      "batch 5587: loss 0.050300\n",
      "batch 5588: loss 0.045579\n",
      "batch 5589: loss 0.029863\n",
      "batch 5590: loss 0.036519\n",
      "batch 5591: loss 0.068373\n",
      "batch 5592: loss 0.104237\n",
      "batch 5593: loss 0.122690\n",
      "batch 5594: loss 0.033864\n",
      "batch 5595: loss 0.126519\n",
      "batch 5596: loss 0.055117\n",
      "batch 5597: loss 0.126668\n",
      "batch 5598: loss 0.092385\n",
      "batch 5599: loss 0.015515\n",
      "batch 5600: loss 0.083151\n",
      "batch 5601: loss 0.098941\n",
      "batch 5602: loss 0.032974\n",
      "batch 5603: loss 0.022980\n",
      "batch 5604: loss 0.013266\n",
      "batch 5605: loss 0.005895\n",
      "batch 5606: loss 0.098689\n",
      "batch 5607: loss 0.178140\n",
      "batch 5608: loss 0.017401\n",
      "batch 5609: loss 0.020909\n",
      "batch 5610: loss 0.173554\n",
      "batch 5611: loss 0.035839\n",
      "batch 5612: loss 0.061406\n",
      "batch 5613: loss 0.010516\n",
      "batch 5614: loss 0.022685\n",
      "batch 5615: loss 0.079814\n",
      "batch 5616: loss 0.045892\n",
      "batch 5617: loss 0.204613\n",
      "batch 5618: loss 0.138432\n",
      "batch 5619: loss 0.017013\n",
      "batch 5620: loss 0.065716\n",
      "batch 5621: loss 0.102124\n",
      "batch 5622: loss 0.105373\n",
      "batch 5623: loss 0.004808\n",
      "batch 5624: loss 0.016584\n",
      "batch 5625: loss 0.023440\n",
      "batch 5626: loss 0.134554\n",
      "batch 5627: loss 0.037693\n",
      "batch 5628: loss 0.025145\n",
      "batch 5629: loss 0.042163\n",
      "batch 5630: loss 0.022514\n",
      "batch 5631: loss 0.032206\n",
      "batch 5632: loss 0.009357\n",
      "batch 5633: loss 0.019691\n",
      "batch 5634: loss 0.005004\n",
      "batch 5635: loss 0.097586\n",
      "batch 5636: loss 0.140439\n",
      "batch 5637: loss 0.036504\n",
      "batch 5638: loss 0.038266\n",
      "batch 5639: loss 0.014987\n",
      "batch 5640: loss 0.118524\n",
      "batch 5641: loss 0.010712\n",
      "batch 5642: loss 0.003151\n",
      "batch 5643: loss 0.049382\n",
      "batch 5644: loss 0.046578\n",
      "batch 5645: loss 0.058205\n",
      "batch 5646: loss 0.033433\n",
      "batch 5647: loss 0.047560\n",
      "batch 5648: loss 0.027973\n",
      "batch 5649: loss 0.030620\n",
      "batch 5650: loss 0.027359\n",
      "batch 5651: loss 0.028407\n",
      "batch 5652: loss 0.012131\n",
      "batch 5653: loss 0.010227\n",
      "batch 5654: loss 0.065307\n",
      "batch 5655: loss 0.009484\n",
      "batch 5656: loss 0.016806\n",
      "batch 5657: loss 0.015869\n",
      "batch 5658: loss 0.162593\n",
      "batch 5659: loss 0.174779\n",
      "batch 5660: loss 0.040112\n",
      "batch 5661: loss 0.051664\n",
      "batch 5662: loss 0.053577\n",
      "batch 5663: loss 0.029274\n",
      "batch 5664: loss 0.346967\n",
      "batch 5665: loss 0.010620\n",
      "batch 5666: loss 0.168350\n",
      "batch 5667: loss 0.061883\n",
      "batch 5668: loss 0.005333\n",
      "batch 5669: loss 0.003978\n",
      "batch 5670: loss 0.034259\n",
      "batch 5671: loss 0.067730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5672: loss 0.109053\n",
      "batch 5673: loss 0.039779\n",
      "batch 5674: loss 0.012006\n",
      "batch 5675: loss 0.192895\n",
      "batch 5676: loss 0.034544\n",
      "batch 5677: loss 0.029613\n",
      "batch 5678: loss 0.048136\n",
      "batch 5679: loss 0.003675\n",
      "batch 5680: loss 0.041943\n",
      "batch 5681: loss 0.033423\n",
      "batch 5682: loss 0.004458\n",
      "batch 5683: loss 0.008699\n",
      "batch 5684: loss 0.002546\n",
      "batch 5685: loss 0.041430\n",
      "batch 5686: loss 0.051093\n",
      "batch 5687: loss 0.053575\n",
      "batch 5688: loss 0.034419\n",
      "batch 5689: loss 0.024202\n",
      "batch 5690: loss 0.038040\n",
      "batch 5691: loss 0.004939\n",
      "batch 5692: loss 0.019188\n",
      "batch 5693: loss 0.080989\n",
      "batch 5694: loss 0.023442\n",
      "batch 5695: loss 0.032882\n",
      "batch 5696: loss 0.088626\n",
      "batch 5697: loss 0.015065\n",
      "batch 5698: loss 0.037924\n",
      "batch 5699: loss 0.078166\n",
      "batch 5700: loss 0.053143\n",
      "batch 5701: loss 0.090256\n",
      "batch 5702: loss 0.139775\n",
      "batch 5703: loss 0.041214\n",
      "batch 5704: loss 0.048543\n",
      "batch 5705: loss 0.126939\n",
      "batch 5706: loss 0.038698\n",
      "batch 5707: loss 0.064499\n",
      "batch 5708: loss 0.021839\n",
      "batch 5709: loss 0.006054\n",
      "batch 5710: loss 0.021011\n",
      "batch 5711: loss 0.112012\n",
      "batch 5712: loss 0.043841\n",
      "batch 5713: loss 0.103390\n",
      "batch 5714: loss 0.008863\n",
      "batch 5715: loss 0.005766\n",
      "batch 5716: loss 0.021135\n",
      "batch 5717: loss 0.031048\n",
      "batch 5718: loss 0.004441\n",
      "batch 5719: loss 0.022834\n",
      "batch 5720: loss 0.022178\n",
      "batch 5721: loss 0.022838\n",
      "batch 5722: loss 0.013061\n",
      "batch 5723: loss 0.314303\n",
      "batch 5724: loss 0.004682\n",
      "batch 5725: loss 0.063125\n",
      "batch 5726: loss 0.049546\n",
      "batch 5727: loss 0.058759\n",
      "batch 5728: loss 0.006291\n",
      "batch 5729: loss 0.163526\n",
      "batch 5730: loss 0.130190\n",
      "batch 5731: loss 0.042332\n",
      "batch 5732: loss 0.008497\n",
      "batch 5733: loss 0.057460\n",
      "batch 5734: loss 0.048040\n",
      "batch 5735: loss 0.068164\n",
      "batch 5736: loss 0.007988\n",
      "batch 5737: loss 0.022153\n",
      "batch 5738: loss 0.045616\n",
      "batch 5739: loss 0.116474\n",
      "batch 5740: loss 0.056891\n",
      "batch 5741: loss 0.003465\n",
      "batch 5742: loss 0.101869\n",
      "batch 5743: loss 0.009151\n",
      "batch 5744: loss 0.048125\n",
      "batch 5745: loss 0.088202\n",
      "batch 5746: loss 0.012717\n",
      "batch 5747: loss 0.009436\n",
      "batch 5748: loss 0.075031\n",
      "batch 5749: loss 0.101092\n",
      "batch 5750: loss 0.142836\n",
      "batch 5751: loss 0.033608\n",
      "batch 5752: loss 0.016991\n",
      "batch 5753: loss 0.095485\n",
      "batch 5754: loss 0.023281\n",
      "batch 5755: loss 0.056921\n",
      "batch 5756: loss 0.133338\n",
      "batch 5757: loss 0.078005\n",
      "batch 5758: loss 0.027209\n",
      "batch 5759: loss 0.028321\n",
      "batch 5760: loss 0.018373\n",
      "batch 5761: loss 0.016029\n",
      "batch 5762: loss 0.065233\n",
      "batch 5763: loss 0.056042\n",
      "batch 5764: loss 0.089891\n",
      "batch 5765: loss 0.021383\n",
      "batch 5766: loss 0.051361\n",
      "batch 5767: loss 0.097496\n",
      "batch 5768: loss 0.263564\n",
      "batch 5769: loss 0.052536\n",
      "batch 5770: loss 0.023792\n",
      "batch 5771: loss 0.021690\n",
      "batch 5772: loss 0.035725\n",
      "batch 5773: loss 0.020333\n",
      "batch 5774: loss 0.314695\n",
      "batch 5775: loss 0.020093\n",
      "batch 5776: loss 0.004925\n",
      "batch 5777: loss 0.118597\n",
      "batch 5778: loss 0.034235\n",
      "batch 5779: loss 0.019139\n",
      "batch 5780: loss 0.082580\n",
      "batch 5781: loss 0.111444\n",
      "batch 5782: loss 0.012803\n",
      "batch 5783: loss 0.011812\n",
      "batch 5784: loss 0.007871\n",
      "batch 5785: loss 0.013812\n",
      "batch 5786: loss 0.079861\n",
      "batch 5787: loss 0.117089\n",
      "batch 5788: loss 0.146632\n",
      "batch 5789: loss 0.149998\n",
      "batch 5790: loss 0.011481\n",
      "batch 5791: loss 0.011136\n",
      "batch 5792: loss 0.022062\n",
      "batch 5793: loss 0.132694\n",
      "batch 5794: loss 0.038360\n",
      "batch 5795: loss 0.270195\n",
      "batch 5796: loss 0.002812\n",
      "batch 5797: loss 0.023216\n",
      "batch 5798: loss 0.137048\n",
      "batch 5799: loss 0.042609\n",
      "batch 5800: loss 0.013293\n",
      "batch 5801: loss 0.092876\n",
      "batch 5802: loss 0.025600\n",
      "batch 5803: loss 0.007246\n",
      "batch 5804: loss 0.006992\n",
      "batch 5805: loss 0.022638\n",
      "batch 5806: loss 0.009424\n",
      "batch 5807: loss 0.042137\n",
      "batch 5808: loss 0.042449\n",
      "batch 5809: loss 0.381369\n",
      "batch 5810: loss 0.111037\n",
      "batch 5811: loss 0.011056\n",
      "batch 5812: loss 0.140757\n",
      "batch 5813: loss 0.055847\n",
      "batch 5814: loss 0.019738\n",
      "batch 5815: loss 0.031280\n",
      "batch 5816: loss 0.012358\n",
      "batch 5817: loss 0.048935\n",
      "batch 5818: loss 0.142881\n",
      "batch 5819: loss 0.247078\n",
      "batch 5820: loss 0.038243\n",
      "batch 5821: loss 0.156485\n",
      "batch 5822: loss 0.073584\n",
      "batch 5823: loss 0.006304\n",
      "batch 5824: loss 0.009979\n",
      "batch 5825: loss 0.050735\n",
      "batch 5826: loss 0.043459\n",
      "batch 5827: loss 0.044536\n",
      "batch 5828: loss 0.079651\n",
      "batch 5829: loss 0.155923\n",
      "batch 5830: loss 0.023549\n",
      "batch 5831: loss 0.013184\n",
      "batch 5832: loss 0.018185\n",
      "batch 5833: loss 0.005172\n",
      "batch 5834: loss 0.038930\n",
      "batch 5835: loss 0.014435\n",
      "batch 5836: loss 0.096329\n",
      "batch 5837: loss 0.028028\n",
      "batch 5838: loss 0.160641\n",
      "batch 5839: loss 0.004845\n",
      "batch 5840: loss 0.025682\n",
      "batch 5841: loss 0.014171\n",
      "batch 5842: loss 0.022915\n",
      "batch 5843: loss 0.021039\n",
      "batch 5844: loss 0.146003\n",
      "batch 5845: loss 0.085844\n",
      "batch 5846: loss 0.011898\n",
      "batch 5847: loss 0.087796\n",
      "batch 5848: loss 0.014739\n",
      "batch 5849: loss 0.052085\n",
      "batch 5850: loss 0.087293\n",
      "batch 5851: loss 0.119028\n",
      "batch 5852: loss 0.028242\n",
      "batch 5853: loss 0.010782\n",
      "batch 5854: loss 0.164493\n",
      "batch 5855: loss 0.129824\n",
      "batch 5856: loss 0.012405\n",
      "batch 5857: loss 0.027704\n",
      "batch 5858: loss 0.141581\n",
      "batch 5859: loss 0.004254\n",
      "batch 5860: loss 0.017462\n",
      "batch 5861: loss 0.004731\n",
      "batch 5862: loss 0.008056\n",
      "batch 5863: loss 0.089465\n",
      "batch 5864: loss 0.029678\n",
      "batch 5865: loss 0.016323\n",
      "batch 5866: loss 0.060782\n",
      "batch 5867: loss 0.010556\n",
      "batch 5868: loss 0.017449\n",
      "batch 5869: loss 0.012052\n",
      "batch 5870: loss 0.076197\n",
      "batch 5871: loss 0.037222\n",
      "batch 5872: loss 0.114677\n",
      "batch 5873: loss 0.027795\n",
      "batch 5874: loss 0.026493\n",
      "batch 5875: loss 0.035434\n",
      "batch 5876: loss 0.013505\n",
      "batch 5877: loss 0.032295\n",
      "batch 5878: loss 0.007728\n",
      "batch 5879: loss 0.024161\n",
      "batch 5880: loss 0.067563\n",
      "batch 5881: loss 0.020173\n",
      "batch 5882: loss 0.151135\n",
      "batch 5883: loss 0.010209\n",
      "batch 5884: loss 0.022512\n",
      "batch 5885: loss 0.157759\n",
      "batch 5886: loss 0.027825\n",
      "batch 5887: loss 0.138905\n",
      "batch 5888: loss 0.054490\n",
      "batch 5889: loss 0.161399\n",
      "batch 5890: loss 0.033781\n",
      "batch 5891: loss 0.107767\n",
      "batch 5892: loss 0.048207\n",
      "batch 5893: loss 0.039768\n",
      "batch 5894: loss 0.004822\n",
      "batch 5895: loss 0.023728\n",
      "batch 5896: loss 0.023030\n",
      "batch 5897: loss 0.016024\n",
      "batch 5898: loss 0.031421\n",
      "batch 5899: loss 0.037617\n",
      "batch 5900: loss 0.042739\n",
      "batch 5901: loss 0.016050\n",
      "batch 5902: loss 0.015236\n",
      "batch 5903: loss 0.027484\n",
      "batch 5904: loss 0.012829\n",
      "batch 5905: loss 0.047618\n",
      "batch 5906: loss 0.020054\n",
      "batch 5907: loss 0.014654\n",
      "batch 5908: loss 0.005181\n",
      "batch 5909: loss 0.037191\n",
      "batch 5910: loss 0.072200\n",
      "batch 5911: loss 0.003299\n",
      "batch 5912: loss 0.009852\n",
      "batch 5913: loss 0.005439\n",
      "batch 5914: loss 0.059419\n",
      "batch 5915: loss 0.022050\n",
      "batch 5916: loss 0.031106\n",
      "batch 5917: loss 0.045176\n",
      "batch 5918: loss 0.109248\n",
      "batch 5919: loss 0.055951\n",
      "batch 5920: loss 0.117466\n",
      "batch 5921: loss 0.055732\n",
      "batch 5922: loss 0.009294\n",
      "batch 5923: loss 0.005397\n",
      "batch 5924: loss 0.046124\n",
      "batch 5925: loss 0.015794\n",
      "batch 5926: loss 0.006252\n",
      "batch 5927: loss 0.085289\n",
      "batch 5928: loss 0.026660\n",
      "batch 5929: loss 0.121011\n",
      "batch 5930: loss 0.022913\n",
      "batch 5931: loss 0.009620\n",
      "batch 5932: loss 0.042326\n",
      "batch 5933: loss 0.041874\n",
      "batch 5934: loss 0.002964\n",
      "batch 5935: loss 0.010107\n",
      "batch 5936: loss 0.008127\n",
      "batch 5937: loss 0.069153\n",
      "batch 5938: loss 0.015165\n",
      "batch 5939: loss 0.003750\n",
      "batch 5940: loss 0.144485\n",
      "batch 5941: loss 0.068544\n",
      "batch 5942: loss 0.067210\n",
      "batch 5943: loss 0.033431\n",
      "batch 5944: loss 0.040925\n",
      "batch 5945: loss 0.106714\n",
      "batch 5946: loss 0.012458\n",
      "batch 5947: loss 0.049979\n",
      "batch 5948: loss 0.061257\n",
      "batch 5949: loss 0.108105\n",
      "batch 5950: loss 0.018955\n",
      "batch 5951: loss 0.021344\n",
      "batch 5952: loss 0.006489\n",
      "batch 5953: loss 0.051446\n",
      "batch 5954: loss 0.117281\n",
      "batch 5955: loss 0.056449\n",
      "batch 5956: loss 0.021937\n",
      "batch 5957: loss 0.017320\n",
      "batch 5958: loss 0.047306\n",
      "batch 5959: loss 0.248705\n",
      "batch 5960: loss 0.124673\n",
      "batch 5961: loss 0.040042\n",
      "batch 5962: loss 0.004275\n",
      "batch 5963: loss 0.077303\n",
      "batch 5964: loss 0.015630\n",
      "batch 5965: loss 0.023302\n",
      "batch 5966: loss 0.003146\n",
      "batch 5967: loss 0.038397\n",
      "batch 5968: loss 0.021437\n",
      "batch 5969: loss 0.072841\n",
      "batch 5970: loss 0.009165\n",
      "batch 5971: loss 0.128043\n",
      "batch 5972: loss 0.058862\n",
      "batch 5973: loss 0.004689\n",
      "batch 5974: loss 0.029984\n",
      "batch 5975: loss 0.048849\n",
      "batch 5976: loss 0.004276\n",
      "batch 5977: loss 0.249300\n",
      "batch 5978: loss 0.184188\n",
      "batch 5979: loss 0.035144\n",
      "batch 5980: loss 0.029489\n",
      "batch 5981: loss 0.083108\n",
      "batch 5982: loss 0.035918\n",
      "batch 5983: loss 0.004705\n",
      "batch 5984: loss 0.101553\n",
      "batch 5985: loss 0.009395\n",
      "batch 5986: loss 0.012378\n",
      "batch 5987: loss 0.002433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5988: loss 0.034664\n",
      "batch 5989: loss 0.008595\n",
      "batch 5990: loss 0.040199\n",
      "batch 5991: loss 0.042098\n",
      "batch 5992: loss 0.284126\n",
      "batch 5993: loss 0.040309\n",
      "batch 5994: loss 0.153446\n",
      "batch 5995: loss 0.062820\n",
      "batch 5996: loss 0.107820\n",
      "batch 5997: loss 0.018578\n",
      "batch 5998: loss 0.055278\n",
      "batch 5999: loss 0.042166\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "    \n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    \n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 優化神經網路(keras版本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)   (60000,)\n",
      "(10000, 784)   (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "#keras.optimizers.Adam(learning_rate=0.01)\n",
    "#keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# provide labels as one_hot representation => tf.keras.losses.CategoricalCrossentropy\n",
    "# provide labels as integers => tf.keras.losses.SparseCategoricalCrossentropy \n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 - 1s - loss: 2.7168 - accuracy: 0.7500 - val_loss: 0.6696 - val_accuracy: 0.8551\n",
      "Epoch 2/100\n",
      "235/235 - 1s - loss: 0.4772 - accuracy: 0.8876 - val_loss: 0.3863 - val_accuracy: 0.9069\n",
      "Epoch 3/100\n",
      "235/235 - 0s - loss: 0.3047 - accuracy: 0.9182 - val_loss: 0.3004 - val_accuracy: 0.9230\n",
      "Epoch 4/100\n",
      "235/235 - 0s - loss: 0.2286 - accuracy: 0.9366 - val_loss: 0.2639 - val_accuracy: 0.9341\n",
      "Epoch 5/100\n",
      "235/235 - 0s - loss: 0.1856 - accuracy: 0.9464 - val_loss: 0.2417 - val_accuracy: 0.9381\n",
      "Epoch 6/100\n",
      "235/235 - 1s - loss: 0.1571 - accuracy: 0.9539 - val_loss: 0.2174 - val_accuracy: 0.9422\n",
      "Epoch 7/100\n",
      "235/235 - 0s - loss: 0.1402 - accuracy: 0.9585 - val_loss: 0.2101 - val_accuracy: 0.9445\n",
      "Epoch 8/100\n",
      "235/235 - 1s - loss: 0.1220 - accuracy: 0.9634 - val_loss: 0.2079 - val_accuracy: 0.9488\n",
      "Epoch 9/100\n",
      "235/235 - 0s - loss: 0.1111 - accuracy: 0.9665 - val_loss: 0.2068 - val_accuracy: 0.9503\n",
      "Epoch 10/100\n",
      "235/235 - 1s - loss: 0.1009 - accuracy: 0.9688 - val_loss: 0.2097 - val_accuracy: 0.9492\n",
      "Epoch 11/100\n",
      "235/235 - 1s - loss: 0.0909 - accuracy: 0.9722 - val_loss: 0.2082 - val_accuracy: 0.9495\n",
      "Epoch 12/100\n",
      "235/235 - 1s - loss: 0.0880 - accuracy: 0.9727 - val_loss: 0.2051 - val_accuracy: 0.9533\n",
      "Epoch 13/100\n",
      "235/235 - 1s - loss: 0.0803 - accuracy: 0.9754 - val_loss: 0.2073 - val_accuracy: 0.9541\n",
      "Epoch 14/100\n",
      "235/235 - 1s - loss: 0.0821 - accuracy: 0.9738 - val_loss: 0.2240 - val_accuracy: 0.9469\n",
      "Epoch 15/100\n",
      "235/235 - 1s - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.2132 - val_accuracy: 0.9515\n",
      "Epoch 16/100\n",
      "235/235 - 1s - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.2468 - val_accuracy: 0.9501\n",
      "Epoch 17/100\n",
      "235/235 - 0s - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.2039 - val_accuracy: 0.9571\n",
      "Epoch 18/100\n",
      "235/235 - 0s - loss: 0.0647 - accuracy: 0.9796 - val_loss: 0.1973 - val_accuracy: 0.9582\n",
      "Epoch 19/100\n",
      "235/235 - 1s - loss: 0.0670 - accuracy: 0.9801 - val_loss: 0.1964 - val_accuracy: 0.9601\n",
      "Epoch 20/100\n",
      "235/235 - 1s - loss: 0.0611 - accuracy: 0.9809 - val_loss: 0.2071 - val_accuracy: 0.9571\n",
      "Epoch 21/100\n",
      "235/235 - 1s - loss: 0.0617 - accuracy: 0.9804 - val_loss: 0.1928 - val_accuracy: 0.9626\n",
      "Epoch 22/100\n",
      "235/235 - 1s - loss: 0.0586 - accuracy: 0.9818 - val_loss: 0.2014 - val_accuracy: 0.9595\n",
      "Epoch 23/100\n",
      "235/235 - 1s - loss: 0.0533 - accuracy: 0.9830 - val_loss: 0.2001 - val_accuracy: 0.9624\n",
      "Epoch 24/100\n",
      "235/235 - 1s - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.1964 - val_accuracy: 0.9635\n",
      "Epoch 25/100\n",
      "235/235 - 1s - loss: 0.0438 - accuracy: 0.9856 - val_loss: 0.2190 - val_accuracy: 0.9606\n",
      "Epoch 26/100\n",
      "235/235 - 1s - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.2121 - val_accuracy: 0.9608\n",
      "Epoch 27/100\n",
      "235/235 - 1s - loss: 0.0502 - accuracy: 0.9846 - val_loss: 0.2166 - val_accuracy: 0.9603\n",
      "Epoch 28/100\n",
      "235/235 - 1s - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.2404 - val_accuracy: 0.9557\n",
      "Epoch 29/100\n",
      "235/235 - 1s - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.2111 - val_accuracy: 0.9612\n",
      "Epoch 30/100\n",
      "235/235 - 0s - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.2199 - val_accuracy: 0.9628\n",
      "Epoch 31/100\n",
      "235/235 - 1s - loss: 0.0388 - accuracy: 0.9880 - val_loss: 0.2257 - val_accuracy: 0.9643\n",
      "Epoch 32/100\n",
      "235/235 - 0s - loss: 0.0406 - accuracy: 0.9876 - val_loss: 0.2016 - val_accuracy: 0.9642\n",
      "Epoch 33/100\n",
      "235/235 - 1s - loss: 0.0422 - accuracy: 0.9868 - val_loss: 0.2295 - val_accuracy: 0.9635\n",
      "Epoch 34/100\n",
      "235/235 - 0s - loss: 0.0365 - accuracy: 0.9888 - val_loss: 0.2316 - val_accuracy: 0.9636\n",
      "Epoch 35/100\n",
      "235/235 - 1s - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.2186 - val_accuracy: 0.9645\n",
      "Epoch 36/100\n",
      "235/235 - 0s - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.2346 - val_accuracy: 0.9652\n",
      "Epoch 37/100\n",
      "235/235 - 0s - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.2144 - val_accuracy: 0.9662\n",
      "Epoch 38/100\n",
      "235/235 - 0s - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.2419 - val_accuracy: 0.9616\n",
      "Epoch 39/100\n",
      "235/235 - 0s - loss: 0.0327 - accuracy: 0.9898 - val_loss: 0.2504 - val_accuracy: 0.9638\n",
      "Epoch 40/100\n",
      "235/235 - 1s - loss: 0.0315 - accuracy: 0.9904 - val_loss: 0.2380 - val_accuracy: 0.9661\n",
      "Epoch 41/100\n",
      "235/235 - 0s - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.2483 - val_accuracy: 0.9657\n",
      "Epoch 42/100\n",
      "235/235 - 0s - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.2340 - val_accuracy: 0.9644\n",
      "Epoch 43/100\n",
      "235/235 - 1s - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.2597 - val_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "235/235 - 0s - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.2654 - val_accuracy: 0.9607\n",
      "Epoch 45/100\n",
      "235/235 - 0s - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.2532 - val_accuracy: 0.9655\n",
      "Epoch 46/100\n",
      "235/235 - 0s - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.2328 - val_accuracy: 0.9614\n",
      "Epoch 47/100\n",
      "235/235 - 1s - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.2334 - val_accuracy: 0.9660\n",
      "Epoch 48/100\n",
      "235/235 - 0s - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.2126 - val_accuracy: 0.9696\n",
      "Epoch 49/100\n",
      "235/235 - 1s - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.2398 - val_accuracy: 0.9680\n",
      "Epoch 50/100\n",
      "235/235 - 0s - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.2371 - val_accuracy: 0.9712\n",
      "Epoch 51/100\n",
      "235/235 - 0s - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.2393 - val_accuracy: 0.9659\n",
      "Epoch 52/100\n",
      "235/235 - 0s - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.2246 - val_accuracy: 0.9696\n",
      "Epoch 53/100\n",
      "235/235 - 0s - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.2464 - val_accuracy: 0.9673\n",
      "Epoch 54/100\n",
      "235/235 - 1s - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.2586 - val_accuracy: 0.9660\n",
      "Epoch 55/100\n",
      "235/235 - 0s - loss: 0.0262 - accuracy: 0.9924 - val_loss: 0.2611 - val_accuracy: 0.9669\n",
      "Epoch 56/100\n",
      "235/235 - 0s - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.2500 - val_accuracy: 0.9673\n",
      "Epoch 57/100\n",
      "235/235 - 0s - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.2622 - val_accuracy: 0.9681\n",
      "Epoch 58/100\n",
      "235/235 - 1s - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.2489 - val_accuracy: 0.9682\n",
      "Epoch 59/100\n",
      "235/235 - 1s - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.2699 - val_accuracy: 0.9681\n",
      "Epoch 60/100\n",
      "235/235 - 1s - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.2822 - val_accuracy: 0.9687\n",
      "Epoch 61/100\n",
      "235/235 - 1s - loss: 0.0285 - accuracy: 0.9920 - val_loss: 0.2526 - val_accuracy: 0.9689\n",
      "Epoch 62/100\n",
      "235/235 - 1s - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.3052 - val_accuracy: 0.9642\n",
      "Epoch 63/100\n",
      "235/235 - 0s - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.2603 - val_accuracy: 0.9702\n",
      "Epoch 64/100\n",
      "235/235 - 0s - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.2449 - val_accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "235/235 - 0s - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.2802 - val_accuracy: 0.9680\n",
      "Epoch 66/100\n",
      "235/235 - 1s - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.2612 - val_accuracy: 0.9693\n",
      "Epoch 67/100\n",
      "235/235 - 0s - loss: 0.0223 - accuracy: 0.9935 - val_loss: 0.2501 - val_accuracy: 0.9694\n",
      "Epoch 68/100\n",
      "235/235 - 0s - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.2579 - val_accuracy: 0.9709\n",
      "Epoch 69/100\n",
      "235/235 - 0s - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.2889 - val_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "235/235 - 0s - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.3014 - val_accuracy: 0.9650\n",
      "Epoch 71/100\n",
      "235/235 - 0s - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.2676 - val_accuracy: 0.9706\n",
      "Epoch 72/100\n",
      "235/235 - 0s - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.2849 - val_accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "235/235 - 1s - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.2880 - val_accuracy: 0.9696\n",
      "Epoch 74/100\n",
      "235/235 - 0s - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.3027 - val_accuracy: 0.9665\n",
      "Epoch 75/100\n",
      "235/235 - 1s - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.2736 - val_accuracy: 0.9695\n",
      "Epoch 76/100\n",
      "235/235 - 0s - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.2943 - val_accuracy: 0.9689\n",
      "Epoch 77/100\n",
      "235/235 - 0s - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.3039 - val_accuracy: 0.9663\n",
      "Epoch 78/100\n",
      "235/235 - 0s - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.2903 - val_accuracy: 0.9666\n",
      "Epoch 79/100\n",
      "235/235 - 0s - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.2868 - val_accuracy: 0.9694\n",
      "Epoch 80/100\n",
      "235/235 - 1s - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.2756 - val_accuracy: 0.9688\n",
      "Epoch 81/100\n",
      "235/235 - 1s - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.2696 - val_accuracy: 0.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "235/235 - 0s - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.3222 - val_accuracy: 0.9641\n",
      "Epoch 83/100\n",
      "235/235 - 0s - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.3162 - val_accuracy: 0.9668\n",
      "Epoch 84/100\n",
      "235/235 - 0s - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.2860 - val_accuracy: 0.9683\n",
      "Epoch 85/100\n",
      "235/235 - 0s - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.3030 - val_accuracy: 0.9663\n",
      "Epoch 86/100\n",
      "235/235 - 0s - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.2927 - val_accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "235/235 - 1s - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.2868 - val_accuracy: 0.9681\n",
      "Epoch 88/100\n",
      "235/235 - 0s - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.3190 - val_accuracy: 0.9684\n",
      "Epoch 89/100\n",
      "235/235 - 0s - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.2905 - val_accuracy: 0.9679\n",
      "Epoch 90/100\n",
      "235/235 - 0s - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.3017 - val_accuracy: 0.9695\n",
      "Epoch 91/100\n",
      "235/235 - 1s - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.2958 - val_accuracy: 0.9711\n",
      "Epoch 92/100\n",
      "235/235 - 1s - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.2984 - val_accuracy: 0.9712\n",
      "Epoch 93/100\n",
      "235/235 - 1s - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.3190 - val_accuracy: 0.9704\n",
      "Epoch 94/100\n",
      "235/235 - 0s - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.3217 - val_accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "235/235 - 0s - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.3090 - val_accuracy: 0.9710\n",
      "Epoch 96/100\n",
      "235/235 - 0s - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.3053 - val_accuracy: 0.9706\n",
      "Epoch 97/100\n",
      "235/235 - 1s - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.3138 - val_accuracy: 0.9706\n",
      "Epoch 98/100\n",
      "235/235 - 0s - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.3533 - val_accuracy: 0.9686\n",
      "Epoch 99/100\n",
      "235/235 - 0s - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.3159 - val_accuracy: 0.9702\n",
      "Epoch 100/100\n",
      "235/235 - 0s - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.3026 - val_accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=2)\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_data=(x_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
